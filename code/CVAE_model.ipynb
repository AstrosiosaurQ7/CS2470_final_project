{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack,MetaMessage\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from midi_arr import *\n",
    "from demo.midi_array import *\n",
    "import os\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label path     \n",
    "# label_path = r'D:\\BrownUniversity\\CS2470\\final_proj\\CS2470_final\\data\\label.csv'\n",
    "# # Define the folder path\n",
    "# folder_path = r'D:\\BrownUniversity\\CS2470\\final_proj\\CS2470_final\\data\\test'\n",
    "# # load data\n",
    "# music,label, align_length = get_music_data(folder_path, label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "music = load_music()\n",
    "label = load_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1078\n",
      "(500, 3)\n"
     ]
    }
   ],
   "source": [
    "print(len(music))\n",
    "print(music[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help function\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    one_hot_labels = np.zeros((len(labels), num_classes))\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot_labels[i, label - 1] = 1\n",
    "    return one_hot_labels\n",
    "\n",
    "# onehot_encode\n",
    "labels = one_hot_encode(label,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_music(reconstruction):\n",
    "    # Split the tensor into the main part and the last 4 elements\n",
    "    main_part = reconstruction[..., :-4]\n",
    "    last_4_elements = reconstruction[..., -4:]\n",
    "\n",
    "    predicted_notes, predicted_velocities, predicted_times = torch.chunk(main_part, chunks=3, dim=-1)\n",
    "    # notes\n",
    "    predicted_notes = torch.sigmoid(predicted_notes)\n",
    "    predicted_notes = (predicted_notes * (90 - 30)) + 30\n",
    "    # velocities\n",
    "    predicted_velocities = torch.sigmoid(predicted_velocities)\n",
    "    predicted_velocities = (predicted_velocities * 127) + 0\n",
    "    # time\n",
    "    predicted_times = torch.sigmoid(predicted_times)\n",
    "    predicted_times = (predicted_times * 110) + 0\n",
    "    \n",
    "    # Concatenate the processed main part with the last 4 elements\n",
    "    reconstructed_music = torch.cat((predicted_notes, predicted_velocities, predicted_times, last_4_elements), dim=-1)\n",
    "    \n",
    "    return reconstructed_music\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(tensor, min_value, max_value):\n",
    "    min_val = tensor.min()\n",
    "    max_val = tensor.max()\n",
    "    normalized_tensor = min_value + (tensor - min_val) * (max_value - min_value) / (max_val - min_val)\n",
    "    return normalized_tensor\n",
    "\n",
    "def convert_reco(reconstruction):\n",
    "    # notes\n",
    "    notes = reconstruction[:,::3] \n",
    "    notes = min_max_normalize(notes,21,108)\n",
    "    # velocity \n",
    "    velocity = reconstruction[:, 1::3]  \n",
    "    velocity = min_max_normalize(notes,0,127)\n",
    "    # time\n",
    "    time = reconstruction[:, 2::3] \n",
    "    time = min_max_normalize(notes,0,300)\n",
    "\n",
    "    return notes,velocity,time\n",
    "\n",
    "def comb_reco(notes,velocity,time):\n",
    "    stacked_tensor = torch.stack((notes, velocity, time), dim=1)\n",
    "    stacked_tensor = stacked_tensor.squeeze()\n",
    "    reconstruction = stacked_tensor.t().flatten()\n",
    "    return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_loss(reconstruction):\n",
    "    # note\n",
    "    notes = reconstruction[::3] \n",
    "    notes = min_max_normalize(notes,21,108)\n",
    "    # velocity \n",
    "    velocity = reconstruction[1::3]  \n",
    "    velocity = min_max_normalize(notes,0,127)\n",
    "    # time\n",
    "    time = reconstruction[2::3] \n",
    "    time = min_max_normalize(notes,0,300)\n",
    "\n",
    "    return notes,velocity,time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, num_classes, dropout_prob=0.5):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size + num_classes, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3_mean = nn.Linear(hidden_size, latent_size)\n",
    "        self.fc3_logvar = nn.Linear(hidden_size, latent_size)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        # Concatenate input with class information\n",
    "        # y = y.view(-1, 1)\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        mean = self.fc3_mean(x)\n",
    "        # Convert mean to one-hot encoded format\n",
    "        _, max_indices = mean.max(dim=1)\n",
    "        mean_one_hot = torch.zeros(mean.size(), dtype=torch.float32)\n",
    "        mean_one_hot.scatter_(1, max_indices.view(-1, 1), 1)\n",
    "\n",
    "        logvar = self.fc3_logvar(x)\n",
    "        _, logvar_indice = logvar.max(dim=1)\n",
    "        logvar_one_hot = torch.zeros(logvar.size(), dtype=torch.float32)\n",
    "        logvar_one_hot.scatter_(1, logvar_indice.view(-1, 1), 1)\n",
    "\n",
    "        return mean_one_hot, logvar_one_hot\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, output_size, num_classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(latent_size + num_classes, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(84, 500)\n",
    "        \n",
    "    def forward(self, z, y):\n",
    "        # Concatenate latent variable with class information\n",
    "        z = torch.cat((z, y), dim=1)\n",
    "        z = F.relu(self.fc1(z))\n",
    "        reconstruction = self.fc2(z)  \n",
    "        # Convert reconstruction \n",
    "        notes,velocity,time = convert_reco(reconstruction)\n",
    "        notes = self.fc3(notes)\n",
    "        velocity = self.fc3(velocity)\n",
    "        time = self.fc3(time)\n",
    "        reconstruction = comb_reco(notes,velocity,time)\n",
    "\n",
    "        return reconstruction\n",
    "\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, latent_size, output_size, num_classes):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size, latent_size, num_classes)\n",
    "        self.decoder = Decoder(latent_size, hidden_size, output_size, num_classes)\n",
    "        \n",
    "    def reparameterize(self, mean, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mean + eps * std\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = x.to(torch.float32)\n",
    "        y = y.to(torch.float32)\n",
    "        mean, logvar = self.encoder(x, y)\n",
    "        # print(f\"mean:{mean}\")\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        reconstruction = self.decoder(z, y)\n",
    "        # print(f\"reconstruction:{reconstruction}\")\n",
    "        return reconstruction, mean, logvar\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO change shape\n",
    "input_size = 500 * 3\n",
    "hidden_size = 252\n",
    "latent_size = 4\n",
    "num_classes = 4\n",
    "output_size = 250 * 3\n",
    "cvae_model = CVAE(input_size, hidden_size, latent_size, output_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "learning_rate = 0.05\n",
    "optimizer = optim.Adam(cvae_model.parameters(), lr=learning_rate)\n",
    "# Define loss function\n",
    "def melody_loss(predicted_notes, target_notes):\n",
    "    return nn.CrossEntropyLoss()(predicted_notes, target_notes)\n",
    "\n",
    "def harmony_loss(predicted_chords, target_chords):\n",
    "    return nn.CrossEntropyLoss()(predicted_chords, target_chords)\n",
    "\n",
    "def rhythm_loss(predicted_times, target_times):\n",
    "    return nn.MSELoss()(predicted_times, target_times)\n",
    "\n",
    "def hierarchical_music_loss(predicted_music, target_music):\n",
    "    # Extract different components of the music (e.g., notes, velocities, times)\n",
    "    predicted_notes, predicted_velocities, predicted_times = convert_loss(predicted_music)\n",
    "    target_notes, target_velocities, target_times = convert_loss(target_music)\n",
    "\n",
    "    # Compute loss for each musical component\n",
    "    melody_loss_value = melody_loss(predicted_notes, target_notes)\n",
    "    harmony_loss_value = harmony_loss(predicted_velocities, target_velocities)\n",
    "    rhythm_loss_value = rhythm_loss(predicted_times, target_times)\n",
    "\n",
    "    # Combine individual losses\n",
    "    total_loss = melody_loss_value + harmony_loss_value + rhythm_loss_value\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define optimizer\n",
    "# learning_rate = 0.05\n",
    "# optimizer = optim.Adam(cvae_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define loss function\n",
    "def loss_function(recon_x, x, mu, logvar,labels):\n",
    "    x = x.squeeze()\n",
    "    # CE = nn.CrossEntropyLoss(reduction='sum')  # Cross-entropy loss\n",
    "    # reconstruction_loss = CE(recon_x, x)\n",
    "    music_loss = hierarchical_music_loss(recon_x, x)\n",
    "    # KL divergence loss\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # Conditional loss\n",
    "    # Convert class indices to one-hot vectors with the same dimensionality as mu\n",
    "    conditional_loss = torch.mean((labels - mu).pow(2))\n",
    "\n",
    "    \n",
    "    return music_loss + KLD + conditional_loss \n",
    "\n",
    "# Define your training function\n",
    "def train(epoch,train_loader,log_interval):\n",
    "    cvae_model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data = data.view(-1, input_size).to(torch.float32)\n",
    "        labels = labels.to(torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = cvae_model(data, labels)\n",
    "        loss = loss_function(recon_batch, data, mu, logvar,labels)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeoi\\AppData\\Local\\Temp\\ipykernel_46704\\4100207038.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  music = torch.tensor(music)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/1078 (0%)]\tLoss: 4725112.000000\n",
      "Train Epoch: 0 [10/1078 (1%)]\tLoss: 890555.937500\n",
      "Train Epoch: 0 [20/1078 (2%)]\tLoss: 796627.312500\n",
      "Train Epoch: 0 [30/1078 (3%)]\tLoss: 683658.250000\n",
      "Train Epoch: 0 [40/1078 (4%)]\tLoss: 736149.437500\n",
      "Train Epoch: 0 [50/1078 (5%)]\tLoss: 627595.750000\n",
      "Train Epoch: 0 [60/1078 (6%)]\tLoss: 449779.437500\n",
      "Train Epoch: 0 [70/1078 (6%)]\tLoss: 463413.062500\n",
      "Train Epoch: 0 [80/1078 (7%)]\tLoss: 580951.812500\n",
      "Train Epoch: 0 [90/1078 (8%)]\tLoss: 491460.312500\n",
      "Train Epoch: 0 [100/1078 (9%)]\tLoss: 447261.406250\n",
      "Train Epoch: 0 [110/1078 (10%)]\tLoss: 583937.062500\n",
      "Train Epoch: 0 [120/1078 (11%)]\tLoss: 493153.281250\n",
      "Train Epoch: 0 [130/1078 (12%)]\tLoss: 586352.812500\n",
      "Train Epoch: 0 [140/1078 (13%)]\tLoss: 369471.781250\n",
      "Train Epoch: 0 [150/1078 (14%)]\tLoss: 496276.687500\n",
      "Train Epoch: 0 [160/1078 (15%)]\tLoss: 457895.062500\n",
      "Train Epoch: 0 [170/1078 (16%)]\tLoss: 376219.593750\n",
      "Train Epoch: 0 [180/1078 (17%)]\tLoss: 513907.593750\n",
      "Train Epoch: 0 [190/1078 (18%)]\tLoss: 418765.375000\n",
      "Train Epoch: 0 [200/1078 (19%)]\tLoss: 421496.062500\n",
      "Train Epoch: 0 [210/1078 (19%)]\tLoss: 462976.906250\n",
      "Train Epoch: 0 [220/1078 (20%)]\tLoss: 497396.156250\n",
      "Train Epoch: 0 [230/1078 (21%)]\tLoss: 446266.250000\n",
      "Train Epoch: 0 [240/1078 (22%)]\tLoss: 515860.000000\n",
      "Train Epoch: 0 [250/1078 (23%)]\tLoss: 549730.625000\n",
      "Train Epoch: 0 [260/1078 (24%)]\tLoss: 539433.437500\n",
      "Train Epoch: 0 [270/1078 (25%)]\tLoss: 493674.875000\n",
      "Train Epoch: 0 [280/1078 (26%)]\tLoss: 563966.000000\n",
      "Train Epoch: 0 [290/1078 (27%)]\tLoss: 545600.125000\n",
      "Train Epoch: 0 [300/1078 (28%)]\tLoss: 481816.656250\n",
      "Train Epoch: 0 [310/1078 (29%)]\tLoss: 583456.062500\n",
      "Train Epoch: 0 [320/1078 (30%)]\tLoss: 496382.343750\n",
      "Train Epoch: 0 [330/1078 (31%)]\tLoss: 511565.968750\n",
      "Train Epoch: 0 [340/1078 (32%)]\tLoss: 436119.968750\n",
      "Train Epoch: 0 [350/1078 (32%)]\tLoss: 426642.593750\n",
      "Train Epoch: 0 [360/1078 (33%)]\tLoss: 440118.781250\n",
      "Train Epoch: 0 [370/1078 (34%)]\tLoss: 408068.406250\n",
      "Train Epoch: 0 [380/1078 (35%)]\tLoss: 337580.656250\n",
      "Train Epoch: 0 [390/1078 (36%)]\tLoss: 507190.968750\n",
      "Train Epoch: 0 [400/1078 (37%)]\tLoss: 543425.812500\n",
      "Train Epoch: 0 [410/1078 (38%)]\tLoss: 377514.125000\n",
      "Train Epoch: 0 [420/1078 (39%)]\tLoss: 443641.531250\n",
      "Train Epoch: 0 [430/1078 (40%)]\tLoss: 453833.500000\n",
      "Train Epoch: 0 [440/1078 (41%)]\tLoss: 505436.062500\n",
      "Train Epoch: 0 [450/1078 (42%)]\tLoss: 427830.781250\n",
      "Train Epoch: 0 [460/1078 (43%)]\tLoss: 541960.812500\n",
      "Train Epoch: 0 [470/1078 (44%)]\tLoss: 319475.656250\n",
      "Train Epoch: 0 [480/1078 (45%)]\tLoss: 330878.625000\n",
      "Train Epoch: 0 [490/1078 (45%)]\tLoss: 481362.000000\n",
      "Train Epoch: 0 [500/1078 (46%)]\tLoss: 475324.968750\n",
      "Train Epoch: 0 [510/1078 (47%)]\tLoss: 572903.562500\n",
      "Train Epoch: 0 [520/1078 (48%)]\tLoss: 395998.031250\n",
      "Train Epoch: 0 [530/1078 (49%)]\tLoss: 436851.562500\n",
      "Train Epoch: 0 [540/1078 (50%)]\tLoss: 680286.000000\n",
      "Train Epoch: 0 [550/1078 (51%)]\tLoss: 658901.500000\n",
      "Train Epoch: 0 [560/1078 (52%)]\tLoss: 555244.125000\n",
      "Train Epoch: 0 [570/1078 (53%)]\tLoss: 433302.843750\n",
      "Train Epoch: 0 [580/1078 (54%)]\tLoss: 499488.906250\n",
      "Train Epoch: 0 [590/1078 (55%)]\tLoss: 374915.156250\n",
      "Train Epoch: 0 [600/1078 (56%)]\tLoss: 415883.125000\n",
      "Train Epoch: 0 [610/1078 (57%)]\tLoss: 491570.250000\n",
      "Train Epoch: 0 [620/1078 (58%)]\tLoss: 377931.687500\n",
      "Train Epoch: 0 [630/1078 (58%)]\tLoss: 416547.687500\n",
      "Train Epoch: 0 [640/1078 (59%)]\tLoss: 523990.625000\n",
      "Train Epoch: 0 [650/1078 (60%)]\tLoss: 562283.187500\n",
      "Train Epoch: 0 [660/1078 (61%)]\tLoss: 516530.437500\n",
      "Train Epoch: 0 [670/1078 (62%)]\tLoss: 416384.968750\n",
      "Train Epoch: 0 [680/1078 (63%)]\tLoss: 571791.625000\n",
      "Train Epoch: 0 [690/1078 (64%)]\tLoss: 491812.937500\n",
      "Train Epoch: 0 [700/1078 (65%)]\tLoss: 655419.125000\n",
      "Train Epoch: 0 [710/1078 (66%)]\tLoss: 535477.562500\n",
      "Train Epoch: 0 [720/1078 (67%)]\tLoss: 573251.500000\n",
      "Train Epoch: 0 [730/1078 (68%)]\tLoss: 505946.718750\n",
      "Train Epoch: 0 [740/1078 (69%)]\tLoss: 516571.125000\n",
      "Train Epoch: 0 [750/1078 (70%)]\tLoss: 367254.593750\n",
      "Train Epoch: 0 [760/1078 (71%)]\tLoss: 536470.125000\n",
      "Train Epoch: 0 [770/1078 (71%)]\tLoss: 329777.968750\n",
      "Train Epoch: 0 [780/1078 (72%)]\tLoss: 481368.187500\n",
      "Train Epoch: 0 [790/1078 (73%)]\tLoss: 489941.250000\n",
      "Train Epoch: 0 [800/1078 (74%)]\tLoss: 395752.718750\n",
      "Train Epoch: 0 [810/1078 (75%)]\tLoss: 556486.062500\n",
      "Train Epoch: 0 [820/1078 (76%)]\tLoss: 436944.468750\n",
      "Train Epoch: 0 [830/1078 (77%)]\tLoss: 429554.406250\n",
      "Train Epoch: 0 [840/1078 (78%)]\tLoss: 523837.125000\n",
      "Train Epoch: 0 [850/1078 (79%)]\tLoss: 367889.187500\n",
      "Train Epoch: 0 [860/1078 (80%)]\tLoss: 489611.500000\n",
      "Train Epoch: 0 [870/1078 (81%)]\tLoss: 415620.687500\n",
      "Train Epoch: 0 [880/1078 (82%)]\tLoss: 511430.562500\n",
      "Train Epoch: 0 [890/1078 (83%)]\tLoss: 261653.921875\n",
      "Train Epoch: 0 [900/1078 (83%)]\tLoss: 545306.812500\n",
      "Train Epoch: 0 [910/1078 (84%)]\tLoss: 490534.406250\n",
      "Train Epoch: 0 [920/1078 (85%)]\tLoss: 448146.906250\n",
      "Train Epoch: 0 [930/1078 (86%)]\tLoss: 466397.281250\n",
      "Train Epoch: 0 [940/1078 (87%)]\tLoss: 471393.250000\n",
      "Train Epoch: 0 [950/1078 (88%)]\tLoss: 477098.906250\n",
      "Train Epoch: 0 [960/1078 (89%)]\tLoss: 408880.062500\n",
      "Train Epoch: 0 [970/1078 (90%)]\tLoss: 452220.000000\n",
      "Train Epoch: 0 [980/1078 (91%)]\tLoss: 362398.093750\n",
      "Train Epoch: 0 [990/1078 (92%)]\tLoss: 373057.468750\n",
      "Train Epoch: 0 [1000/1078 (93%)]\tLoss: 524141.750000\n",
      "Train Epoch: 0 [1010/1078 (94%)]\tLoss: 363438.781250\n",
      "Train Epoch: 0 [1020/1078 (95%)]\tLoss: 559941.562500\n",
      "Train Epoch: 0 [1030/1078 (96%)]\tLoss: 400373.437500\n",
      "Train Epoch: 0 [1040/1078 (96%)]\tLoss: 529836.750000\n",
      "Train Epoch: 0 [1050/1078 (97%)]\tLoss: 416689.968750\n",
      "Train Epoch: 0 [1060/1078 (98%)]\tLoss: 508385.062500\n",
      "Train Epoch: 0 [1070/1078 (99%)]\tLoss: 517556.687500\n",
      "Train Epoch: 1 [0/1078 (0%)]\tLoss: 490092.437500\n",
      "Train Epoch: 1 [10/1078 (1%)]\tLoss: 557849.562500\n",
      "Train Epoch: 1 [20/1078 (2%)]\tLoss: 386929.437500\n",
      "Train Epoch: 1 [30/1078 (3%)]\tLoss: 350307.687500\n",
      "Train Epoch: 1 [40/1078 (4%)]\tLoss: 465478.281250\n",
      "Train Epoch: 1 [50/1078 (5%)]\tLoss: 400743.343750\n",
      "Train Epoch: 1 [60/1078 (6%)]\tLoss: 512478.437500\n",
      "Train Epoch: 1 [70/1078 (6%)]\tLoss: 403535.281250\n",
      "Train Epoch: 1 [80/1078 (7%)]\tLoss: 364285.250000\n",
      "Train Epoch: 1 [90/1078 (8%)]\tLoss: 454597.843750\n",
      "Train Epoch: 1 [100/1078 (9%)]\tLoss: 380873.437500\n",
      "Train Epoch: 1 [110/1078 (10%)]\tLoss: 494232.562500\n",
      "Train Epoch: 1 [120/1078 (11%)]\tLoss: 540146.375000\n",
      "Train Epoch: 1 [130/1078 (12%)]\tLoss: 514201.093750\n",
      "Train Epoch: 1 [140/1078 (13%)]\tLoss: 326258.062500\n",
      "Train Epoch: 1 [150/1078 (14%)]\tLoss: 380083.312500\n",
      "Train Epoch: 1 [160/1078 (15%)]\tLoss: 427954.281250\n",
      "Train Epoch: 1 [170/1078 (16%)]\tLoss: 423562.406250\n",
      "Train Epoch: 1 [180/1078 (17%)]\tLoss: 548526.312500\n",
      "Train Epoch: 1 [190/1078 (18%)]\tLoss: 490121.406250\n",
      "Train Epoch: 1 [200/1078 (19%)]\tLoss: 456207.812500\n",
      "Train Epoch: 1 [210/1078 (19%)]\tLoss: 505406.375000\n",
      "Train Epoch: 1 [220/1078 (20%)]\tLoss: 314884.281250\n",
      "Train Epoch: 1 [230/1078 (21%)]\tLoss: 391627.562500\n",
      "Train Epoch: 1 [240/1078 (22%)]\tLoss: 321682.281250\n",
      "Train Epoch: 1 [250/1078 (23%)]\tLoss: 490906.500000\n",
      "Train Epoch: 1 [260/1078 (24%)]\tLoss: 498165.187500\n",
      "Train Epoch: 1 [270/1078 (25%)]\tLoss: 268240.687500\n",
      "Train Epoch: 1 [280/1078 (26%)]\tLoss: 564140.437500\n",
      "Train Epoch: 1 [290/1078 (27%)]\tLoss: 518071.875000\n",
      "Train Epoch: 1 [300/1078 (28%)]\tLoss: 474405.937500\n",
      "Train Epoch: 1 [310/1078 (29%)]\tLoss: 546357.000000\n",
      "Train Epoch: 1 [320/1078 (30%)]\tLoss: 483417.843750\n",
      "Train Epoch: 1 [330/1078 (31%)]\tLoss: 448550.781250\n",
      "Train Epoch: 1 [340/1078 (32%)]\tLoss: 286078.062500\n",
      "Train Epoch: 1 [350/1078 (32%)]\tLoss: 496956.000000\n",
      "Train Epoch: 1 [360/1078 (33%)]\tLoss: 516501.843750\n",
      "Train Epoch: 1 [370/1078 (34%)]\tLoss: 255213.671875\n",
      "Train Epoch: 1 [380/1078 (35%)]\tLoss: 327313.031250\n",
      "Train Epoch: 1 [390/1078 (36%)]\tLoss: 366725.218750\n",
      "Train Epoch: 1 [400/1078 (37%)]\tLoss: 558671.500000\n",
      "Train Epoch: 1 [410/1078 (38%)]\tLoss: 378100.156250\n",
      "Train Epoch: 1 [420/1078 (39%)]\tLoss: 451655.281250\n",
      "Train Epoch: 1 [430/1078 (40%)]\tLoss: 406577.656250\n",
      "Train Epoch: 1 [440/1078 (41%)]\tLoss: 466048.656250\n",
      "Train Epoch: 1 [450/1078 (42%)]\tLoss: 565543.250000\n",
      "Train Epoch: 1 [460/1078 (43%)]\tLoss: 520311.500000\n",
      "Train Epoch: 1 [470/1078 (44%)]\tLoss: 560498.187500\n",
      "Train Epoch: 1 [480/1078 (45%)]\tLoss: 263340.156250\n",
      "Train Epoch: 1 [490/1078 (45%)]\tLoss: 393935.250000\n",
      "Train Epoch: 1 [500/1078 (46%)]\tLoss: 304913.406250\n",
      "Train Epoch: 1 [510/1078 (47%)]\tLoss: 412059.000000\n",
      "Train Epoch: 1 [520/1078 (48%)]\tLoss: 440391.687500\n",
      "Train Epoch: 1 [530/1078 (49%)]\tLoss: 464070.406250\n",
      "Train Epoch: 1 [540/1078 (50%)]\tLoss: 400022.468750\n",
      "Train Epoch: 1 [550/1078 (51%)]\tLoss: 520798.937500\n",
      "Train Epoch: 1 [560/1078 (52%)]\tLoss: 358676.312500\n",
      "Train Epoch: 1 [570/1078 (53%)]\tLoss: 503256.187500\n",
      "Train Epoch: 1 [580/1078 (54%)]\tLoss: 418147.968750\n",
      "Train Epoch: 1 [590/1078 (55%)]\tLoss: 394163.406250\n",
      "Train Epoch: 1 [600/1078 (56%)]\tLoss: 541009.687500\n",
      "Train Epoch: 1 [610/1078 (57%)]\tLoss: 472471.843750\n",
      "Train Epoch: 1 [620/1078 (58%)]\tLoss: 443432.093750\n",
      "Train Epoch: 1 [630/1078 (58%)]\tLoss: 336347.062500\n",
      "Train Epoch: 1 [640/1078 (59%)]\tLoss: 557870.250000\n",
      "Train Epoch: 1 [650/1078 (60%)]\tLoss: 366972.187500\n",
      "Train Epoch: 1 [660/1078 (61%)]\tLoss: 481424.531250\n",
      "Train Epoch: 1 [670/1078 (62%)]\tLoss: 506132.312500\n",
      "Train Epoch: 1 [680/1078 (63%)]\tLoss: 491605.843750\n",
      "Train Epoch: 1 [690/1078 (64%)]\tLoss: 479646.843750\n",
      "Train Epoch: 1 [700/1078 (65%)]\tLoss: 537986.125000\n",
      "Train Epoch: 1 [710/1078 (66%)]\tLoss: 371910.937500\n",
      "Train Epoch: 1 [720/1078 (67%)]\tLoss: 525023.562500\n",
      "Train Epoch: 1 [730/1078 (68%)]\tLoss: 505553.281250\n",
      "Train Epoch: 1 [740/1078 (69%)]\tLoss: 483034.718750\n",
      "Train Epoch: 1 [750/1078 (70%)]\tLoss: 532886.125000\n",
      "Train Epoch: 1 [760/1078 (71%)]\tLoss: 374344.562500\n",
      "Train Epoch: 1 [770/1078 (71%)]\tLoss: 425196.625000\n",
      "Train Epoch: 1 [780/1078 (72%)]\tLoss: 532959.250000\n",
      "Train Epoch: 1 [790/1078 (73%)]\tLoss: 542829.750000\n",
      "Train Epoch: 1 [800/1078 (74%)]\tLoss: 525100.875000\n",
      "Train Epoch: 1 [810/1078 (75%)]\tLoss: 508194.343750\n",
      "Train Epoch: 1 [820/1078 (76%)]\tLoss: 289517.531250\n",
      "Train Epoch: 1 [830/1078 (77%)]\tLoss: 444848.781250\n",
      "Train Epoch: 1 [840/1078 (78%)]\tLoss: 551287.625000\n",
      "Train Epoch: 1 [850/1078 (79%)]\tLoss: 494679.343750\n",
      "Train Epoch: 1 [860/1078 (80%)]\tLoss: 499649.656250\n",
      "Train Epoch: 1 [870/1078 (81%)]\tLoss: 491478.093750\n",
      "Train Epoch: 1 [880/1078 (82%)]\tLoss: 425403.562500\n",
      "Train Epoch: 1 [890/1078 (83%)]\tLoss: 469195.875000\n",
      "Train Epoch: 1 [900/1078 (83%)]\tLoss: 347434.406250\n",
      "Train Epoch: 1 [910/1078 (84%)]\tLoss: 489506.968750\n",
      "Train Epoch: 1 [920/1078 (85%)]\tLoss: 302109.906250\n",
      "Train Epoch: 1 [930/1078 (86%)]\tLoss: 321097.750000\n",
      "Train Epoch: 1 [940/1078 (87%)]\tLoss: 504488.812500\n",
      "Train Epoch: 1 [950/1078 (88%)]\tLoss: 528777.500000\n",
      "Train Epoch: 1 [960/1078 (89%)]\tLoss: 604909.125000\n",
      "Train Epoch: 1 [970/1078 (90%)]\tLoss: 541186.062500\n",
      "Train Epoch: 1 [980/1078 (91%)]\tLoss: 355162.875000\n",
      "Train Epoch: 1 [990/1078 (92%)]\tLoss: 401741.531250\n",
      "Train Epoch: 1 [1000/1078 (93%)]\tLoss: 466113.031250\n",
      "Train Epoch: 1 [1010/1078 (94%)]\tLoss: 408109.531250\n",
      "Train Epoch: 1 [1020/1078 (95%)]\tLoss: 535880.500000\n",
      "Train Epoch: 1 [1030/1078 (96%)]\tLoss: 403729.500000\n",
      "Train Epoch: 1 [1040/1078 (96%)]\tLoss: 304444.656250\n",
      "Train Epoch: 1 [1050/1078 (97%)]\tLoss: 367205.187500\n",
      "Train Epoch: 1 [1060/1078 (98%)]\tLoss: 407716.593750\n",
      "Train Epoch: 1 [1070/1078 (99%)]\tLoss: 435997.250000\n",
      "Train Epoch: 2 [0/1078 (0%)]\tLoss: 321277.281250\n",
      "Train Epoch: 2 [10/1078 (1%)]\tLoss: 490123.468750\n",
      "Train Epoch: 2 [20/1078 (2%)]\tLoss: 445784.375000\n",
      "Train Epoch: 2 [30/1078 (3%)]\tLoss: 496416.281250\n",
      "Train Epoch: 2 [40/1078 (4%)]\tLoss: 484196.125000\n",
      "Train Epoch: 2 [50/1078 (5%)]\tLoss: 240323.765625\n",
      "Train Epoch: 2 [60/1078 (6%)]\tLoss: 482720.281250\n",
      "Train Epoch: 2 [70/1078 (6%)]\tLoss: 398110.156250\n",
      "Train Epoch: 2 [80/1078 (7%)]\tLoss: 547135.437500\n",
      "Train Epoch: 2 [90/1078 (8%)]\tLoss: 420019.125000\n",
      "Train Epoch: 2 [100/1078 (9%)]\tLoss: 425245.625000\n",
      "Train Epoch: 2 [110/1078 (10%)]\tLoss: 439095.062500\n",
      "Train Epoch: 2 [120/1078 (11%)]\tLoss: 574176.625000\n",
      "Train Epoch: 2 [130/1078 (12%)]\tLoss: 423225.656250\n",
      "Train Epoch: 2 [140/1078 (13%)]\tLoss: 489509.312500\n",
      "Train Epoch: 2 [150/1078 (14%)]\tLoss: 482197.968750\n",
      "Train Epoch: 2 [160/1078 (15%)]\tLoss: 531944.562500\n",
      "Train Epoch: 2 [170/1078 (16%)]\tLoss: 434444.593750\n",
      "Train Epoch: 2 [180/1078 (17%)]\tLoss: 504064.125000\n",
      "Train Epoch: 2 [190/1078 (18%)]\tLoss: 508324.687500\n",
      "Train Epoch: 2 [200/1078 (19%)]\tLoss: 482069.500000\n",
      "Train Epoch: 2 [210/1078 (19%)]\tLoss: 359180.343750\n",
      "Train Epoch: 2 [220/1078 (20%)]\tLoss: 392212.437500\n",
      "Train Epoch: 2 [230/1078 (21%)]\tLoss: 620411.437500\n",
      "Train Epoch: 2 [240/1078 (22%)]\tLoss: 382711.125000\n",
      "Train Epoch: 2 [250/1078 (23%)]\tLoss: 528173.375000\n",
      "Train Epoch: 2 [260/1078 (24%)]\tLoss: 377340.812500\n",
      "Train Epoch: 2 [270/1078 (25%)]\tLoss: 451040.843750\n",
      "Train Epoch: 2 [280/1078 (26%)]\tLoss: 385502.187500\n",
      "Train Epoch: 2 [290/1078 (27%)]\tLoss: 483370.625000\n",
      "Train Epoch: 2 [300/1078 (28%)]\tLoss: 296898.218750\n",
      "Train Epoch: 2 [310/1078 (29%)]\tLoss: 452335.312500\n",
      "Train Epoch: 2 [320/1078 (30%)]\tLoss: 503150.031250\n",
      "Train Epoch: 2 [330/1078 (31%)]\tLoss: 456937.531250\n",
      "Train Epoch: 2 [340/1078 (32%)]\tLoss: 485067.187500\n",
      "Train Epoch: 2 [350/1078 (32%)]\tLoss: 427680.187500\n",
      "Train Epoch: 2 [360/1078 (33%)]\tLoss: 469745.343750\n",
      "Train Epoch: 2 [370/1078 (34%)]\tLoss: 256251.781250\n",
      "Train Epoch: 2 [380/1078 (35%)]\tLoss: 560975.687500\n",
      "Train Epoch: 2 [390/1078 (36%)]\tLoss: 444848.781250\n",
      "Train Epoch: 2 [400/1078 (37%)]\tLoss: 398187.531250\n",
      "Train Epoch: 2 [410/1078 (38%)]\tLoss: 397655.968750\n",
      "Train Epoch: 2 [420/1078 (39%)]\tLoss: 462446.500000\n",
      "Train Epoch: 2 [430/1078 (40%)]\tLoss: 423693.312500\n",
      "Train Epoch: 2 [440/1078 (41%)]\tLoss: 531763.062500\n",
      "Train Epoch: 2 [450/1078 (42%)]\tLoss: 406119.375000\n",
      "Train Epoch: 2 [460/1078 (43%)]\tLoss: 494732.781250\n",
      "Train Epoch: 2 [470/1078 (44%)]\tLoss: 415659.312500\n",
      "Train Epoch: 2 [480/1078 (45%)]\tLoss: 549581.625000\n",
      "Train Epoch: 2 [490/1078 (45%)]\tLoss: 491179.312500\n",
      "Train Epoch: 2 [500/1078 (46%)]\tLoss: 495310.843750\n",
      "Train Epoch: 2 [510/1078 (47%)]\tLoss: 382289.937500\n",
      "Train Epoch: 2 [520/1078 (48%)]\tLoss: 361472.281250\n",
      "Train Epoch: 2 [530/1078 (49%)]\tLoss: 513116.312500\n",
      "Train Epoch: 2 [540/1078 (50%)]\tLoss: 506920.375000\n",
      "Train Epoch: 2 [550/1078 (51%)]\tLoss: 503738.312500\n",
      "Train Epoch: 2 [560/1078 (52%)]\tLoss: 493312.500000\n",
      "Train Epoch: 2 [570/1078 (53%)]\tLoss: 438752.281250\n",
      "Train Epoch: 2 [580/1078 (54%)]\tLoss: 474570.843750\n",
      "Train Epoch: 2 [590/1078 (55%)]\tLoss: 470207.281250\n",
      "Train Epoch: 2 [600/1078 (56%)]\tLoss: 389444.718750\n",
      "Train Epoch: 2 [610/1078 (57%)]\tLoss: 378897.656250\n",
      "Train Epoch: 2 [620/1078 (58%)]\tLoss: 452364.312500\n",
      "Train Epoch: 2 [630/1078 (58%)]\tLoss: 507872.718750\n",
      "Train Epoch: 2 [640/1078 (59%)]\tLoss: 544153.312500\n",
      "Train Epoch: 2 [650/1078 (60%)]\tLoss: 515670.312500\n",
      "Train Epoch: 2 [660/1078 (61%)]\tLoss: 429001.218750\n",
      "Train Epoch: 2 [670/1078 (62%)]\tLoss: 417881.250000\n",
      "Train Epoch: 2 [680/1078 (63%)]\tLoss: 434544.625000\n",
      "Train Epoch: 2 [690/1078 (64%)]\tLoss: 248430.359375\n",
      "Train Epoch: 2 [700/1078 (65%)]\tLoss: 287404.718750\n",
      "Train Epoch: 2 [710/1078 (66%)]\tLoss: 502554.937500\n",
      "Train Epoch: 2 [720/1078 (67%)]\tLoss: 466111.125000\n",
      "Train Epoch: 2 [730/1078 (68%)]\tLoss: 504744.781250\n",
      "Train Epoch: 2 [740/1078 (69%)]\tLoss: 453965.375000\n",
      "Train Epoch: 2 [750/1078 (70%)]\tLoss: 440453.468750\n",
      "Train Epoch: 2 [760/1078 (71%)]\tLoss: 482302.781250\n",
      "Train Epoch: 2 [770/1078 (71%)]\tLoss: 483335.968750\n",
      "Train Epoch: 2 [780/1078 (72%)]\tLoss: 462467.875000\n",
      "Train Epoch: 2 [790/1078 (73%)]\tLoss: 375480.500000\n",
      "Train Epoch: 2 [800/1078 (74%)]\tLoss: 364027.093750\n",
      "Train Epoch: 2 [810/1078 (75%)]\tLoss: 395366.968750\n",
      "Train Epoch: 2 [820/1078 (76%)]\tLoss: 322950.812500\n",
      "Train Epoch: 2 [830/1078 (77%)]\tLoss: 338832.531250\n",
      "Train Epoch: 2 [840/1078 (78%)]\tLoss: 481472.468750\n",
      "Train Epoch: 2 [850/1078 (79%)]\tLoss: 537372.625000\n",
      "Train Epoch: 2 [860/1078 (80%)]\tLoss: 507492.718750\n",
      "Train Epoch: 2 [870/1078 (81%)]\tLoss: 448862.781250\n",
      "Train Epoch: 2 [880/1078 (82%)]\tLoss: 461758.562500\n",
      "Train Epoch: 2 [890/1078 (83%)]\tLoss: 426770.906250\n",
      "Train Epoch: 2 [900/1078 (83%)]\tLoss: 344733.437500\n",
      "Train Epoch: 2 [910/1078 (84%)]\tLoss: 529520.375000\n",
      "Train Epoch: 2 [920/1078 (85%)]\tLoss: 321211.625000\n",
      "Train Epoch: 2 [930/1078 (86%)]\tLoss: 439437.187500\n",
      "Train Epoch: 2 [940/1078 (87%)]\tLoss: 429346.656250\n",
      "Train Epoch: 2 [950/1078 (88%)]\tLoss: 351353.500000\n",
      "Train Epoch: 2 [960/1078 (89%)]\tLoss: 543987.750000\n",
      "Train Epoch: 2 [970/1078 (90%)]\tLoss: 557668.500000\n",
      "Train Epoch: 2 [980/1078 (91%)]\tLoss: 411944.031250\n",
      "Train Epoch: 2 [990/1078 (92%)]\tLoss: 276113.718750\n",
      "Train Epoch: 2 [1000/1078 (93%)]\tLoss: 534772.750000\n",
      "Train Epoch: 2 [1010/1078 (94%)]\tLoss: 403650.062500\n",
      "Train Epoch: 2 [1020/1078 (95%)]\tLoss: 506185.531250\n",
      "Train Epoch: 2 [1030/1078 (96%)]\tLoss: 360402.000000\n",
      "Train Epoch: 2 [1040/1078 (96%)]\tLoss: 419616.562500\n",
      "Train Epoch: 2 [1050/1078 (97%)]\tLoss: 427389.906250\n",
      "Train Epoch: 2 [1060/1078 (98%)]\tLoss: 339645.281250\n",
      "Train Epoch: 2 [1070/1078 (99%)]\tLoss: 410252.187500\n",
      "Train Epoch: 3 [0/1078 (0%)]\tLoss: 416221.468750\n",
      "Train Epoch: 3 [10/1078 (1%)]\tLoss: 373030.937500\n",
      "Train Epoch: 3 [20/1078 (2%)]\tLoss: 554236.687500\n",
      "Train Epoch: 3 [30/1078 (3%)]\tLoss: 470512.531250\n",
      "Train Epoch: 3 [40/1078 (4%)]\tLoss: 450777.187500\n",
      "Train Epoch: 3 [50/1078 (5%)]\tLoss: 468042.687500\n",
      "Train Epoch: 3 [60/1078 (6%)]\tLoss: 534572.562500\n",
      "Train Epoch: 3 [70/1078 (6%)]\tLoss: 485906.000000\n",
      "Train Epoch: 3 [80/1078 (7%)]\tLoss: 595784.937500\n",
      "Train Epoch: 3 [90/1078 (8%)]\tLoss: 391737.343750\n",
      "Train Epoch: 3 [100/1078 (9%)]\tLoss: 322187.500000\n",
      "Train Epoch: 3 [110/1078 (10%)]\tLoss: 478564.000000\n",
      "Train Epoch: 3 [120/1078 (11%)]\tLoss: 395866.812500\n",
      "Train Epoch: 3 [130/1078 (12%)]\tLoss: 410808.781250\n",
      "Train Epoch: 3 [140/1078 (13%)]\tLoss: 594584.062500\n",
      "Train Epoch: 3 [150/1078 (14%)]\tLoss: 401591.125000\n",
      "Train Epoch: 3 [160/1078 (15%)]\tLoss: 395004.187500\n",
      "Train Epoch: 3 [170/1078 (16%)]\tLoss: 432204.218750\n",
      "Train Epoch: 3 [180/1078 (17%)]\tLoss: 444150.062500\n",
      "Train Epoch: 3 [190/1078 (18%)]\tLoss: 586987.875000\n",
      "Train Epoch: 3 [200/1078 (19%)]\tLoss: 452259.000000\n",
      "Train Epoch: 3 [210/1078 (19%)]\tLoss: 409611.875000\n",
      "Train Epoch: 3 [220/1078 (20%)]\tLoss: 578383.812500\n",
      "Train Epoch: 3 [230/1078 (21%)]\tLoss: 433146.812500\n",
      "Train Epoch: 3 [240/1078 (22%)]\tLoss: 379413.718750\n",
      "Train Epoch: 3 [250/1078 (23%)]\tLoss: 473032.031250\n",
      "Train Epoch: 3 [260/1078 (24%)]\tLoss: 301925.281250\n",
      "Train Epoch: 3 [270/1078 (25%)]\tLoss: 317875.281250\n",
      "Train Epoch: 3 [280/1078 (26%)]\tLoss: 471582.968750\n",
      "Train Epoch: 3 [290/1078 (27%)]\tLoss: 380061.468750\n",
      "Train Epoch: 3 [300/1078 (28%)]\tLoss: 480860.937500\n",
      "Train Epoch: 3 [310/1078 (29%)]\tLoss: 505707.375000\n",
      "Train Epoch: 3 [320/1078 (30%)]\tLoss: 445887.125000\n",
      "Train Epoch: 3 [330/1078 (31%)]\tLoss: 447718.875000\n",
      "Train Epoch: 3 [340/1078 (32%)]\tLoss: 332947.312500\n",
      "Train Epoch: 3 [350/1078 (32%)]\tLoss: 470546.593750\n",
      "Train Epoch: 3 [360/1078 (33%)]\tLoss: 708737.375000\n",
      "Train Epoch: 3 [370/1078 (34%)]\tLoss: 536539.437500\n",
      "Train Epoch: 3 [380/1078 (35%)]\tLoss: 426077.781250\n",
      "Train Epoch: 3 [390/1078 (36%)]\tLoss: 454254.031250\n",
      "Train Epoch: 3 [400/1078 (37%)]\tLoss: 355160.343750\n",
      "Train Epoch: 3 [410/1078 (38%)]\tLoss: 460375.625000\n",
      "Train Epoch: 3 [420/1078 (39%)]\tLoss: 540464.312500\n",
      "Train Epoch: 3 [430/1078 (40%)]\tLoss: 507671.406250\n",
      "Train Epoch: 3 [440/1078 (41%)]\tLoss: 536019.812500\n",
      "Train Epoch: 3 [450/1078 (42%)]\tLoss: 510053.406250\n",
      "Train Epoch: 3 [460/1078 (43%)]\tLoss: 360805.750000\n",
      "Train Epoch: 3 [470/1078 (44%)]\tLoss: 558327.312500\n",
      "Train Epoch: 3 [480/1078 (45%)]\tLoss: 339017.312500\n",
      "Train Epoch: 3 [490/1078 (45%)]\tLoss: 524874.812500\n",
      "Train Epoch: 3 [500/1078 (46%)]\tLoss: 258876.015625\n",
      "Train Epoch: 3 [510/1078 (47%)]\tLoss: 500177.875000\n",
      "Train Epoch: 3 [520/1078 (48%)]\tLoss: 495623.500000\n",
      "Train Epoch: 3 [530/1078 (49%)]\tLoss: 482055.968750\n",
      "Train Epoch: 3 [540/1078 (50%)]\tLoss: 516386.656250\n",
      "Train Epoch: 3 [550/1078 (51%)]\tLoss: 434920.718750\n",
      "Train Epoch: 3 [560/1078 (52%)]\tLoss: 492218.750000\n",
      "Train Epoch: 3 [570/1078 (53%)]\tLoss: 448233.906250\n",
      "Train Epoch: 3 [580/1078 (54%)]\tLoss: 407424.593750\n",
      "Train Epoch: 3 [590/1078 (55%)]\tLoss: 497598.687500\n",
      "Train Epoch: 3 [600/1078 (56%)]\tLoss: 511183.156250\n",
      "Train Epoch: 3 [610/1078 (57%)]\tLoss: 480980.906250\n",
      "Train Epoch: 3 [620/1078 (58%)]\tLoss: 414409.312500\n",
      "Train Epoch: 3 [630/1078 (58%)]\tLoss: 503477.343750\n",
      "Train Epoch: 3 [640/1078 (59%)]\tLoss: 355160.656250\n",
      "Train Epoch: 3 [650/1078 (60%)]\tLoss: 511997.531250\n",
      "Train Epoch: 3 [660/1078 (61%)]\tLoss: 505088.875000\n",
      "Train Epoch: 3 [670/1078 (62%)]\tLoss: 399260.031250\n",
      "Train Epoch: 3 [680/1078 (63%)]\tLoss: 360815.843750\n",
      "Train Epoch: 3 [690/1078 (64%)]\tLoss: 498759.406250\n",
      "Train Epoch: 3 [700/1078 (65%)]\tLoss: 428595.312500\n",
      "Train Epoch: 3 [710/1078 (66%)]\tLoss: 494336.031250\n",
      "Train Epoch: 3 [720/1078 (67%)]\tLoss: 410824.500000\n",
      "Train Epoch: 3 [730/1078 (68%)]\tLoss: 507467.968750\n",
      "Train Epoch: 3 [740/1078 (69%)]\tLoss: 531535.937500\n",
      "Train Epoch: 3 [750/1078 (70%)]\tLoss: 493537.625000\n",
      "Train Epoch: 3 [760/1078 (71%)]\tLoss: 462353.281250\n",
      "Train Epoch: 3 [770/1078 (71%)]\tLoss: 524631.562500\n",
      "Train Epoch: 3 [780/1078 (72%)]\tLoss: 405435.343750\n",
      "Train Epoch: 3 [790/1078 (73%)]\tLoss: 411151.937500\n",
      "Train Epoch: 3 [800/1078 (74%)]\tLoss: 295615.375000\n",
      "Train Epoch: 3 [810/1078 (75%)]\tLoss: 470625.218750\n",
      "Train Epoch: 3 [820/1078 (76%)]\tLoss: 416358.593750\n",
      "Train Epoch: 3 [830/1078 (77%)]\tLoss: 301898.062500\n",
      "Train Epoch: 3 [840/1078 (78%)]\tLoss: 415165.093750\n",
      "Train Epoch: 3 [850/1078 (79%)]\tLoss: 458318.218750\n",
      "Train Epoch: 3 [860/1078 (80%)]\tLoss: 427785.593750\n",
      "Train Epoch: 3 [870/1078 (81%)]\tLoss: 556893.500000\n",
      "Train Epoch: 3 [880/1078 (82%)]\tLoss: 336790.687500\n",
      "Train Epoch: 3 [890/1078 (83%)]\tLoss: 299441.812500\n",
      "Train Epoch: 3 [900/1078 (83%)]\tLoss: 464620.156250\n",
      "Train Epoch: 3 [910/1078 (84%)]\tLoss: 460804.343750\n",
      "Train Epoch: 3 [920/1078 (85%)]\tLoss: 281858.093750\n",
      "Train Epoch: 3 [930/1078 (86%)]\tLoss: 362147.156250\n",
      "Train Epoch: 3 [940/1078 (87%)]\tLoss: 474116.593750\n",
      "Train Epoch: 3 [950/1078 (88%)]\tLoss: 349224.218750\n",
      "Train Epoch: 3 [960/1078 (89%)]\tLoss: 466978.031250\n",
      "Train Epoch: 3 [970/1078 (90%)]\tLoss: 505408.375000\n",
      "Train Epoch: 3 [980/1078 (91%)]\tLoss: 463614.875000\n",
      "Train Epoch: 3 [990/1078 (92%)]\tLoss: 428255.500000\n",
      "Train Epoch: 3 [1000/1078 (93%)]\tLoss: 460479.062500\n",
      "Train Epoch: 3 [1010/1078 (94%)]\tLoss: 501743.625000\n",
      "Train Epoch: 3 [1020/1078 (95%)]\tLoss: 347233.968750\n",
      "Train Epoch: 3 [1030/1078 (96%)]\tLoss: 362085.531250\n",
      "Train Epoch: 3 [1040/1078 (96%)]\tLoss: 384586.031250\n",
      "Train Epoch: 3 [1050/1078 (97%)]\tLoss: 563741.812500\n",
      "Train Epoch: 3 [1060/1078 (98%)]\tLoss: 348550.718750\n",
      "Train Epoch: 3 [1070/1078 (99%)]\tLoss: 484664.812500\n",
      "Train Epoch: 4 [0/1078 (0%)]\tLoss: 383838.500000\n",
      "Train Epoch: 4 [10/1078 (1%)]\tLoss: 488681.937500\n",
      "Train Epoch: 4 [20/1078 (2%)]\tLoss: 281798.812500\n",
      "Train Epoch: 4 [30/1078 (3%)]\tLoss: 371862.843750\n",
      "Train Epoch: 4 [40/1078 (4%)]\tLoss: 400067.281250\n",
      "Train Epoch: 4 [50/1078 (5%)]\tLoss: 514642.125000\n",
      "Train Epoch: 4 [60/1078 (6%)]\tLoss: 529655.562500\n",
      "Train Epoch: 4 [70/1078 (6%)]\tLoss: 368082.687500\n",
      "Train Epoch: 4 [80/1078 (7%)]\tLoss: 524420.375000\n",
      "Train Epoch: 4 [90/1078 (8%)]\tLoss: 442918.906250\n",
      "Train Epoch: 4 [100/1078 (9%)]\tLoss: 414033.843750\n",
      "Train Epoch: 4 [110/1078 (10%)]\tLoss: 539803.562500\n",
      "Train Epoch: 4 [120/1078 (11%)]\tLoss: 519580.531250\n",
      "Train Epoch: 4 [130/1078 (12%)]\tLoss: 435864.781250\n",
      "Train Epoch: 4 [140/1078 (13%)]\tLoss: 508171.593750\n",
      "Train Epoch: 4 [150/1078 (14%)]\tLoss: 461580.406250\n",
      "Train Epoch: 4 [160/1078 (15%)]\tLoss: 263759.656250\n",
      "Train Epoch: 4 [170/1078 (16%)]\tLoss: 483952.562500\n",
      "Train Epoch: 4 [180/1078 (17%)]\tLoss: 522900.968750\n",
      "Train Epoch: 4 [190/1078 (18%)]\tLoss: 461458.500000\n",
      "Train Epoch: 4 [200/1078 (19%)]\tLoss: 424838.187500\n",
      "Train Epoch: 4 [210/1078 (19%)]\tLoss: 437491.125000\n",
      "Train Epoch: 4 [220/1078 (20%)]\tLoss: 441802.812500\n",
      "Train Epoch: 4 [230/1078 (21%)]\tLoss: 437795.593750\n",
      "Train Epoch: 4 [240/1078 (22%)]\tLoss: 367359.656250\n",
      "Train Epoch: 4 [250/1078 (23%)]\tLoss: 467712.906250\n",
      "Train Epoch: 4 [260/1078 (24%)]\tLoss: 482611.531250\n",
      "Train Epoch: 4 [270/1078 (25%)]\tLoss: 468994.750000\n",
      "Train Epoch: 4 [280/1078 (26%)]\tLoss: 434344.937500\n",
      "Train Epoch: 4 [290/1078 (27%)]\tLoss: 508229.093750\n",
      "Train Epoch: 4 [300/1078 (28%)]\tLoss: 309345.906250\n",
      "Train Epoch: 4 [310/1078 (29%)]\tLoss: 398415.593750\n",
      "Train Epoch: 4 [320/1078 (30%)]\tLoss: 521684.968750\n",
      "Train Epoch: 4 [330/1078 (31%)]\tLoss: 353109.718750\n",
      "Train Epoch: 4 [340/1078 (32%)]\tLoss: 447404.781250\n",
      "Train Epoch: 4 [350/1078 (32%)]\tLoss: 502491.875000\n",
      "Train Epoch: 4 [360/1078 (33%)]\tLoss: 470146.437500\n",
      "Train Epoch: 4 [370/1078 (34%)]\tLoss: 556803.500000\n",
      "Train Epoch: 4 [380/1078 (35%)]\tLoss: 270585.625000\n",
      "Train Epoch: 4 [390/1078 (36%)]\tLoss: 431297.000000\n",
      "Train Epoch: 4 [400/1078 (37%)]\tLoss: 320526.437500\n",
      "Train Epoch: 4 [410/1078 (38%)]\tLoss: 420105.500000\n",
      "Train Epoch: 4 [420/1078 (39%)]\tLoss: 462155.875000\n",
      "Train Epoch: 4 [430/1078 (40%)]\tLoss: 556073.625000\n",
      "Train Epoch: 4 [440/1078 (41%)]\tLoss: 426388.656250\n",
      "Train Epoch: 4 [450/1078 (42%)]\tLoss: 485891.312500\n",
      "Train Epoch: 4 [460/1078 (43%)]\tLoss: 417522.687500\n",
      "Train Epoch: 4 [470/1078 (44%)]\tLoss: 372090.968750\n",
      "Train Epoch: 4 [480/1078 (45%)]\tLoss: 498019.281250\n",
      "Train Epoch: 4 [490/1078 (45%)]\tLoss: 514926.375000\n",
      "Train Epoch: 4 [500/1078 (46%)]\tLoss: 490288.437500\n",
      "Train Epoch: 4 [510/1078 (47%)]\tLoss: 532717.437500\n",
      "Train Epoch: 4 [520/1078 (48%)]\tLoss: 543784.062500\n",
      "Train Epoch: 4 [530/1078 (49%)]\tLoss: 314797.406250\n",
      "Train Epoch: 4 [540/1078 (50%)]\tLoss: 360828.718750\n",
      "Train Epoch: 4 [550/1078 (51%)]\tLoss: 478561.781250\n",
      "Train Epoch: 4 [560/1078 (52%)]\tLoss: 368390.593750\n",
      "Train Epoch: 4 [570/1078 (53%)]\tLoss: 496829.281250\n",
      "Train Epoch: 4 [580/1078 (54%)]\tLoss: 499394.593750\n",
      "Train Epoch: 4 [590/1078 (55%)]\tLoss: 422543.000000\n",
      "Train Epoch: 4 [600/1078 (56%)]\tLoss: 471571.781250\n",
      "Train Epoch: 4 [610/1078 (57%)]\tLoss: 495940.125000\n",
      "Train Epoch: 4 [620/1078 (58%)]\tLoss: 527477.250000\n",
      "Train Epoch: 4 [630/1078 (58%)]\tLoss: 471432.187500\n",
      "Train Epoch: 4 [640/1078 (59%)]\tLoss: 366464.125000\n",
      "Train Epoch: 4 [650/1078 (60%)]\tLoss: 273444.593750\n",
      "Train Epoch: 4 [660/1078 (61%)]\tLoss: 436650.937500\n",
      "Train Epoch: 4 [670/1078 (62%)]\tLoss: 495991.875000\n",
      "Train Epoch: 4 [680/1078 (63%)]\tLoss: 486204.031250\n",
      "Train Epoch: 4 [690/1078 (64%)]\tLoss: 409103.406250\n",
      "Train Epoch: 4 [700/1078 (65%)]\tLoss: 453707.750000\n",
      "Train Epoch: 4 [710/1078 (66%)]\tLoss: 313846.218750\n",
      "Train Epoch: 4 [720/1078 (67%)]\tLoss: 443313.687500\n",
      "Train Epoch: 4 [730/1078 (68%)]\tLoss: 611538.250000\n",
      "Train Epoch: 4 [740/1078 (69%)]\tLoss: 430161.093750\n",
      "Train Epoch: 4 [750/1078 (70%)]\tLoss: 504993.562500\n",
      "Train Epoch: 4 [760/1078 (71%)]\tLoss: 457928.375000\n",
      "Train Epoch: 4 [770/1078 (71%)]\tLoss: 497119.718750\n",
      "Train Epoch: 4 [780/1078 (72%)]\tLoss: 320144.156250\n",
      "Train Epoch: 4 [790/1078 (73%)]\tLoss: 438344.531250\n",
      "Train Epoch: 4 [800/1078 (74%)]\tLoss: 416321.312500\n",
      "Train Epoch: 4 [810/1078 (75%)]\tLoss: 540777.062500\n",
      "Train Epoch: 4 [820/1078 (76%)]\tLoss: 470707.218750\n",
      "Train Epoch: 4 [830/1078 (77%)]\tLoss: 447898.687500\n",
      "Train Epoch: 4 [840/1078 (78%)]\tLoss: 463210.125000\n",
      "Train Epoch: 4 [850/1078 (79%)]\tLoss: 484613.968750\n",
      "Train Epoch: 4 [860/1078 (80%)]\tLoss: 377116.500000\n",
      "Train Epoch: 4 [870/1078 (81%)]\tLoss: 501036.343750\n",
      "Train Epoch: 4 [880/1078 (82%)]\tLoss: 504644.750000\n",
      "Train Epoch: 4 [890/1078 (83%)]\tLoss: 487813.531250\n",
      "Train Epoch: 4 [900/1078 (83%)]\tLoss: 504359.000000\n",
      "Train Epoch: 4 [910/1078 (84%)]\tLoss: 480979.000000\n",
      "Train Epoch: 4 [920/1078 (85%)]\tLoss: 444699.562500\n",
      "Train Epoch: 4 [930/1078 (86%)]\tLoss: 456810.625000\n",
      "Train Epoch: 4 [940/1078 (87%)]\tLoss: 415285.718750\n",
      "Train Epoch: 4 [950/1078 (88%)]\tLoss: 371475.562500\n",
      "Train Epoch: 4 [960/1078 (89%)]\tLoss: 522141.218750\n",
      "Train Epoch: 4 [970/1078 (90%)]\tLoss: 303700.156250\n",
      "Train Epoch: 4 [980/1078 (91%)]\tLoss: 453269.437500\n",
      "Train Epoch: 4 [990/1078 (92%)]\tLoss: 474348.656250\n",
      "Train Epoch: 4 [1000/1078 (93%)]\tLoss: 508721.562500\n",
      "Train Epoch: 4 [1010/1078 (94%)]\tLoss: 454609.125000\n",
      "Train Epoch: 4 [1020/1078 (95%)]\tLoss: 408035.625000\n",
      "Train Epoch: 4 [1030/1078 (96%)]\tLoss: 349120.406250\n",
      "Train Epoch: 4 [1040/1078 (96%)]\tLoss: 377325.437500\n",
      "Train Epoch: 4 [1050/1078 (97%)]\tLoss: 455195.250000\n",
      "Train Epoch: 4 [1060/1078 (98%)]\tLoss: 463706.250000\n",
      "Train Epoch: 4 [1070/1078 (99%)]\tLoss: 503255.156250\n",
      "Train Epoch: 5 [0/1078 (0%)]\tLoss: 387805.593750\n",
      "Train Epoch: 5 [10/1078 (1%)]\tLoss: 460522.750000\n",
      "Train Epoch: 5 [20/1078 (2%)]\tLoss: 526404.750000\n",
      "Train Epoch: 5 [30/1078 (3%)]\tLoss: 493963.125000\n",
      "Train Epoch: 5 [40/1078 (4%)]\tLoss: 400356.656250\n",
      "Train Epoch: 5 [50/1078 (5%)]\tLoss: 561260.062500\n",
      "Train Epoch: 5 [60/1078 (6%)]\tLoss: 524273.156250\n",
      "Train Epoch: 5 [70/1078 (6%)]\tLoss: 447682.468750\n",
      "Train Epoch: 5 [80/1078 (7%)]\tLoss: 352657.656250\n",
      "Train Epoch: 5 [90/1078 (8%)]\tLoss: 526083.187500\n",
      "Train Epoch: 5 [100/1078 (9%)]\tLoss: 500213.156250\n",
      "Train Epoch: 5 [110/1078 (10%)]\tLoss: 369225.156250\n",
      "Train Epoch: 5 [120/1078 (11%)]\tLoss: 358790.843750\n",
      "Train Epoch: 5 [130/1078 (12%)]\tLoss: 527253.062500\n",
      "Train Epoch: 5 [140/1078 (13%)]\tLoss: 402257.375000\n",
      "Train Epoch: 5 [150/1078 (14%)]\tLoss: 523466.281250\n",
      "Train Epoch: 5 [160/1078 (15%)]\tLoss: 248189.281250\n",
      "Train Epoch: 5 [170/1078 (16%)]\tLoss: 493286.750000\n",
      "Train Epoch: 5 [180/1078 (17%)]\tLoss: 334480.500000\n",
      "Train Epoch: 5 [190/1078 (18%)]\tLoss: 307027.906250\n",
      "Train Epoch: 5 [200/1078 (19%)]\tLoss: 340202.375000\n",
      "Train Epoch: 5 [210/1078 (19%)]\tLoss: 483405.843750\n",
      "Train Epoch: 5 [220/1078 (20%)]\tLoss: 529914.312500\n",
      "Train Epoch: 5 [230/1078 (21%)]\tLoss: 394574.500000\n",
      "Train Epoch: 5 [240/1078 (22%)]\tLoss: 482883.875000\n",
      "Train Epoch: 5 [250/1078 (23%)]\tLoss: 313947.062500\n",
      "Train Epoch: 5 [260/1078 (24%)]\tLoss: 406552.125000\n",
      "Train Epoch: 5 [270/1078 (25%)]\tLoss: 544586.437500\n",
      "Train Epoch: 5 [280/1078 (26%)]\tLoss: 534361.562500\n",
      "Train Epoch: 5 [290/1078 (27%)]\tLoss: 532012.687500\n",
      "Train Epoch: 5 [300/1078 (28%)]\tLoss: 481226.718750\n",
      "Train Epoch: 5 [310/1078 (29%)]\tLoss: 451255.687500\n",
      "Train Epoch: 5 [320/1078 (30%)]\tLoss: 484278.125000\n",
      "Train Epoch: 5 [330/1078 (31%)]\tLoss: 460865.437500\n",
      "Train Epoch: 5 [340/1078 (32%)]\tLoss: 566409.937500\n",
      "Train Epoch: 5 [350/1078 (32%)]\tLoss: 487660.218750\n",
      "Train Epoch: 5 [360/1078 (33%)]\tLoss: 389902.218750\n",
      "Train Epoch: 5 [370/1078 (34%)]\tLoss: 418747.937500\n",
      "Train Epoch: 5 [380/1078 (35%)]\tLoss: 459127.500000\n",
      "Train Epoch: 5 [390/1078 (36%)]\tLoss: 526976.125000\n",
      "Train Epoch: 5 [400/1078 (37%)]\tLoss: 571650.625000\n",
      "Train Epoch: 5 [410/1078 (38%)]\tLoss: 414340.812500\n",
      "Train Epoch: 5 [420/1078 (39%)]\tLoss: 539223.375000\n",
      "Train Epoch: 5 [430/1078 (40%)]\tLoss: 449888.000000\n",
      "Train Epoch: 5 [440/1078 (41%)]\tLoss: 517128.812500\n",
      "Train Epoch: 5 [450/1078 (42%)]\tLoss: 469844.562500\n",
      "Train Epoch: 5 [460/1078 (43%)]\tLoss: 407324.281250\n",
      "Train Epoch: 5 [470/1078 (44%)]\tLoss: 422212.093750\n",
      "Train Epoch: 5 [480/1078 (45%)]\tLoss: 555655.750000\n",
      "Train Epoch: 5 [490/1078 (45%)]\tLoss: 481771.968750\n",
      "Train Epoch: 5 [500/1078 (46%)]\tLoss: 514335.281250\n",
      "Train Epoch: 5 [510/1078 (47%)]\tLoss: 567604.375000\n",
      "Train Epoch: 5 [520/1078 (48%)]\tLoss: 462753.968750\n",
      "Train Epoch: 5 [530/1078 (49%)]\tLoss: 520150.906250\n",
      "Train Epoch: 5 [540/1078 (50%)]\tLoss: 439916.125000\n",
      "Train Epoch: 5 [550/1078 (51%)]\tLoss: 445279.781250\n",
      "Train Epoch: 5 [560/1078 (52%)]\tLoss: 498413.250000\n",
      "Train Epoch: 5 [570/1078 (53%)]\tLoss: 396439.968750\n",
      "Train Epoch: 5 [580/1078 (54%)]\tLoss: 439339.718750\n",
      "Train Epoch: 5 [590/1078 (55%)]\tLoss: 415162.312500\n",
      "Train Epoch: 5 [600/1078 (56%)]\tLoss: 425600.375000\n",
      "Train Epoch: 5 [610/1078 (57%)]\tLoss: 464935.656250\n",
      "Train Epoch: 5 [620/1078 (58%)]\tLoss: 483091.843750\n",
      "Train Epoch: 5 [630/1078 (58%)]\tLoss: 421094.593750\n",
      "Train Epoch: 5 [640/1078 (59%)]\tLoss: 419019.156250\n",
      "Train Epoch: 5 [650/1078 (60%)]\tLoss: 453057.625000\n",
      "Train Epoch: 5 [660/1078 (61%)]\tLoss: 314329.843750\n",
      "Train Epoch: 5 [670/1078 (62%)]\tLoss: 292395.906250\n",
      "Train Epoch: 5 [680/1078 (63%)]\tLoss: 300210.343750\n",
      "Train Epoch: 5 [690/1078 (64%)]\tLoss: 387568.968750\n",
      "Train Epoch: 5 [700/1078 (65%)]\tLoss: 286840.218750\n",
      "Train Epoch: 5 [710/1078 (66%)]\tLoss: 444041.750000\n",
      "Train Epoch: 5 [720/1078 (67%)]\tLoss: 443751.468750\n",
      "Train Epoch: 5 [730/1078 (68%)]\tLoss: 387334.343750\n",
      "Train Epoch: 5 [740/1078 (69%)]\tLoss: 437511.500000\n",
      "Train Epoch: 5 [750/1078 (70%)]\tLoss: 297258.437500\n",
      "Train Epoch: 5 [760/1078 (71%)]\tLoss: 394257.656250\n",
      "Train Epoch: 5 [770/1078 (71%)]\tLoss: 499790.718750\n",
      "Train Epoch: 5 [780/1078 (72%)]\tLoss: 400752.187500\n",
      "Train Epoch: 5 [790/1078 (73%)]\tLoss: 405949.437500\n",
      "Train Epoch: 5 [800/1078 (74%)]\tLoss: 323980.687500\n",
      "Train Epoch: 5 [810/1078 (75%)]\tLoss: 483563.781250\n",
      "Train Epoch: 5 [820/1078 (76%)]\tLoss: 500301.375000\n",
      "Train Epoch: 5 [830/1078 (77%)]\tLoss: 398410.718750\n",
      "Train Epoch: 5 [840/1078 (78%)]\tLoss: 501336.406250\n",
      "Train Epoch: 5 [850/1078 (79%)]\tLoss: 465813.250000\n",
      "Train Epoch: 5 [860/1078 (80%)]\tLoss: 497721.125000\n",
      "Train Epoch: 5 [870/1078 (81%)]\tLoss: 426665.687500\n",
      "Train Epoch: 5 [880/1078 (82%)]\tLoss: 301735.031250\n",
      "Train Epoch: 5 [890/1078 (83%)]\tLoss: 463068.312500\n",
      "Train Epoch: 5 [900/1078 (83%)]\tLoss: 358677.937500\n",
      "Train Epoch: 5 [910/1078 (84%)]\tLoss: 478314.906250\n",
      "Train Epoch: 5 [920/1078 (85%)]\tLoss: 467805.250000\n",
      "Train Epoch: 5 [930/1078 (86%)]\tLoss: 548071.000000\n",
      "Train Epoch: 5 [940/1078 (87%)]\tLoss: 551476.750000\n",
      "Train Epoch: 5 [950/1078 (88%)]\tLoss: 438374.718750\n",
      "Train Epoch: 5 [960/1078 (89%)]\tLoss: 503292.531250\n",
      "Train Epoch: 5 [970/1078 (90%)]\tLoss: 477456.093750\n",
      "Train Epoch: 5 [980/1078 (91%)]\tLoss: 353935.937500\n",
      "Train Epoch: 5 [990/1078 (92%)]\tLoss: 487433.093750\n",
      "Train Epoch: 5 [1000/1078 (93%)]\tLoss: 414202.125000\n",
      "Train Epoch: 5 [1010/1078 (94%)]\tLoss: 375975.625000\n",
      "Train Epoch: 5 [1020/1078 (95%)]\tLoss: 349437.906250\n",
      "Train Epoch: 5 [1030/1078 (96%)]\tLoss: 460740.781250\n",
      "Train Epoch: 5 [1040/1078 (96%)]\tLoss: 466469.343750\n",
      "Train Epoch: 5 [1050/1078 (97%)]\tLoss: 376251.718750\n",
      "Train Epoch: 5 [1060/1078 (98%)]\tLoss: 406168.500000\n",
      "Train Epoch: 5 [1070/1078 (99%)]\tLoss: 474543.593750\n",
      "Train Epoch: 6 [0/1078 (0%)]\tLoss: 522977.250000\n",
      "Train Epoch: 6 [10/1078 (1%)]\tLoss: 449954.062500\n",
      "Train Epoch: 6 [20/1078 (2%)]\tLoss: 464721.656250\n",
      "Train Epoch: 6 [30/1078 (3%)]\tLoss: 384507.968750\n",
      "Train Epoch: 6 [40/1078 (4%)]\tLoss: 430573.281250\n",
      "Train Epoch: 6 [50/1078 (5%)]\tLoss: 390952.437500\n",
      "Train Epoch: 6 [60/1078 (6%)]\tLoss: 347978.750000\n",
      "Train Epoch: 6 [70/1078 (6%)]\tLoss: 386444.781250\n",
      "Train Epoch: 6 [80/1078 (7%)]\tLoss: 518108.968750\n",
      "Train Epoch: 6 [90/1078 (8%)]\tLoss: 570518.437500\n",
      "Train Epoch: 6 [100/1078 (9%)]\tLoss: 592659.187500\n",
      "Train Epoch: 6 [110/1078 (10%)]\tLoss: 369987.187500\n",
      "Train Epoch: 6 [120/1078 (11%)]\tLoss: 476247.656250\n",
      "Train Epoch: 6 [130/1078 (12%)]\tLoss: 454204.781250\n",
      "Train Epoch: 6 [140/1078 (13%)]\tLoss: 522504.875000\n",
      "Train Epoch: 6 [150/1078 (14%)]\tLoss: 392458.500000\n",
      "Train Epoch: 6 [160/1078 (15%)]\tLoss: 388275.312500\n",
      "Train Epoch: 6 [170/1078 (16%)]\tLoss: 489043.562500\n",
      "Train Epoch: 6 [180/1078 (17%)]\tLoss: 527891.250000\n",
      "Train Epoch: 6 [190/1078 (18%)]\tLoss: 357409.593750\n",
      "Train Epoch: 6 [200/1078 (19%)]\tLoss: 398405.750000\n",
      "Train Epoch: 6 [210/1078 (19%)]\tLoss: 334861.750000\n",
      "Train Epoch: 6 [220/1078 (20%)]\tLoss: 568255.562500\n",
      "Train Epoch: 6 [230/1078 (21%)]\tLoss: 521222.250000\n",
      "Train Epoch: 6 [240/1078 (22%)]\tLoss: 480914.656250\n",
      "Train Epoch: 6 [250/1078 (23%)]\tLoss: 409249.000000\n",
      "Train Epoch: 6 [260/1078 (24%)]\tLoss: 372603.187500\n",
      "Train Epoch: 6 [270/1078 (25%)]\tLoss: 558145.812500\n",
      "Train Epoch: 6 [280/1078 (26%)]\tLoss: 481864.875000\n",
      "Train Epoch: 6 [290/1078 (27%)]\tLoss: 533400.812500\n",
      "Train Epoch: 6 [300/1078 (28%)]\tLoss: 315912.687500\n",
      "Train Epoch: 6 [310/1078 (29%)]\tLoss: 404226.968750\n",
      "Train Epoch: 6 [320/1078 (30%)]\tLoss: 502652.031250\n",
      "Train Epoch: 6 [330/1078 (31%)]\tLoss: 445140.718750\n",
      "Train Epoch: 6 [340/1078 (32%)]\tLoss: 562826.812500\n",
      "Train Epoch: 6 [350/1078 (32%)]\tLoss: 362309.156250\n",
      "Train Epoch: 6 [360/1078 (33%)]\tLoss: 419063.531250\n",
      "Train Epoch: 6 [370/1078 (34%)]\tLoss: 412875.281250\n",
      "Train Epoch: 6 [380/1078 (35%)]\tLoss: 407972.031250\n",
      "Train Epoch: 6 [390/1078 (36%)]\tLoss: 425986.812500\n",
      "Train Epoch: 6 [400/1078 (37%)]\tLoss: 462390.156250\n",
      "Train Epoch: 6 [410/1078 (38%)]\tLoss: 469413.281250\n",
      "Train Epoch: 6 [420/1078 (39%)]\tLoss: 531018.375000\n",
      "Train Epoch: 6 [430/1078 (40%)]\tLoss: 436785.843750\n",
      "Train Epoch: 6 [440/1078 (41%)]\tLoss: 392437.250000\n",
      "Train Epoch: 6 [450/1078 (42%)]\tLoss: 390423.593750\n",
      "Train Epoch: 6 [460/1078 (43%)]\tLoss: 589792.250000\n",
      "Train Epoch: 6 [470/1078 (44%)]\tLoss: 355167.625000\n",
      "Train Epoch: 6 [480/1078 (45%)]\tLoss: 379871.781250\n",
      "Train Epoch: 6 [490/1078 (45%)]\tLoss: 484548.031250\n",
      "Train Epoch: 6 [500/1078 (46%)]\tLoss: 449333.375000\n",
      "Train Epoch: 6 [510/1078 (47%)]\tLoss: 516009.593750\n",
      "Train Epoch: 6 [520/1078 (48%)]\tLoss: 247620.312500\n",
      "Train Epoch: 6 [530/1078 (49%)]\tLoss: 396884.031250\n",
      "Train Epoch: 6 [540/1078 (50%)]\tLoss: 590017.625000\n",
      "Train Epoch: 6 [550/1078 (51%)]\tLoss: 430259.281250\n",
      "Train Epoch: 6 [560/1078 (52%)]\tLoss: 490422.687500\n",
      "Train Epoch: 6 [570/1078 (53%)]\tLoss: 363314.062500\n",
      "Train Epoch: 6 [580/1078 (54%)]\tLoss: 286046.531250\n",
      "Train Epoch: 6 [590/1078 (55%)]\tLoss: 463540.375000\n",
      "Train Epoch: 6 [600/1078 (56%)]\tLoss: 477521.031250\n",
      "Train Epoch: 6 [610/1078 (57%)]\tLoss: 517698.656250\n",
      "Train Epoch: 6 [620/1078 (58%)]\tLoss: 322662.906250\n",
      "Train Epoch: 6 [630/1078 (58%)]\tLoss: 528269.312500\n",
      "Train Epoch: 6 [640/1078 (59%)]\tLoss: 466949.750000\n",
      "Train Epoch: 6 [650/1078 (60%)]\tLoss: 525603.375000\n",
      "Train Epoch: 6 [660/1078 (61%)]\tLoss: 460829.156250\n",
      "Train Epoch: 6 [670/1078 (62%)]\tLoss: 445812.968750\n",
      "Train Epoch: 6 [680/1078 (63%)]\tLoss: 460455.156250\n",
      "Train Epoch: 6 [690/1078 (64%)]\tLoss: 394664.281250\n",
      "Train Epoch: 6 [700/1078 (65%)]\tLoss: 529140.750000\n",
      "Train Epoch: 6 [710/1078 (66%)]\tLoss: 545093.750000\n",
      "Train Epoch: 6 [720/1078 (67%)]\tLoss: 543311.000000\n",
      "Train Epoch: 6 [730/1078 (68%)]\tLoss: 284455.781250\n",
      "Train Epoch: 6 [740/1078 (69%)]\tLoss: 405487.875000\n",
      "Train Epoch: 6 [750/1078 (70%)]\tLoss: 406789.437500\n",
      "Train Epoch: 6 [760/1078 (71%)]\tLoss: 338246.593750\n",
      "Train Epoch: 6 [770/1078 (71%)]\tLoss: 472669.187500\n",
      "Train Epoch: 6 [780/1078 (72%)]\tLoss: 506755.843750\n",
      "Train Epoch: 6 [790/1078 (73%)]\tLoss: 519964.656250\n",
      "Train Epoch: 6 [800/1078 (74%)]\tLoss: 480605.718750\n",
      "Train Epoch: 6 [810/1078 (75%)]\tLoss: 294377.531250\n",
      "Train Epoch: 6 [820/1078 (76%)]\tLoss: 448828.875000\n",
      "Train Epoch: 6 [830/1078 (77%)]\tLoss: 453238.875000\n",
      "Train Epoch: 6 [840/1078 (78%)]\tLoss: 415738.968750\n",
      "Train Epoch: 6 [850/1078 (79%)]\tLoss: 402526.343750\n",
      "Train Epoch: 6 [860/1078 (80%)]\tLoss: 480127.031250\n",
      "Train Epoch: 6 [870/1078 (81%)]\tLoss: 512445.375000\n",
      "Train Epoch: 6 [880/1078 (82%)]\tLoss: 489771.781250\n",
      "Train Epoch: 6 [890/1078 (83%)]\tLoss: 484705.843750\n",
      "Train Epoch: 6 [900/1078 (83%)]\tLoss: 419718.875000\n",
      "Train Epoch: 6 [910/1078 (84%)]\tLoss: 356731.218750\n",
      "Train Epoch: 6 [920/1078 (85%)]\tLoss: 536940.375000\n",
      "Train Epoch: 6 [930/1078 (86%)]\tLoss: 488791.500000\n",
      "Train Epoch: 6 [940/1078 (87%)]\tLoss: 320578.562500\n",
      "Train Epoch: 6 [950/1078 (88%)]\tLoss: 630087.000000\n",
      "Train Epoch: 6 [960/1078 (89%)]\tLoss: 430742.812500\n",
      "Train Epoch: 6 [970/1078 (90%)]\tLoss: 340769.500000\n",
      "Train Epoch: 6 [980/1078 (91%)]\tLoss: 530557.500000\n",
      "Train Epoch: 6 [990/1078 (92%)]\tLoss: 503673.968750\n",
      "Train Epoch: 6 [1000/1078 (93%)]\tLoss: 521022.281250\n",
      "Train Epoch: 6 [1010/1078 (94%)]\tLoss: 551479.625000\n",
      "Train Epoch: 6 [1020/1078 (95%)]\tLoss: 397983.281250\n",
      "Train Epoch: 6 [1030/1078 (96%)]\tLoss: 455123.656250\n",
      "Train Epoch: 6 [1040/1078 (96%)]\tLoss: 304013.250000\n",
      "Train Epoch: 6 [1050/1078 (97%)]\tLoss: 432184.937500\n",
      "Train Epoch: 6 [1060/1078 (98%)]\tLoss: 481603.875000\n",
      "Train Epoch: 6 [1070/1078 (99%)]\tLoss: 388317.687500\n",
      "Train Epoch: 7 [0/1078 (0%)]\tLoss: 471204.031250\n",
      "Train Epoch: 7 [10/1078 (1%)]\tLoss: 494525.718750\n",
      "Train Epoch: 7 [20/1078 (2%)]\tLoss: 339375.906250\n",
      "Train Epoch: 7 [30/1078 (3%)]\tLoss: 431195.750000\n",
      "Train Epoch: 7 [40/1078 (4%)]\tLoss: 244082.625000\n",
      "Train Epoch: 7 [50/1078 (5%)]\tLoss: 436148.031250\n",
      "Train Epoch: 7 [60/1078 (6%)]\tLoss: 299885.843750\n",
      "Train Epoch: 7 [70/1078 (6%)]\tLoss: 487290.906250\n",
      "Train Epoch: 7 [80/1078 (7%)]\tLoss: 410004.812500\n",
      "Train Epoch: 7 [90/1078 (8%)]\tLoss: 415238.750000\n",
      "Train Epoch: 7 [100/1078 (9%)]\tLoss: 481166.906250\n",
      "Train Epoch: 7 [110/1078 (10%)]\tLoss: 352313.531250\n",
      "Train Epoch: 7 [120/1078 (11%)]\tLoss: 561591.562500\n",
      "Train Epoch: 7 [130/1078 (12%)]\tLoss: 299162.312500\n",
      "Train Epoch: 7 [140/1078 (13%)]\tLoss: 298039.781250\n",
      "Train Epoch: 7 [150/1078 (14%)]\tLoss: 479860.812500\n",
      "Train Epoch: 7 [160/1078 (15%)]\tLoss: 427975.281250\n",
      "Train Epoch: 7 [170/1078 (16%)]\tLoss: 244892.796875\n",
      "Train Epoch: 7 [180/1078 (17%)]\tLoss: 372830.062500\n",
      "Train Epoch: 7 [190/1078 (18%)]\tLoss: 382733.375000\n",
      "Train Epoch: 7 [200/1078 (19%)]\tLoss: 337799.250000\n",
      "Train Epoch: 7 [210/1078 (19%)]\tLoss: 451077.562500\n",
      "Train Epoch: 7 [220/1078 (20%)]\tLoss: 512804.718750\n",
      "Train Epoch: 7 [230/1078 (21%)]\tLoss: 439459.468750\n",
      "Train Epoch: 7 [240/1078 (22%)]\tLoss: 498995.343750\n",
      "Train Epoch: 7 [250/1078 (23%)]\tLoss: 414624.250000\n",
      "Train Epoch: 7 [260/1078 (24%)]\tLoss: 429618.093750\n",
      "Train Epoch: 7 [270/1078 (25%)]\tLoss: 396167.937500\n",
      "Train Epoch: 7 [280/1078 (26%)]\tLoss: 379355.187500\n",
      "Train Epoch: 7 [290/1078 (27%)]\tLoss: 253835.171875\n",
      "Train Epoch: 7 [300/1078 (28%)]\tLoss: 444032.218750\n",
      "Train Epoch: 7 [310/1078 (29%)]\tLoss: 437605.718750\n",
      "Train Epoch: 7 [320/1078 (30%)]\tLoss: 414213.718750\n",
      "Train Epoch: 7 [330/1078 (31%)]\tLoss: 357437.031250\n",
      "Train Epoch: 7 [340/1078 (32%)]\tLoss: 376232.531250\n",
      "Train Epoch: 7 [350/1078 (32%)]\tLoss: 485396.156250\n",
      "Train Epoch: 7 [360/1078 (33%)]\tLoss: 339096.843750\n",
      "Train Epoch: 7 [370/1078 (34%)]\tLoss: 638067.437500\n",
      "Train Epoch: 7 [380/1078 (35%)]\tLoss: 260606.546875\n",
      "Train Epoch: 7 [390/1078 (36%)]\tLoss: 434176.687500\n",
      "Train Epoch: 7 [400/1078 (37%)]\tLoss: 416937.593750\n",
      "Train Epoch: 7 [410/1078 (38%)]\tLoss: 528004.937500\n",
      "Train Epoch: 7 [420/1078 (39%)]\tLoss: 436365.718750\n",
      "Train Epoch: 7 [430/1078 (40%)]\tLoss: 368688.781250\n",
      "Train Epoch: 7 [440/1078 (41%)]\tLoss: 512779.437500\n",
      "Train Epoch: 7 [450/1078 (42%)]\tLoss: 375019.093750\n",
      "Train Epoch: 7 [460/1078 (43%)]\tLoss: 354537.687500\n",
      "Train Epoch: 7 [470/1078 (44%)]\tLoss: 446820.406250\n",
      "Train Epoch: 7 [480/1078 (45%)]\tLoss: 495359.562500\n",
      "Train Epoch: 7 [490/1078 (45%)]\tLoss: 471846.312500\n",
      "Train Epoch: 7 [500/1078 (46%)]\tLoss: 534946.875000\n",
      "Train Epoch: 7 [510/1078 (47%)]\tLoss: 525215.875000\n",
      "Train Epoch: 7 [520/1078 (48%)]\tLoss: 521177.625000\n",
      "Train Epoch: 7 [530/1078 (49%)]\tLoss: 377720.281250\n",
      "Train Epoch: 7 [540/1078 (50%)]\tLoss: 417226.937500\n",
      "Train Epoch: 7 [550/1078 (51%)]\tLoss: 459011.718750\n",
      "Train Epoch: 7 [560/1078 (52%)]\tLoss: 495578.562500\n",
      "Train Epoch: 7 [570/1078 (53%)]\tLoss: 497601.750000\n",
      "Train Epoch: 7 [580/1078 (54%)]\tLoss: 531068.750000\n",
      "Train Epoch: 7 [590/1078 (55%)]\tLoss: 409483.312500\n",
      "Train Epoch: 7 [600/1078 (56%)]\tLoss: 450431.312500\n",
      "Train Epoch: 7 [610/1078 (57%)]\tLoss: 501104.187500\n",
      "Train Epoch: 7 [620/1078 (58%)]\tLoss: 487561.656250\n",
      "Train Epoch: 7 [630/1078 (58%)]\tLoss: 430298.156250\n",
      "Train Epoch: 7 [640/1078 (59%)]\tLoss: 333611.843750\n",
      "Train Epoch: 7 [650/1078 (60%)]\tLoss: 356234.812500\n",
      "Train Epoch: 7 [660/1078 (61%)]\tLoss: 473040.562500\n",
      "Train Epoch: 7 [670/1078 (62%)]\tLoss: 573637.250000\n",
      "Train Epoch: 7 [680/1078 (63%)]\tLoss: 388859.875000\n",
      "Train Epoch: 7 [690/1078 (64%)]\tLoss: 325110.156250\n",
      "Train Epoch: 7 [700/1078 (65%)]\tLoss: 495386.406250\n",
      "Train Epoch: 7 [710/1078 (66%)]\tLoss: 360843.218750\n",
      "Train Epoch: 7 [720/1078 (67%)]\tLoss: 501581.843750\n",
      "Train Epoch: 7 [730/1078 (68%)]\tLoss: 498437.593750\n",
      "Train Epoch: 7 [740/1078 (69%)]\tLoss: 369506.843750\n",
      "Train Epoch: 7 [750/1078 (70%)]\tLoss: 375914.625000\n",
      "Train Epoch: 7 [760/1078 (71%)]\tLoss: 418020.843750\n",
      "Train Epoch: 7 [770/1078 (71%)]\tLoss: 357879.187500\n",
      "Train Epoch: 7 [780/1078 (72%)]\tLoss: 353413.437500\n",
      "Train Epoch: 7 [790/1078 (73%)]\tLoss: 431702.406250\n",
      "Train Epoch: 7 [800/1078 (74%)]\tLoss: 510740.656250\n",
      "Train Epoch: 7 [810/1078 (75%)]\tLoss: 475853.625000\n",
      "Train Epoch: 7 [820/1078 (76%)]\tLoss: 292529.093750\n",
      "Train Epoch: 7 [830/1078 (77%)]\tLoss: 570783.750000\n",
      "Train Epoch: 7 [840/1078 (78%)]\tLoss: 418079.812500\n",
      "Train Epoch: 7 [850/1078 (79%)]\tLoss: 481749.500000\n",
      "Train Epoch: 7 [860/1078 (80%)]\tLoss: 376969.000000\n",
      "Train Epoch: 7 [870/1078 (81%)]\tLoss: 494631.750000\n",
      "Train Epoch: 7 [880/1078 (82%)]\tLoss: 491700.312500\n",
      "Train Epoch: 7 [890/1078 (83%)]\tLoss: 339754.687500\n",
      "Train Epoch: 7 [900/1078 (83%)]\tLoss: 508637.375000\n",
      "Train Epoch: 7 [910/1078 (84%)]\tLoss: 442479.093750\n",
      "Train Epoch: 7 [920/1078 (85%)]\tLoss: 446987.218750\n",
      "Train Epoch: 7 [930/1078 (86%)]\tLoss: 421730.250000\n",
      "Train Epoch: 7 [940/1078 (87%)]\tLoss: 412441.187500\n",
      "Train Epoch: 7 [950/1078 (88%)]\tLoss: 355616.843750\n",
      "Train Epoch: 7 [960/1078 (89%)]\tLoss: 428779.625000\n",
      "Train Epoch: 7 [970/1078 (90%)]\tLoss: 436782.281250\n",
      "Train Epoch: 7 [980/1078 (91%)]\tLoss: 527079.250000\n",
      "Train Epoch: 7 [990/1078 (92%)]\tLoss: 441314.468750\n",
      "Train Epoch: 7 [1000/1078 (93%)]\tLoss: 500469.781250\n",
      "Train Epoch: 7 [1010/1078 (94%)]\tLoss: 420177.781250\n",
      "Train Epoch: 7 [1020/1078 (95%)]\tLoss: 448749.250000\n",
      "Train Epoch: 7 [1030/1078 (96%)]\tLoss: 513565.937500\n",
      "Train Epoch: 7 [1040/1078 (96%)]\tLoss: 450102.500000\n",
      "Train Epoch: 7 [1050/1078 (97%)]\tLoss: 469846.093750\n",
      "Train Epoch: 7 [1060/1078 (98%)]\tLoss: 482764.156250\n",
      "Train Epoch: 7 [1070/1078 (99%)]\tLoss: 492452.906250\n",
      "Train Epoch: 8 [0/1078 (0%)]\tLoss: 463006.906250\n",
      "Train Epoch: 8 [10/1078 (1%)]\tLoss: 381089.468750\n",
      "Train Epoch: 8 [20/1078 (2%)]\tLoss: 611183.875000\n",
      "Train Epoch: 8 [30/1078 (3%)]\tLoss: 435559.312500\n",
      "Train Epoch: 8 [40/1078 (4%)]\tLoss: 440184.562500\n",
      "Train Epoch: 8 [50/1078 (5%)]\tLoss: 464371.000000\n",
      "Train Epoch: 8 [60/1078 (6%)]\tLoss: 366097.625000\n",
      "Train Epoch: 8 [70/1078 (6%)]\tLoss: 410903.625000\n",
      "Train Epoch: 8 [80/1078 (7%)]\tLoss: 465467.656250\n",
      "Train Epoch: 8 [90/1078 (8%)]\tLoss: 486978.312500\n",
      "Train Epoch: 8 [100/1078 (9%)]\tLoss: 289908.218750\n",
      "Train Epoch: 8 [110/1078 (10%)]\tLoss: 380194.125000\n",
      "Train Epoch: 8 [120/1078 (11%)]\tLoss: 390228.250000\n",
      "Train Epoch: 8 [130/1078 (12%)]\tLoss: 471011.500000\n",
      "Train Epoch: 8 [140/1078 (13%)]\tLoss: 453227.187500\n",
      "Train Epoch: 8 [150/1078 (14%)]\tLoss: 537170.937500\n",
      "Train Epoch: 8 [160/1078 (15%)]\tLoss: 512120.531250\n",
      "Train Epoch: 8 [170/1078 (16%)]\tLoss: 390643.218750\n",
      "Train Epoch: 8 [180/1078 (17%)]\tLoss: 519428.156250\n",
      "Train Epoch: 8 [190/1078 (18%)]\tLoss: 470681.843750\n",
      "Train Epoch: 8 [200/1078 (19%)]\tLoss: 429981.187500\n",
      "Train Epoch: 8 [210/1078 (19%)]\tLoss: 502215.562500\n",
      "Train Epoch: 8 [220/1078 (20%)]\tLoss: 435912.718750\n",
      "Train Epoch: 8 [230/1078 (21%)]\tLoss: 397085.937500\n",
      "Train Epoch: 8 [240/1078 (22%)]\tLoss: 278019.968750\n",
      "Train Epoch: 8 [250/1078 (23%)]\tLoss: 443419.781250\n",
      "Train Epoch: 8 [260/1078 (24%)]\tLoss: 494286.500000\n",
      "Train Epoch: 8 [270/1078 (25%)]\tLoss: 439252.718750\n",
      "Train Epoch: 8 [280/1078 (26%)]\tLoss: 398071.718750\n",
      "Train Epoch: 8 [290/1078 (27%)]\tLoss: 455791.562500\n",
      "Train Epoch: 8 [300/1078 (28%)]\tLoss: 366614.468750\n",
      "Train Epoch: 8 [310/1078 (29%)]\tLoss: 483856.812500\n",
      "Train Epoch: 8 [320/1078 (30%)]\tLoss: 432347.562500\n",
      "Train Epoch: 8 [330/1078 (31%)]\tLoss: 472488.593750\n",
      "Train Epoch: 8 [340/1078 (32%)]\tLoss: 404711.750000\n",
      "Train Epoch: 8 [350/1078 (32%)]\tLoss: 394648.937500\n",
      "Train Epoch: 8 [360/1078 (33%)]\tLoss: 543681.812500\n",
      "Train Epoch: 8 [370/1078 (34%)]\tLoss: 404721.468750\n",
      "Train Epoch: 8 [380/1078 (35%)]\tLoss: 462548.781250\n",
      "Train Epoch: 8 [390/1078 (36%)]\tLoss: 428578.187500\n",
      "Train Epoch: 8 [400/1078 (37%)]\tLoss: 497544.250000\n",
      "Train Epoch: 8 [410/1078 (38%)]\tLoss: 387575.468750\n",
      "Train Epoch: 8 [420/1078 (39%)]\tLoss: 547734.000000\n",
      "Train Epoch: 8 [430/1078 (40%)]\tLoss: 520962.500000\n",
      "Train Epoch: 8 [440/1078 (41%)]\tLoss: 435117.718750\n",
      "Train Epoch: 8 [450/1078 (42%)]\tLoss: 409418.000000\n",
      "Train Epoch: 8 [460/1078 (43%)]\tLoss: 488141.125000\n",
      "Train Epoch: 8 [470/1078 (44%)]\tLoss: 504013.000000\n",
      "Train Epoch: 8 [480/1078 (45%)]\tLoss: 526768.375000\n",
      "Train Epoch: 8 [490/1078 (45%)]\tLoss: 490242.875000\n",
      "Train Epoch: 8 [500/1078 (46%)]\tLoss: 394514.093750\n",
      "Train Epoch: 8 [510/1078 (47%)]\tLoss: 398791.843750\n",
      "Train Epoch: 8 [520/1078 (48%)]\tLoss: 480007.031250\n",
      "Train Epoch: 8 [530/1078 (49%)]\tLoss: 260876.468750\n",
      "Train Epoch: 8 [540/1078 (50%)]\tLoss: 442050.250000\n",
      "Train Epoch: 8 [550/1078 (51%)]\tLoss: 410190.375000\n",
      "Train Epoch: 8 [560/1078 (52%)]\tLoss: 533849.750000\n",
      "Train Epoch: 8 [570/1078 (53%)]\tLoss: 389999.031250\n",
      "Train Epoch: 8 [580/1078 (54%)]\tLoss: 555660.250000\n",
      "Train Epoch: 8 [590/1078 (55%)]\tLoss: 454636.875000\n",
      "Train Epoch: 8 [600/1078 (56%)]\tLoss: 438312.250000\n",
      "Train Epoch: 8 [610/1078 (57%)]\tLoss: 573158.062500\n",
      "Train Epoch: 8 [620/1078 (58%)]\tLoss: 325742.718750\n",
      "Train Epoch: 8 [630/1078 (58%)]\tLoss: 461089.687500\n",
      "Train Epoch: 8 [640/1078 (59%)]\tLoss: 517979.343750\n",
      "Train Epoch: 8 [650/1078 (60%)]\tLoss: 421229.656250\n",
      "Train Epoch: 8 [660/1078 (61%)]\tLoss: 480975.656250\n",
      "Train Epoch: 8 [670/1078 (62%)]\tLoss: 294411.031250\n",
      "Train Epoch: 8 [680/1078 (63%)]\tLoss: 466760.031250\n",
      "Train Epoch: 8 [690/1078 (64%)]\tLoss: 627342.812500\n",
      "Train Epoch: 8 [700/1078 (65%)]\tLoss: 425433.093750\n",
      "Train Epoch: 8 [710/1078 (66%)]\tLoss: 519314.500000\n",
      "Train Epoch: 8 [720/1078 (67%)]\tLoss: 571575.562500\n",
      "Train Epoch: 8 [730/1078 (68%)]\tLoss: 519826.218750\n",
      "Train Epoch: 8 [740/1078 (69%)]\tLoss: 442309.218750\n",
      "Train Epoch: 8 [750/1078 (70%)]\tLoss: 431920.437500\n",
      "Train Epoch: 8 [760/1078 (71%)]\tLoss: 269548.843750\n",
      "Train Epoch: 8 [770/1078 (71%)]\tLoss: 511885.093750\n",
      "Train Epoch: 8 [780/1078 (72%)]\tLoss: 488785.562500\n",
      "Train Epoch: 8 [790/1078 (73%)]\tLoss: 405142.187500\n",
      "Train Epoch: 8 [800/1078 (74%)]\tLoss: 486903.343750\n",
      "Train Epoch: 8 [810/1078 (75%)]\tLoss: 604624.375000\n",
      "Train Epoch: 8 [820/1078 (76%)]\tLoss: 548545.375000\n",
      "Train Epoch: 8 [830/1078 (77%)]\tLoss: 318852.875000\n",
      "Train Epoch: 8 [840/1078 (78%)]\tLoss: 502693.812500\n",
      "Train Epoch: 8 [850/1078 (79%)]\tLoss: 391600.656250\n",
      "Train Epoch: 8 [860/1078 (80%)]\tLoss: 357218.687500\n",
      "Train Epoch: 8 [870/1078 (81%)]\tLoss: 354798.593750\n",
      "Train Epoch: 8 [880/1078 (82%)]\tLoss: 461567.031250\n",
      "Train Epoch: 8 [890/1078 (83%)]\tLoss: 483524.750000\n",
      "Train Epoch: 8 [900/1078 (83%)]\tLoss: 510442.562500\n",
      "Train Epoch: 8 [910/1078 (84%)]\tLoss: 374813.718750\n",
      "Train Epoch: 8 [920/1078 (85%)]\tLoss: 305102.156250\n",
      "Train Epoch: 8 [930/1078 (86%)]\tLoss: 454220.781250\n",
      "Train Epoch: 8 [940/1078 (87%)]\tLoss: 314429.406250\n",
      "Train Epoch: 8 [950/1078 (88%)]\tLoss: 516352.156250\n",
      "Train Epoch: 8 [960/1078 (89%)]\tLoss: 265337.718750\n",
      "Train Epoch: 8 [970/1078 (90%)]\tLoss: 483967.343750\n",
      "Train Epoch: 8 [980/1078 (91%)]\tLoss: 409309.937500\n",
      "Train Epoch: 8 [990/1078 (92%)]\tLoss: 449453.531250\n",
      "Train Epoch: 8 [1000/1078 (93%)]\tLoss: 540977.250000\n",
      "Train Epoch: 8 [1010/1078 (94%)]\tLoss: 470433.875000\n",
      "Train Epoch: 8 [1020/1078 (95%)]\tLoss: 430075.687500\n",
      "Train Epoch: 8 [1030/1078 (96%)]\tLoss: 434806.093750\n",
      "Train Epoch: 8 [1040/1078 (96%)]\tLoss: 426422.718750\n",
      "Train Epoch: 8 [1050/1078 (97%)]\tLoss: 571348.062500\n",
      "Train Epoch: 8 [1060/1078 (98%)]\tLoss: 344188.343750\n",
      "Train Epoch: 8 [1070/1078 (99%)]\tLoss: 514295.406250\n",
      "Train Epoch: 9 [0/1078 (0%)]\tLoss: 399258.375000\n",
      "Train Epoch: 9 [10/1078 (1%)]\tLoss: 481616.125000\n",
      "Train Epoch: 9 [20/1078 (2%)]\tLoss: 301484.593750\n",
      "Train Epoch: 9 [30/1078 (3%)]\tLoss: 626154.062500\n",
      "Train Epoch: 9 [40/1078 (4%)]\tLoss: 439905.343750\n",
      "Train Epoch: 9 [50/1078 (5%)]\tLoss: 527326.562500\n",
      "Train Epoch: 9 [60/1078 (6%)]\tLoss: 364501.625000\n",
      "Train Epoch: 9 [70/1078 (6%)]\tLoss: 523896.750000\n",
      "Train Epoch: 9 [80/1078 (7%)]\tLoss: 465838.843750\n",
      "Train Epoch: 9 [90/1078 (8%)]\tLoss: 489253.687500\n",
      "Train Epoch: 9 [100/1078 (9%)]\tLoss: 542749.562500\n",
      "Train Epoch: 9 [110/1078 (10%)]\tLoss: 393340.781250\n",
      "Train Epoch: 9 [120/1078 (11%)]\tLoss: 488673.343750\n",
      "Train Epoch: 9 [130/1078 (12%)]\tLoss: 447192.625000\n",
      "Train Epoch: 9 [140/1078 (13%)]\tLoss: 519772.718750\n",
      "Train Epoch: 9 [150/1078 (14%)]\tLoss: 500877.156250\n",
      "Train Epoch: 9 [160/1078 (15%)]\tLoss: 534702.500000\n",
      "Train Epoch: 9 [170/1078 (16%)]\tLoss: 481438.406250\n",
      "Train Epoch: 9 [180/1078 (17%)]\tLoss: 484786.062500\n",
      "Train Epoch: 9 [190/1078 (18%)]\tLoss: 418639.250000\n",
      "Train Epoch: 9 [200/1078 (19%)]\tLoss: 414052.312500\n",
      "Train Epoch: 9 [210/1078 (19%)]\tLoss: 469982.312500\n",
      "Train Epoch: 9 [220/1078 (20%)]\tLoss: 249637.656250\n",
      "Train Epoch: 9 [230/1078 (21%)]\tLoss: 475899.968750\n",
      "Train Epoch: 9 [240/1078 (22%)]\tLoss: 586719.062500\n",
      "Train Epoch: 9 [250/1078 (23%)]\tLoss: 439590.343750\n",
      "Train Epoch: 9 [260/1078 (24%)]\tLoss: 518744.843750\n",
      "Train Epoch: 9 [270/1078 (25%)]\tLoss: 499556.750000\n",
      "Train Epoch: 9 [280/1078 (26%)]\tLoss: 488295.000000\n",
      "Train Epoch: 9 [290/1078 (27%)]\tLoss: 292622.500000\n",
      "Train Epoch: 9 [300/1078 (28%)]\tLoss: 508600.187500\n",
      "Train Epoch: 9 [310/1078 (29%)]\tLoss: 272890.031250\n",
      "Train Epoch: 9 [320/1078 (30%)]\tLoss: 383563.906250\n",
      "Train Epoch: 9 [330/1078 (31%)]\tLoss: 484958.187500\n",
      "Train Epoch: 9 [340/1078 (32%)]\tLoss: 467025.625000\n",
      "Train Epoch: 9 [350/1078 (32%)]\tLoss: 323640.781250\n",
      "Train Epoch: 9 [360/1078 (33%)]\tLoss: 419469.187500\n",
      "Train Epoch: 9 [370/1078 (34%)]\tLoss: 423281.343750\n",
      "Train Epoch: 9 [380/1078 (35%)]\tLoss: 452765.562500\n",
      "Train Epoch: 9 [390/1078 (36%)]\tLoss: 469056.562500\n",
      "Train Epoch: 9 [400/1078 (37%)]\tLoss: 294320.625000\n",
      "Train Epoch: 9 [410/1078 (38%)]\tLoss: 520510.437500\n",
      "Train Epoch: 9 [420/1078 (39%)]\tLoss: 417981.906250\n",
      "Train Epoch: 9 [430/1078 (40%)]\tLoss: 548674.437500\n",
      "Train Epoch: 9 [440/1078 (41%)]\tLoss: 412845.718750\n",
      "Train Epoch: 9 [450/1078 (42%)]\tLoss: 526512.187500\n",
      "Train Epoch: 9 [460/1078 (43%)]\tLoss: 384002.437500\n",
      "Train Epoch: 9 [470/1078 (44%)]\tLoss: 376693.562500\n",
      "Train Epoch: 9 [480/1078 (45%)]\tLoss: 398429.937500\n",
      "Train Epoch: 9 [490/1078 (45%)]\tLoss: 534703.812500\n",
      "Train Epoch: 9 [500/1078 (46%)]\tLoss: 473374.937500\n",
      "Train Epoch: 9 [510/1078 (47%)]\tLoss: 451580.937500\n",
      "Train Epoch: 9 [520/1078 (48%)]\tLoss: 421285.875000\n",
      "Train Epoch: 9 [530/1078 (49%)]\tLoss: 564928.562500\n",
      "Train Epoch: 9 [540/1078 (50%)]\tLoss: 539596.437500\n",
      "Train Epoch: 9 [550/1078 (51%)]\tLoss: 495172.250000\n",
      "Train Epoch: 9 [560/1078 (52%)]\tLoss: 521821.343750\n",
      "Train Epoch: 9 [570/1078 (53%)]\tLoss: 518534.031250\n",
      "Train Epoch: 9 [580/1078 (54%)]\tLoss: 321285.656250\n",
      "Train Epoch: 9 [590/1078 (55%)]\tLoss: 436827.312500\n",
      "Train Epoch: 9 [600/1078 (56%)]\tLoss: 506847.812500\n",
      "Train Epoch: 9 [610/1078 (57%)]\tLoss: 309838.343750\n",
      "Train Epoch: 9 [620/1078 (58%)]\tLoss: 475889.437500\n",
      "Train Epoch: 9 [630/1078 (58%)]\tLoss: 496329.656250\n",
      "Train Epoch: 9 [640/1078 (59%)]\tLoss: 386874.937500\n",
      "Train Epoch: 9 [650/1078 (60%)]\tLoss: 491459.531250\n",
      "Train Epoch: 9 [660/1078 (61%)]\tLoss: 438890.125000\n",
      "Train Epoch: 9 [670/1078 (62%)]\tLoss: 424056.093750\n",
      "Train Epoch: 9 [680/1078 (63%)]\tLoss: 461120.031250\n",
      "Train Epoch: 9 [690/1078 (64%)]\tLoss: 452573.718750\n",
      "Train Epoch: 9 [700/1078 (65%)]\tLoss: 529675.875000\n",
      "Train Epoch: 9 [710/1078 (66%)]\tLoss: 443937.812500\n",
      "Train Epoch: 9 [720/1078 (67%)]\tLoss: 413022.093750\n",
      "Train Epoch: 9 [730/1078 (68%)]\tLoss: 410514.375000\n",
      "Train Epoch: 9 [740/1078 (69%)]\tLoss: 472123.156250\n",
      "Train Epoch: 9 [750/1078 (70%)]\tLoss: 359230.656250\n",
      "Train Epoch: 9 [760/1078 (71%)]\tLoss: 487742.968750\n",
      "Train Epoch: 9 [770/1078 (71%)]\tLoss: 500017.875000\n",
      "Train Epoch: 9 [780/1078 (72%)]\tLoss: 409673.125000\n",
      "Train Epoch: 9 [790/1078 (73%)]\tLoss: 305778.437500\n",
      "Train Epoch: 9 [800/1078 (74%)]\tLoss: 491712.781250\n",
      "Train Epoch: 9 [810/1078 (75%)]\tLoss: 392369.500000\n",
      "Train Epoch: 9 [820/1078 (76%)]\tLoss: 459561.156250\n",
      "Train Epoch: 9 [830/1078 (77%)]\tLoss: 478944.875000\n",
      "Train Epoch: 9 [840/1078 (78%)]\tLoss: 462229.406250\n",
      "Train Epoch: 9 [850/1078 (79%)]\tLoss: 585734.375000\n",
      "Train Epoch: 9 [860/1078 (80%)]\tLoss: 479315.843750\n",
      "Train Epoch: 9 [870/1078 (81%)]\tLoss: 373889.062500\n",
      "Train Epoch: 9 [880/1078 (82%)]\tLoss: 474436.406250\n",
      "Train Epoch: 9 [890/1078 (83%)]\tLoss: 504613.437500\n",
      "Train Epoch: 9 [900/1078 (83%)]\tLoss: 437407.906250\n",
      "Train Epoch: 9 [910/1078 (84%)]\tLoss: 442856.187500\n",
      "Train Epoch: 9 [920/1078 (85%)]\tLoss: 450744.906250\n",
      "Train Epoch: 9 [930/1078 (86%)]\tLoss: 432538.312500\n",
      "Train Epoch: 9 [940/1078 (87%)]\tLoss: 373955.531250\n",
      "Train Epoch: 9 [950/1078 (88%)]\tLoss: 226842.859375\n",
      "Train Epoch: 9 [960/1078 (89%)]\tLoss: 358090.687500\n",
      "Train Epoch: 9 [970/1078 (90%)]\tLoss: 431731.406250\n",
      "Train Epoch: 9 [980/1078 (91%)]\tLoss: 505113.718750\n",
      "Train Epoch: 9 [990/1078 (92%)]\tLoss: 469660.937500\n",
      "Train Epoch: 9 [1000/1078 (93%)]\tLoss: 398109.031250\n",
      "Train Epoch: 9 [1010/1078 (94%)]\tLoss: 432020.218750\n",
      "Train Epoch: 9 [1020/1078 (95%)]\tLoss: 313951.593750\n",
      "Train Epoch: 9 [1030/1078 (96%)]\tLoss: 334023.687500\n",
      "Train Epoch: 9 [1040/1078 (96%)]\tLoss: 416822.406250\n",
      "Train Epoch: 9 [1050/1078 (97%)]\tLoss: 412975.593750\n",
      "Train Epoch: 9 [1060/1078 (98%)]\tLoss: 381277.281250\n",
      "Train Epoch: 9 [1070/1078 (99%)]\tLoss: 412207.906250\n",
      "Train Epoch: 10 [0/1078 (0%)]\tLoss: 513039.187500\n",
      "Train Epoch: 10 [10/1078 (1%)]\tLoss: 523085.562500\n",
      "Train Epoch: 10 [20/1078 (2%)]\tLoss: 354793.593750\n",
      "Train Epoch: 10 [30/1078 (3%)]\tLoss: 496345.937500\n",
      "Train Epoch: 10 [40/1078 (4%)]\tLoss: 406366.812500\n",
      "Train Epoch: 10 [50/1078 (5%)]\tLoss: 304449.312500\n",
      "Train Epoch: 10 [60/1078 (6%)]\tLoss: 466979.750000\n",
      "Train Epoch: 10 [70/1078 (6%)]\tLoss: 322393.500000\n",
      "Train Epoch: 10 [80/1078 (7%)]\tLoss: 419773.437500\n",
      "Train Epoch: 10 [90/1078 (8%)]\tLoss: 555832.375000\n",
      "Train Epoch: 10 [100/1078 (9%)]\tLoss: 337322.500000\n",
      "Train Epoch: 10 [110/1078 (10%)]\tLoss: 489149.218750\n",
      "Train Epoch: 10 [120/1078 (11%)]\tLoss: 413692.843750\n",
      "Train Epoch: 10 [130/1078 (12%)]\tLoss: 452567.406250\n",
      "Train Epoch: 10 [140/1078 (13%)]\tLoss: 415032.500000\n",
      "Train Epoch: 10 [150/1078 (14%)]\tLoss: 523488.312500\n",
      "Train Epoch: 10 [160/1078 (15%)]\tLoss: 474251.437500\n",
      "Train Epoch: 10 [170/1078 (16%)]\tLoss: 521430.687500\n",
      "Train Epoch: 10 [180/1078 (17%)]\tLoss: 352452.968750\n",
      "Train Epoch: 10 [190/1078 (18%)]\tLoss: 378321.250000\n",
      "Train Epoch: 10 [200/1078 (19%)]\tLoss: 497598.437500\n",
      "Train Epoch: 10 [210/1078 (19%)]\tLoss: 531918.125000\n",
      "Train Epoch: 10 [220/1078 (20%)]\tLoss: 502834.906250\n",
      "Train Epoch: 10 [230/1078 (21%)]\tLoss: 508967.968750\n",
      "Train Epoch: 10 [240/1078 (22%)]\tLoss: 418784.812500\n",
      "Train Epoch: 10 [250/1078 (23%)]\tLoss: 389921.562500\n",
      "Train Epoch: 10 [260/1078 (24%)]\tLoss: 387510.781250\n",
      "Train Epoch: 10 [270/1078 (25%)]\tLoss: 479907.343750\n",
      "Train Epoch: 10 [280/1078 (26%)]\tLoss: 320140.781250\n",
      "Train Epoch: 10 [290/1078 (27%)]\tLoss: 260824.453125\n",
      "Train Epoch: 10 [300/1078 (28%)]\tLoss: 234266.921875\n",
      "Train Epoch: 10 [310/1078 (29%)]\tLoss: 529135.062500\n",
      "Train Epoch: 10 [320/1078 (30%)]\tLoss: 532762.187500\n",
      "Train Epoch: 10 [330/1078 (31%)]\tLoss: 494741.937500\n",
      "Train Epoch: 10 [340/1078 (32%)]\tLoss: 509652.343750\n",
      "Train Epoch: 10 [350/1078 (32%)]\tLoss: 517005.687500\n",
      "Train Epoch: 10 [360/1078 (33%)]\tLoss: 478839.750000\n",
      "Train Epoch: 10 [370/1078 (34%)]\tLoss: 504386.781250\n",
      "Train Epoch: 10 [380/1078 (35%)]\tLoss: 531125.062500\n",
      "Train Epoch: 10 [390/1078 (36%)]\tLoss: 352115.562500\n",
      "Train Epoch: 10 [400/1078 (37%)]\tLoss: 468205.468750\n",
      "Train Epoch: 10 [410/1078 (38%)]\tLoss: 495861.656250\n",
      "Train Epoch: 10 [420/1078 (39%)]\tLoss: 511045.343750\n",
      "Train Epoch: 10 [430/1078 (40%)]\tLoss: 455572.406250\n",
      "Train Epoch: 10 [440/1078 (41%)]\tLoss: 433256.750000\n",
      "Train Epoch: 10 [450/1078 (42%)]\tLoss: 641713.750000\n",
      "Train Epoch: 10 [460/1078 (43%)]\tLoss: 533664.875000\n",
      "Train Epoch: 10 [470/1078 (44%)]\tLoss: 498712.125000\n",
      "Train Epoch: 10 [480/1078 (45%)]\tLoss: 477541.593750\n",
      "Train Epoch: 10 [490/1078 (45%)]\tLoss: 503540.593750\n",
      "Train Epoch: 10 [500/1078 (46%)]\tLoss: 487874.156250\n",
      "Train Epoch: 10 [510/1078 (47%)]\tLoss: 509257.968750\n",
      "Train Epoch: 10 [520/1078 (48%)]\tLoss: 469442.750000\n",
      "Train Epoch: 10 [530/1078 (49%)]\tLoss: 482494.906250\n",
      "Train Epoch: 10 [540/1078 (50%)]\tLoss: 389741.500000\n",
      "Train Epoch: 10 [550/1078 (51%)]\tLoss: 485306.625000\n",
      "Train Epoch: 10 [560/1078 (52%)]\tLoss: 481145.156250\n",
      "Train Epoch: 10 [570/1078 (53%)]\tLoss: 470485.468750\n",
      "Train Epoch: 10 [580/1078 (54%)]\tLoss: 438564.625000\n",
      "Train Epoch: 10 [590/1078 (55%)]\tLoss: 505038.312500\n",
      "Train Epoch: 10 [600/1078 (56%)]\tLoss: 481659.906250\n",
      "Train Epoch: 10 [610/1078 (57%)]\tLoss: 411477.281250\n",
      "Train Epoch: 10 [620/1078 (58%)]\tLoss: 545272.687500\n",
      "Train Epoch: 10 [630/1078 (58%)]\tLoss: 590710.500000\n",
      "Train Epoch: 10 [640/1078 (59%)]\tLoss: 457787.875000\n",
      "Train Epoch: 10 [650/1078 (60%)]\tLoss: 422587.187500\n",
      "Train Epoch: 10 [660/1078 (61%)]\tLoss: 429512.593750\n",
      "Train Epoch: 10 [670/1078 (62%)]\tLoss: 583308.937500\n",
      "Train Epoch: 10 [680/1078 (63%)]\tLoss: 342577.906250\n",
      "Train Epoch: 10 [690/1078 (64%)]\tLoss: 496372.750000\n",
      "Train Epoch: 10 [700/1078 (65%)]\tLoss: 479595.687500\n",
      "Train Epoch: 10 [710/1078 (66%)]\tLoss: 374511.062500\n",
      "Train Epoch: 10 [720/1078 (67%)]\tLoss: 471213.406250\n",
      "Train Epoch: 10 [730/1078 (68%)]\tLoss: 438384.687500\n",
      "Train Epoch: 10 [740/1078 (69%)]\tLoss: 466557.218750\n",
      "Train Epoch: 10 [750/1078 (70%)]\tLoss: 521493.156250\n",
      "Train Epoch: 10 [760/1078 (71%)]\tLoss: 455621.000000\n",
      "Train Epoch: 10 [770/1078 (71%)]\tLoss: 423543.968750\n",
      "Train Epoch: 10 [780/1078 (72%)]\tLoss: 480097.625000\n",
      "Train Epoch: 10 [790/1078 (73%)]\tLoss: 485384.750000\n",
      "Train Epoch: 10 [800/1078 (74%)]\tLoss: 500446.718750\n",
      "Train Epoch: 10 [810/1078 (75%)]\tLoss: 457532.750000\n",
      "Train Epoch: 10 [820/1078 (76%)]\tLoss: 397510.718750\n",
      "Train Epoch: 10 [830/1078 (77%)]\tLoss: 413063.843750\n",
      "Train Epoch: 10 [840/1078 (78%)]\tLoss: 423947.281250\n",
      "Train Epoch: 10 [850/1078 (79%)]\tLoss: 433988.187500\n",
      "Train Epoch: 10 [860/1078 (80%)]\tLoss: 460390.312500\n",
      "Train Epoch: 10 [870/1078 (81%)]\tLoss: 433985.312500\n",
      "Train Epoch: 10 [880/1078 (82%)]\tLoss: 461605.031250\n",
      "Train Epoch: 10 [890/1078 (83%)]\tLoss: 404645.593750\n",
      "Train Epoch: 10 [900/1078 (83%)]\tLoss: 324872.625000\n",
      "Train Epoch: 10 [910/1078 (84%)]\tLoss: 564337.500000\n",
      "Train Epoch: 10 [920/1078 (85%)]\tLoss: 358968.062500\n",
      "Train Epoch: 10 [930/1078 (86%)]\tLoss: 426246.937500\n",
      "Train Epoch: 10 [940/1078 (87%)]\tLoss: 405119.031250\n",
      "Train Epoch: 10 [950/1078 (88%)]\tLoss: 337403.125000\n",
      "Train Epoch: 10 [960/1078 (89%)]\tLoss: 470356.750000\n",
      "Train Epoch: 10 [970/1078 (90%)]\tLoss: 554147.375000\n",
      "Train Epoch: 10 [980/1078 (91%)]\tLoss: 424702.843750\n",
      "Train Epoch: 10 [990/1078 (92%)]\tLoss: 576453.375000\n",
      "Train Epoch: 10 [1000/1078 (93%)]\tLoss: 440511.031250\n",
      "Train Epoch: 10 [1010/1078 (94%)]\tLoss: 418563.125000\n",
      "Train Epoch: 10 [1020/1078 (95%)]\tLoss: 529419.500000\n",
      "Train Epoch: 10 [1030/1078 (96%)]\tLoss: 373379.593750\n",
      "Train Epoch: 10 [1040/1078 (96%)]\tLoss: 426127.343750\n",
      "Train Epoch: 10 [1050/1078 (97%)]\tLoss: 360348.656250\n",
      "Train Epoch: 10 [1060/1078 (98%)]\tLoss: 490847.031250\n",
      "Train Epoch: 10 [1070/1078 (99%)]\tLoss: 466660.593750\n",
      "Train Epoch: 11 [0/1078 (0%)]\tLoss: 428600.531250\n",
      "Train Epoch: 11 [10/1078 (1%)]\tLoss: 316137.687500\n",
      "Train Epoch: 11 [20/1078 (2%)]\tLoss: 420063.031250\n",
      "Train Epoch: 11 [30/1078 (3%)]\tLoss: 460280.593750\n",
      "Train Epoch: 11 [40/1078 (4%)]\tLoss: 382333.468750\n",
      "Train Epoch: 11 [50/1078 (5%)]\tLoss: 405073.125000\n",
      "Train Epoch: 11 [60/1078 (6%)]\tLoss: 498961.687500\n",
      "Train Epoch: 11 [70/1078 (6%)]\tLoss: 398303.187500\n",
      "Train Epoch: 11 [80/1078 (7%)]\tLoss: 431925.968750\n",
      "Train Epoch: 11 [90/1078 (8%)]\tLoss: 449978.968750\n",
      "Train Epoch: 11 [100/1078 (9%)]\tLoss: 260053.875000\n",
      "Train Epoch: 11 [110/1078 (10%)]\tLoss: 499468.281250\n",
      "Train Epoch: 11 [120/1078 (11%)]\tLoss: 441986.750000\n",
      "Train Epoch: 11 [130/1078 (12%)]\tLoss: 463355.781250\n",
      "Train Epoch: 11 [140/1078 (13%)]\tLoss: 459767.343750\n",
      "Train Epoch: 11 [150/1078 (14%)]\tLoss: 453195.812500\n",
      "Train Epoch: 11 [160/1078 (15%)]\tLoss: 315914.062500\n",
      "Train Epoch: 11 [170/1078 (16%)]\tLoss: 322303.000000\n",
      "Train Epoch: 11 [180/1078 (17%)]\tLoss: 444950.437500\n",
      "Train Epoch: 11 [190/1078 (18%)]\tLoss: 428054.562500\n",
      "Train Epoch: 11 [200/1078 (19%)]\tLoss: 394678.406250\n",
      "Train Epoch: 11 [210/1078 (19%)]\tLoss: 425705.968750\n",
      "Train Epoch: 11 [220/1078 (20%)]\tLoss: 466574.343750\n",
      "Train Epoch: 11 [230/1078 (21%)]\tLoss: 487542.468750\n",
      "Train Epoch: 11 [240/1078 (22%)]\tLoss: 534284.187500\n",
      "Train Epoch: 11 [250/1078 (23%)]\tLoss: 486899.875000\n",
      "Train Epoch: 11 [260/1078 (24%)]\tLoss: 421755.062500\n",
      "Train Epoch: 11 [270/1078 (25%)]\tLoss: 338178.843750\n",
      "Train Epoch: 11 [280/1078 (26%)]\tLoss: 409244.281250\n",
      "Train Epoch: 11 [290/1078 (27%)]\tLoss: 484765.250000\n",
      "Train Epoch: 11 [300/1078 (28%)]\tLoss: 344769.093750\n",
      "Train Epoch: 11 [310/1078 (29%)]\tLoss: 435050.156250\n",
      "Train Epoch: 11 [320/1078 (30%)]\tLoss: 481596.187500\n",
      "Train Epoch: 11 [330/1078 (31%)]\tLoss: 426608.156250\n",
      "Train Epoch: 11 [340/1078 (32%)]\tLoss: 256065.953125\n",
      "Train Epoch: 11 [350/1078 (32%)]\tLoss: 460374.156250\n",
      "Train Epoch: 11 [360/1078 (33%)]\tLoss: 432365.531250\n",
      "Train Epoch: 11 [370/1078 (34%)]\tLoss: 453132.718750\n",
      "Train Epoch: 11 [380/1078 (35%)]\tLoss: 417897.406250\n",
      "Train Epoch: 11 [390/1078 (36%)]\tLoss: 503607.312500\n",
      "Train Epoch: 11 [400/1078 (37%)]\tLoss: 385413.343750\n",
      "Train Epoch: 11 [410/1078 (38%)]\tLoss: 392366.062500\n",
      "Train Epoch: 11 [420/1078 (39%)]\tLoss: 323067.593750\n",
      "Train Epoch: 11 [430/1078 (40%)]\tLoss: 375947.343750\n",
      "Train Epoch: 11 [440/1078 (41%)]\tLoss: 424108.968750\n",
      "Train Epoch: 11 [450/1078 (42%)]\tLoss: 612439.500000\n",
      "Train Epoch: 11 [460/1078 (43%)]\tLoss: 344732.593750\n",
      "Train Epoch: 11 [470/1078 (44%)]\tLoss: 367365.468750\n",
      "Train Epoch: 11 [480/1078 (45%)]\tLoss: 507652.937500\n",
      "Train Epoch: 11 [490/1078 (45%)]\tLoss: 304702.562500\n",
      "Train Epoch: 11 [500/1078 (46%)]\tLoss: 374662.406250\n",
      "Train Epoch: 11 [510/1078 (47%)]\tLoss: 402214.656250\n",
      "Train Epoch: 11 [520/1078 (48%)]\tLoss: 449160.937500\n",
      "Train Epoch: 11 [530/1078 (49%)]\tLoss: 397298.906250\n",
      "Train Epoch: 11 [540/1078 (50%)]\tLoss: 503990.062500\n",
      "Train Epoch: 11 [550/1078 (51%)]\tLoss: 515341.562500\n",
      "Train Epoch: 11 [560/1078 (52%)]\tLoss: 490444.312500\n",
      "Train Epoch: 11 [570/1078 (53%)]\tLoss: 479637.093750\n",
      "Train Epoch: 11 [580/1078 (54%)]\tLoss: 493833.343750\n",
      "Train Epoch: 11 [590/1078 (55%)]\tLoss: 494483.500000\n",
      "Train Epoch: 11 [600/1078 (56%)]\tLoss: 286382.968750\n",
      "Train Epoch: 11 [610/1078 (57%)]\tLoss: 531950.250000\n",
      "Train Epoch: 11 [620/1078 (58%)]\tLoss: 434791.812500\n",
      "Train Epoch: 11 [630/1078 (58%)]\tLoss: 488409.156250\n",
      "Train Epoch: 11 [640/1078 (59%)]\tLoss: 480516.437500\n",
      "Train Epoch: 11 [650/1078 (60%)]\tLoss: 468776.843750\n",
      "Train Epoch: 11 [660/1078 (61%)]\tLoss: 504357.437500\n",
      "Train Epoch: 11 [670/1078 (62%)]\tLoss: 450423.500000\n",
      "Train Epoch: 11 [680/1078 (63%)]\tLoss: 358136.031250\n",
      "Train Epoch: 11 [690/1078 (64%)]\tLoss: 430487.031250\n",
      "Train Epoch: 11 [700/1078 (65%)]\tLoss: 503282.343750\n",
      "Train Epoch: 11 [710/1078 (66%)]\tLoss: 506598.500000\n",
      "Train Epoch: 11 [720/1078 (67%)]\tLoss: 440043.343750\n",
      "Train Epoch: 11 [730/1078 (68%)]\tLoss: 494933.093750\n",
      "Train Epoch: 11 [740/1078 (69%)]\tLoss: 327517.125000\n",
      "Train Epoch: 11 [750/1078 (70%)]\tLoss: 482618.593750\n",
      "Train Epoch: 11 [760/1078 (71%)]\tLoss: 375516.468750\n",
      "Train Epoch: 11 [770/1078 (71%)]\tLoss: 480591.843750\n",
      "Train Epoch: 11 [780/1078 (72%)]\tLoss: 345639.437500\n",
      "Train Epoch: 11 [790/1078 (73%)]\tLoss: 410447.125000\n",
      "Train Epoch: 11 [800/1078 (74%)]\tLoss: 498213.781250\n",
      "Train Epoch: 11 [810/1078 (75%)]\tLoss: 554738.312500\n",
      "Train Epoch: 11 [820/1078 (76%)]\tLoss: 456786.781250\n",
      "Train Epoch: 11 [830/1078 (77%)]\tLoss: 278294.218750\n",
      "Train Epoch: 11 [840/1078 (78%)]\tLoss: 329357.312500\n",
      "Train Epoch: 11 [850/1078 (79%)]\tLoss: 481737.656250\n",
      "Train Epoch: 11 [860/1078 (80%)]\tLoss: 430213.281250\n",
      "Train Epoch: 11 [870/1078 (81%)]\tLoss: 454199.062500\n",
      "Train Epoch: 11 [880/1078 (82%)]\tLoss: 528765.125000\n",
      "Train Epoch: 11 [890/1078 (83%)]\tLoss: 473517.656250\n",
      "Train Epoch: 11 [900/1078 (83%)]\tLoss: 528918.125000\n",
      "Train Epoch: 11 [910/1078 (84%)]\tLoss: 474022.218750\n",
      "Train Epoch: 11 [920/1078 (85%)]\tLoss: 410401.375000\n",
      "Train Epoch: 11 [930/1078 (86%)]\tLoss: 465195.125000\n",
      "Train Epoch: 11 [940/1078 (87%)]\tLoss: 433160.812500\n",
      "Train Epoch: 11 [950/1078 (88%)]\tLoss: 470321.062500\n",
      "Train Epoch: 11 [960/1078 (89%)]\tLoss: 447270.718750\n",
      "Train Epoch: 11 [970/1078 (90%)]\tLoss: 439234.406250\n",
      "Train Epoch: 11 [980/1078 (91%)]\tLoss: 402295.625000\n",
      "Train Epoch: 11 [990/1078 (92%)]\tLoss: 431446.000000\n",
      "Train Epoch: 11 [1000/1078 (93%)]\tLoss: 317409.062500\n",
      "Train Epoch: 11 [1010/1078 (94%)]\tLoss: 475276.187500\n",
      "Train Epoch: 11 [1020/1078 (95%)]\tLoss: 444084.187500\n",
      "Train Epoch: 11 [1030/1078 (96%)]\tLoss: 383633.218750\n",
      "Train Epoch: 11 [1040/1078 (96%)]\tLoss: 445836.343750\n",
      "Train Epoch: 11 [1050/1078 (97%)]\tLoss: 488791.593750\n",
      "Train Epoch: 11 [1060/1078 (98%)]\tLoss: 481084.000000\n",
      "Train Epoch: 11 [1070/1078 (99%)]\tLoss: 514782.343750\n",
      "Train Epoch: 12 [0/1078 (0%)]\tLoss: 448304.187500\n",
      "Train Epoch: 12 [10/1078 (1%)]\tLoss: 520780.687500\n",
      "Train Epoch: 12 [20/1078 (2%)]\tLoss: 415375.875000\n",
      "Train Epoch: 12 [30/1078 (3%)]\tLoss: 489113.531250\n",
      "Train Epoch: 12 [40/1078 (4%)]\tLoss: 398340.031250\n",
      "Train Epoch: 12 [50/1078 (5%)]\tLoss: 550315.250000\n",
      "Train Epoch: 12 [60/1078 (6%)]\tLoss: 300809.562500\n",
      "Train Epoch: 12 [70/1078 (6%)]\tLoss: 384472.500000\n",
      "Train Epoch: 12 [80/1078 (7%)]\tLoss: 431143.125000\n",
      "Train Epoch: 12 [90/1078 (8%)]\tLoss: 450727.656250\n",
      "Train Epoch: 12 [100/1078 (9%)]\tLoss: 328749.718750\n",
      "Train Epoch: 12 [110/1078 (10%)]\tLoss: 550600.062500\n",
      "Train Epoch: 12 [120/1078 (11%)]\tLoss: 550224.562500\n",
      "Train Epoch: 12 [130/1078 (12%)]\tLoss: 622415.000000\n",
      "Train Epoch: 12 [140/1078 (13%)]\tLoss: 472691.000000\n",
      "Train Epoch: 12 [150/1078 (14%)]\tLoss: 582205.312500\n",
      "Train Epoch: 12 [160/1078 (15%)]\tLoss: 526612.562500\n",
      "Train Epoch: 12 [170/1078 (16%)]\tLoss: 480414.562500\n",
      "Train Epoch: 12 [180/1078 (17%)]\tLoss: 413447.468750\n",
      "Train Epoch: 12 [190/1078 (18%)]\tLoss: 431282.906250\n",
      "Train Epoch: 12 [200/1078 (19%)]\tLoss: 466418.343750\n",
      "Train Epoch: 12 [210/1078 (19%)]\tLoss: 455171.093750\n",
      "Train Epoch: 12 [220/1078 (20%)]\tLoss: 419662.250000\n",
      "Train Epoch: 12 [230/1078 (21%)]\tLoss: 460334.875000\n",
      "Train Epoch: 12 [240/1078 (22%)]\tLoss: 451988.187500\n",
      "Train Epoch: 12 [250/1078 (23%)]\tLoss: 478007.750000\n",
      "Train Epoch: 12 [260/1078 (24%)]\tLoss: 426556.625000\n",
      "Train Epoch: 12 [270/1078 (25%)]\tLoss: 371442.406250\n",
      "Train Epoch: 12 [280/1078 (26%)]\tLoss: 248588.500000\n",
      "Train Epoch: 12 [290/1078 (27%)]\tLoss: 257466.875000\n",
      "Train Epoch: 12 [300/1078 (28%)]\tLoss: 478057.187500\n",
      "Train Epoch: 12 [310/1078 (29%)]\tLoss: 630451.062500\n",
      "Train Epoch: 12 [320/1078 (30%)]\tLoss: 505026.812500\n",
      "Train Epoch: 12 [330/1078 (31%)]\tLoss: 529571.000000\n",
      "Train Epoch: 12 [340/1078 (32%)]\tLoss: 494314.781250\n",
      "Train Epoch: 12 [350/1078 (32%)]\tLoss: 433672.031250\n",
      "Train Epoch: 12 [360/1078 (33%)]\tLoss: 485854.093750\n",
      "Train Epoch: 12 [370/1078 (34%)]\tLoss: 506743.093750\n",
      "Train Epoch: 12 [380/1078 (35%)]\tLoss: 489076.781250\n",
      "Train Epoch: 12 [390/1078 (36%)]\tLoss: 450347.437500\n",
      "Train Epoch: 12 [400/1078 (37%)]\tLoss: 350434.312500\n",
      "Train Epoch: 12 [410/1078 (38%)]\tLoss: 426121.187500\n",
      "Train Epoch: 12 [420/1078 (39%)]\tLoss: 395196.156250\n",
      "Train Epoch: 12 [430/1078 (40%)]\tLoss: 497340.531250\n",
      "Train Epoch: 12 [440/1078 (41%)]\tLoss: 380906.250000\n",
      "Train Epoch: 12 [450/1078 (42%)]\tLoss: 480935.906250\n",
      "Train Epoch: 12 [460/1078 (43%)]\tLoss: 444619.937500\n",
      "Train Epoch: 12 [470/1078 (44%)]\tLoss: 331850.718750\n",
      "Train Epoch: 12 [480/1078 (45%)]\tLoss: 473556.812500\n",
      "Train Epoch: 12 [490/1078 (45%)]\tLoss: 497346.875000\n",
      "Train Epoch: 12 [500/1078 (46%)]\tLoss: 384383.843750\n",
      "Train Epoch: 12 [510/1078 (47%)]\tLoss: 475263.000000\n",
      "Train Epoch: 12 [520/1078 (48%)]\tLoss: 346739.093750\n",
      "Train Epoch: 12 [530/1078 (49%)]\tLoss: 428280.343750\n",
      "Train Epoch: 12 [540/1078 (50%)]\tLoss: 424873.781250\n",
      "Train Epoch: 12 [550/1078 (51%)]\tLoss: 494395.156250\n",
      "Train Epoch: 12 [560/1078 (52%)]\tLoss: 450190.156250\n",
      "Train Epoch: 12 [570/1078 (53%)]\tLoss: 406313.375000\n",
      "Train Epoch: 12 [580/1078 (54%)]\tLoss: 471781.656250\n",
      "Train Epoch: 12 [590/1078 (55%)]\tLoss: 481623.187500\n",
      "Train Epoch: 12 [600/1078 (56%)]\tLoss: 501174.875000\n",
      "Train Epoch: 12 [610/1078 (57%)]\tLoss: 461219.750000\n",
      "Train Epoch: 12 [620/1078 (58%)]\tLoss: 528614.000000\n",
      "Train Epoch: 12 [630/1078 (58%)]\tLoss: 424492.281250\n",
      "Train Epoch: 12 [640/1078 (59%)]\tLoss: 443116.562500\n",
      "Train Epoch: 12 [650/1078 (60%)]\tLoss: 486833.968750\n",
      "Train Epoch: 12 [660/1078 (61%)]\tLoss: 379948.812500\n",
      "Train Epoch: 12 [670/1078 (62%)]\tLoss: 422004.468750\n",
      "Train Epoch: 12 [680/1078 (63%)]\tLoss: 315968.281250\n",
      "Train Epoch: 12 [690/1078 (64%)]\tLoss: 386512.812500\n",
      "Train Epoch: 12 [700/1078 (65%)]\tLoss: 518927.250000\n",
      "Train Epoch: 12 [710/1078 (66%)]\tLoss: 398444.843750\n",
      "Train Epoch: 12 [720/1078 (67%)]\tLoss: 490737.125000\n",
      "Train Epoch: 12 [730/1078 (68%)]\tLoss: 389269.843750\n",
      "Train Epoch: 12 [740/1078 (69%)]\tLoss: 426356.593750\n",
      "Train Epoch: 12 [750/1078 (70%)]\tLoss: 497415.812500\n",
      "Train Epoch: 12 [760/1078 (71%)]\tLoss: 439225.531250\n",
      "Train Epoch: 12 [770/1078 (71%)]\tLoss: 352125.562500\n",
      "Train Epoch: 12 [780/1078 (72%)]\tLoss: 502665.187500\n",
      "Train Epoch: 12 [790/1078 (73%)]\tLoss: 439140.687500\n",
      "Train Epoch: 12 [800/1078 (74%)]\tLoss: 353295.500000\n",
      "Train Epoch: 12 [810/1078 (75%)]\tLoss: 435739.281250\n",
      "Train Epoch: 12 [820/1078 (76%)]\tLoss: 280332.593750\n",
      "Train Epoch: 12 [830/1078 (77%)]\tLoss: 691978.375000\n",
      "Train Epoch: 12 [840/1078 (78%)]\tLoss: 561408.437500\n",
      "Train Epoch: 12 [850/1078 (79%)]\tLoss: 424250.437500\n",
      "Train Epoch: 12 [860/1078 (80%)]\tLoss: 372916.406250\n",
      "Train Epoch: 12 [870/1078 (81%)]\tLoss: 470993.218750\n",
      "Train Epoch: 12 [880/1078 (82%)]\tLoss: 474626.937500\n",
      "Train Epoch: 12 [890/1078 (83%)]\tLoss: 520292.812500\n",
      "Train Epoch: 12 [900/1078 (83%)]\tLoss: 568585.000000\n",
      "Train Epoch: 12 [910/1078 (84%)]\tLoss: 400523.156250\n",
      "Train Epoch: 12 [920/1078 (85%)]\tLoss: 527495.000000\n",
      "Train Epoch: 12 [930/1078 (86%)]\tLoss: 502371.906250\n",
      "Train Epoch: 12 [940/1078 (87%)]\tLoss: 486449.343750\n",
      "Train Epoch: 12 [950/1078 (88%)]\tLoss: 531055.437500\n",
      "Train Epoch: 12 [960/1078 (89%)]\tLoss: 516151.937500\n",
      "Train Epoch: 12 [970/1078 (90%)]\tLoss: 486808.937500\n",
      "Train Epoch: 12 [980/1078 (91%)]\tLoss: 515960.875000\n",
      "Train Epoch: 12 [990/1078 (92%)]\tLoss: 327335.531250\n",
      "Train Epoch: 12 [1000/1078 (93%)]\tLoss: 291338.218750\n",
      "Train Epoch: 12 [1010/1078 (94%)]\tLoss: 425986.062500\n",
      "Train Epoch: 12 [1020/1078 (95%)]\tLoss: 439992.937500\n",
      "Train Epoch: 12 [1030/1078 (96%)]\tLoss: 359127.468750\n",
      "Train Epoch: 12 [1040/1078 (96%)]\tLoss: 512358.531250\n",
      "Train Epoch: 12 [1050/1078 (97%)]\tLoss: 572413.437500\n",
      "Train Epoch: 12 [1060/1078 (98%)]\tLoss: 496057.656250\n",
      "Train Epoch: 12 [1070/1078 (99%)]\tLoss: 350691.281250\n",
      "Train Epoch: 13 [0/1078 (0%)]\tLoss: 514749.125000\n",
      "Train Epoch: 13 [10/1078 (1%)]\tLoss: 483800.781250\n",
      "Train Epoch: 13 [20/1078 (2%)]\tLoss: 480581.968750\n",
      "Train Epoch: 13 [30/1078 (3%)]\tLoss: 501789.781250\n",
      "Train Epoch: 13 [40/1078 (4%)]\tLoss: 416291.375000\n",
      "Train Epoch: 13 [50/1078 (5%)]\tLoss: 428068.000000\n",
      "Train Epoch: 13 [60/1078 (6%)]\tLoss: 432185.906250\n",
      "Train Epoch: 13 [70/1078 (6%)]\tLoss: 435629.562500\n",
      "Train Epoch: 13 [80/1078 (7%)]\tLoss: 399135.750000\n",
      "Train Epoch: 13 [90/1078 (8%)]\tLoss: 546328.625000\n",
      "Train Epoch: 13 [100/1078 (9%)]\tLoss: 486983.906250\n",
      "Train Epoch: 13 [110/1078 (10%)]\tLoss: 493263.281250\n",
      "Train Epoch: 13 [120/1078 (11%)]\tLoss: 456806.406250\n",
      "Train Epoch: 13 [130/1078 (12%)]\tLoss: 526182.500000\n",
      "Train Epoch: 13 [140/1078 (13%)]\tLoss: 357096.687500\n",
      "Train Epoch: 13 [150/1078 (14%)]\tLoss: 417268.593750\n",
      "Train Epoch: 13 [160/1078 (15%)]\tLoss: 351076.875000\n",
      "Train Epoch: 13 [170/1078 (16%)]\tLoss: 479956.500000\n",
      "Train Epoch: 13 [180/1078 (17%)]\tLoss: 480049.437500\n",
      "Train Epoch: 13 [190/1078 (18%)]\tLoss: 464113.343750\n",
      "Train Epoch: 13 [200/1078 (19%)]\tLoss: 469071.187500\n",
      "Train Epoch: 13 [210/1078 (19%)]\tLoss: 403313.843750\n",
      "Train Epoch: 13 [220/1078 (20%)]\tLoss: 455295.437500\n",
      "Train Epoch: 13 [230/1078 (21%)]\tLoss: 498054.812500\n",
      "Train Epoch: 13 [240/1078 (22%)]\tLoss: 441185.500000\n",
      "Train Epoch: 13 [250/1078 (23%)]\tLoss: 567761.875000\n",
      "Train Epoch: 13 [260/1078 (24%)]\tLoss: 473163.718750\n",
      "Train Epoch: 13 [270/1078 (25%)]\tLoss: 570976.625000\n",
      "Train Epoch: 13 [280/1078 (26%)]\tLoss: 451230.250000\n",
      "Train Epoch: 13 [290/1078 (27%)]\tLoss: 508615.843750\n",
      "Train Epoch: 13 [300/1078 (28%)]\tLoss: 240459.421875\n",
      "Train Epoch: 13 [310/1078 (29%)]\tLoss: 438606.281250\n",
      "Train Epoch: 13 [320/1078 (30%)]\tLoss: 527407.875000\n",
      "Train Epoch: 13 [330/1078 (31%)]\tLoss: 429107.281250\n",
      "Train Epoch: 13 [340/1078 (32%)]\tLoss: 555146.000000\n",
      "Train Epoch: 13 [350/1078 (32%)]\tLoss: 398228.093750\n",
      "Train Epoch: 13 [360/1078 (33%)]\tLoss: 491504.281250\n",
      "Train Epoch: 13 [370/1078 (34%)]\tLoss: 396201.187500\n",
      "Train Epoch: 13 [380/1078 (35%)]\tLoss: 364679.781250\n",
      "Train Epoch: 13 [390/1078 (36%)]\tLoss: 480672.062500\n",
      "Train Epoch: 13 [400/1078 (37%)]\tLoss: 339253.125000\n",
      "Train Epoch: 13 [410/1078 (38%)]\tLoss: 453564.750000\n",
      "Train Epoch: 13 [420/1078 (39%)]\tLoss: 487281.187500\n",
      "Train Epoch: 13 [430/1078 (40%)]\tLoss: 474138.906250\n",
      "Train Epoch: 13 [440/1078 (41%)]\tLoss: 431571.625000\n",
      "Train Epoch: 13 [450/1078 (42%)]\tLoss: 470809.718750\n",
      "Train Epoch: 13 [460/1078 (43%)]\tLoss: 419706.156250\n",
      "Train Epoch: 13 [470/1078 (44%)]\tLoss: 481145.312500\n",
      "Train Epoch: 13 [480/1078 (45%)]\tLoss: 442665.593750\n",
      "Train Epoch: 13 [490/1078 (45%)]\tLoss: 511654.500000\n",
      "Train Epoch: 13 [500/1078 (46%)]\tLoss: 422475.281250\n",
      "Train Epoch: 13 [510/1078 (47%)]\tLoss: 521104.218750\n",
      "Train Epoch: 13 [520/1078 (48%)]\tLoss: 512554.031250\n",
      "Train Epoch: 13 [530/1078 (49%)]\tLoss: 504374.031250\n",
      "Train Epoch: 13 [540/1078 (50%)]\tLoss: 485534.437500\n",
      "Train Epoch: 13 [550/1078 (51%)]\tLoss: 256665.343750\n",
      "Train Epoch: 13 [560/1078 (52%)]\tLoss: 434973.906250\n",
      "Train Epoch: 13 [570/1078 (53%)]\tLoss: 464829.531250\n",
      "Train Epoch: 13 [580/1078 (54%)]\tLoss: 478620.656250\n",
      "Train Epoch: 13 [590/1078 (55%)]\tLoss: 293233.968750\n",
      "Train Epoch: 13 [600/1078 (56%)]\tLoss: 442328.031250\n",
      "Train Epoch: 13 [610/1078 (57%)]\tLoss: 418975.281250\n",
      "Train Epoch: 13 [620/1078 (58%)]\tLoss: 440772.343750\n",
      "Train Epoch: 13 [630/1078 (58%)]\tLoss: 424681.031250\n",
      "Train Epoch: 13 [640/1078 (59%)]\tLoss: 521044.593750\n",
      "Train Epoch: 13 [650/1078 (60%)]\tLoss: 314995.281250\n",
      "Train Epoch: 13 [660/1078 (61%)]\tLoss: 558446.500000\n",
      "Train Epoch: 13 [670/1078 (62%)]\tLoss: 491230.562500\n",
      "Train Epoch: 13 [680/1078 (63%)]\tLoss: 517904.875000\n",
      "Train Epoch: 13 [690/1078 (64%)]\tLoss: 360656.375000\n",
      "Train Epoch: 13 [700/1078 (65%)]\tLoss: 399787.781250\n",
      "Train Epoch: 13 [710/1078 (66%)]\tLoss: 440279.156250\n",
      "Train Epoch: 13 [720/1078 (67%)]\tLoss: 256591.390625\n",
      "Train Epoch: 13 [730/1078 (68%)]\tLoss: 504593.281250\n",
      "Train Epoch: 13 [740/1078 (69%)]\tLoss: 411177.968750\n",
      "Train Epoch: 13 [750/1078 (70%)]\tLoss: 465089.000000\n",
      "Train Epoch: 13 [760/1078 (71%)]\tLoss: 425078.000000\n",
      "Train Epoch: 13 [770/1078 (71%)]\tLoss: 337310.281250\n",
      "Train Epoch: 13 [780/1078 (72%)]\tLoss: 338954.531250\n",
      "Train Epoch: 13 [790/1078 (73%)]\tLoss: 382509.281250\n",
      "Train Epoch: 13 [800/1078 (74%)]\tLoss: 485536.187500\n",
      "Train Epoch: 13 [810/1078 (75%)]\tLoss: 456465.531250\n",
      "Train Epoch: 13 [820/1078 (76%)]\tLoss: 484888.406250\n",
      "Train Epoch: 13 [830/1078 (77%)]\tLoss: 504448.843750\n",
      "Train Epoch: 13 [840/1078 (78%)]\tLoss: 404823.406250\n",
      "Train Epoch: 13 [850/1078 (79%)]\tLoss: 480999.062500\n",
      "Train Epoch: 13 [860/1078 (80%)]\tLoss: 438311.812500\n",
      "Train Epoch: 13 [870/1078 (81%)]\tLoss: 446469.031250\n",
      "Train Epoch: 13 [880/1078 (82%)]\tLoss: 530133.437500\n",
      "Train Epoch: 13 [890/1078 (83%)]\tLoss: 428973.593750\n",
      "Train Epoch: 13 [900/1078 (83%)]\tLoss: 418335.750000\n",
      "Train Epoch: 13 [910/1078 (84%)]\tLoss: 460455.093750\n",
      "Train Epoch: 13 [920/1078 (85%)]\tLoss: 509802.093750\n",
      "Train Epoch: 13 [930/1078 (86%)]\tLoss: 557754.000000\n",
      "Train Epoch: 13 [940/1078 (87%)]\tLoss: 369585.156250\n",
      "Train Epoch: 13 [950/1078 (88%)]\tLoss: 409692.062500\n",
      "Train Epoch: 13 [960/1078 (89%)]\tLoss: 355851.625000\n",
      "Train Epoch: 13 [970/1078 (90%)]\tLoss: 459818.906250\n",
      "Train Epoch: 13 [980/1078 (91%)]\tLoss: 422231.781250\n",
      "Train Epoch: 13 [990/1078 (92%)]\tLoss: 577201.062500\n",
      "Train Epoch: 13 [1000/1078 (93%)]\tLoss: 501124.812500\n",
      "Train Epoch: 13 [1010/1078 (94%)]\tLoss: 302782.437500\n",
      "Train Epoch: 13 [1020/1078 (95%)]\tLoss: 307611.875000\n",
      "Train Epoch: 13 [1030/1078 (96%)]\tLoss: 530370.937500\n",
      "Train Epoch: 13 [1040/1078 (96%)]\tLoss: 534289.687500\n",
      "Train Epoch: 13 [1050/1078 (97%)]\tLoss: 486996.500000\n",
      "Train Epoch: 13 [1060/1078 (98%)]\tLoss: 380095.531250\n",
      "Train Epoch: 13 [1070/1078 (99%)]\tLoss: 257206.953125\n",
      "Train Epoch: 14 [0/1078 (0%)]\tLoss: 462037.093750\n",
      "Train Epoch: 14 [10/1078 (1%)]\tLoss: 396653.968750\n",
      "Train Epoch: 14 [20/1078 (2%)]\tLoss: 389456.718750\n",
      "Train Epoch: 14 [30/1078 (3%)]\tLoss: 479793.031250\n",
      "Train Epoch: 14 [40/1078 (4%)]\tLoss: 444576.531250\n",
      "Train Epoch: 14 [50/1078 (5%)]\tLoss: 548005.937500\n",
      "Train Epoch: 14 [60/1078 (6%)]\tLoss: 414270.406250\n",
      "Train Epoch: 14 [70/1078 (6%)]\tLoss: 491856.625000\n",
      "Train Epoch: 14 [80/1078 (7%)]\tLoss: 536077.125000\n",
      "Train Epoch: 14 [90/1078 (8%)]\tLoss: 448664.593750\n",
      "Train Epoch: 14 [100/1078 (9%)]\tLoss: 474114.593750\n",
      "Train Epoch: 14 [110/1078 (10%)]\tLoss: 336928.906250\n",
      "Train Epoch: 14 [120/1078 (11%)]\tLoss: 469867.750000\n",
      "Train Epoch: 14 [130/1078 (12%)]\tLoss: 486449.468750\n",
      "Train Epoch: 14 [140/1078 (13%)]\tLoss: 472344.218750\n",
      "Train Epoch: 14 [150/1078 (14%)]\tLoss: 496503.312500\n",
      "Train Epoch: 14 [160/1078 (15%)]\tLoss: 317471.343750\n",
      "Train Epoch: 14 [170/1078 (16%)]\tLoss: 492620.937500\n",
      "Train Epoch: 14 [180/1078 (17%)]\tLoss: 444140.718750\n",
      "Train Epoch: 14 [190/1078 (18%)]\tLoss: 499220.343750\n",
      "Train Epoch: 14 [200/1078 (19%)]\tLoss: 398704.875000\n",
      "Train Epoch: 14 [210/1078 (19%)]\tLoss: 438530.031250\n",
      "Train Epoch: 14 [220/1078 (20%)]\tLoss: 434032.437500\n",
      "Train Epoch: 14 [230/1078 (21%)]\tLoss: 461595.281250\n",
      "Train Epoch: 14 [240/1078 (22%)]\tLoss: 410649.562500\n",
      "Train Epoch: 14 [250/1078 (23%)]\tLoss: 506461.000000\n",
      "Train Epoch: 14 [260/1078 (24%)]\tLoss: 589445.750000\n",
      "Train Epoch: 14 [270/1078 (25%)]\tLoss: 488283.156250\n",
      "Train Epoch: 14 [280/1078 (26%)]\tLoss: 553614.875000\n",
      "Train Epoch: 14 [290/1078 (27%)]\tLoss: 424705.500000\n",
      "Train Epoch: 14 [300/1078 (28%)]\tLoss: 455829.437500\n",
      "Train Epoch: 14 [310/1078 (29%)]\tLoss: 548024.937500\n",
      "Train Epoch: 14 [320/1078 (30%)]\tLoss: 487729.593750\n",
      "Train Epoch: 14 [330/1078 (31%)]\tLoss: 383848.656250\n",
      "Train Epoch: 14 [340/1078 (32%)]\tLoss: 337827.000000\n",
      "Train Epoch: 14 [350/1078 (32%)]\tLoss: 299680.000000\n",
      "Train Epoch: 14 [360/1078 (33%)]\tLoss: 437109.625000\n",
      "Train Epoch: 14 [370/1078 (34%)]\tLoss: 293333.531250\n",
      "Train Epoch: 14 [380/1078 (35%)]\tLoss: 400097.156250\n",
      "Train Epoch: 14 [390/1078 (36%)]\tLoss: 388745.093750\n",
      "Train Epoch: 14 [400/1078 (37%)]\tLoss: 387361.343750\n",
      "Train Epoch: 14 [410/1078 (38%)]\tLoss: 464383.062500\n",
      "Train Epoch: 14 [420/1078 (39%)]\tLoss: 411812.875000\n",
      "Train Epoch: 14 [430/1078 (40%)]\tLoss: 354272.312500\n",
      "Train Epoch: 14 [440/1078 (41%)]\tLoss: 467028.781250\n",
      "Train Epoch: 14 [450/1078 (42%)]\tLoss: 408188.812500\n",
      "Train Epoch: 14 [460/1078 (43%)]\tLoss: 257837.515625\n",
      "Train Epoch: 14 [470/1078 (44%)]\tLoss: 370868.812500\n",
      "Train Epoch: 14 [480/1078 (45%)]\tLoss: 380143.500000\n",
      "Train Epoch: 14 [490/1078 (45%)]\tLoss: 436743.593750\n",
      "Train Epoch: 14 [500/1078 (46%)]\tLoss: 478254.562500\n",
      "Train Epoch: 14 [510/1078 (47%)]\tLoss: 397037.406250\n",
      "Train Epoch: 14 [520/1078 (48%)]\tLoss: 349133.875000\n",
      "Train Epoch: 14 [530/1078 (49%)]\tLoss: 362174.062500\n",
      "Train Epoch: 14 [540/1078 (50%)]\tLoss: 412043.406250\n",
      "Train Epoch: 14 [550/1078 (51%)]\tLoss: 415459.781250\n",
      "Train Epoch: 14 [560/1078 (52%)]\tLoss: 485075.656250\n",
      "Train Epoch: 14 [570/1078 (53%)]\tLoss: 468946.625000\n",
      "Train Epoch: 14 [580/1078 (54%)]\tLoss: 465106.750000\n",
      "Train Epoch: 14 [590/1078 (55%)]\tLoss: 495165.468750\n",
      "Train Epoch: 14 [600/1078 (56%)]\tLoss: 458789.187500\n",
      "Train Epoch: 14 [610/1078 (57%)]\tLoss: 504411.875000\n",
      "Train Epoch: 14 [620/1078 (58%)]\tLoss: 306982.125000\n",
      "Train Epoch: 14 [630/1078 (58%)]\tLoss: 370477.906250\n",
      "Train Epoch: 14 [640/1078 (59%)]\tLoss: 374402.468750\n",
      "Train Epoch: 14 [650/1078 (60%)]\tLoss: 424446.218750\n",
      "Train Epoch: 14 [660/1078 (61%)]\tLoss: 372364.625000\n",
      "Train Epoch: 14 [670/1078 (62%)]\tLoss: 429860.718750\n",
      "Train Epoch: 14 [680/1078 (63%)]\tLoss: 430207.593750\n",
      "Train Epoch: 14 [690/1078 (64%)]\tLoss: 410484.531250\n",
      "Train Epoch: 14 [700/1078 (65%)]\tLoss: 433752.593750\n",
      "Train Epoch: 14 [710/1078 (66%)]\tLoss: 412458.406250\n",
      "Train Epoch: 14 [720/1078 (67%)]\tLoss: 285466.218750\n",
      "Train Epoch: 14 [730/1078 (68%)]\tLoss: 559579.250000\n",
      "Train Epoch: 14 [740/1078 (69%)]\tLoss: 393389.531250\n",
      "Train Epoch: 14 [750/1078 (70%)]\tLoss: 359559.031250\n",
      "Train Epoch: 14 [760/1078 (71%)]\tLoss: 478757.812500\n",
      "Train Epoch: 14 [770/1078 (71%)]\tLoss: 494601.593750\n",
      "Train Epoch: 14 [780/1078 (72%)]\tLoss: 338089.718750\n",
      "Train Epoch: 14 [790/1078 (73%)]\tLoss: 443584.718750\n",
      "Train Epoch: 14 [800/1078 (74%)]\tLoss: 339285.062500\n",
      "Train Epoch: 14 [810/1078 (75%)]\tLoss: 523979.062500\n",
      "Train Epoch: 14 [820/1078 (76%)]\tLoss: 455876.750000\n",
      "Train Epoch: 14 [830/1078 (77%)]\tLoss: 523524.843750\n",
      "Train Epoch: 14 [840/1078 (78%)]\tLoss: 502902.156250\n",
      "Train Epoch: 14 [850/1078 (79%)]\tLoss: 478383.093750\n",
      "Train Epoch: 14 [860/1078 (80%)]\tLoss: 295722.500000\n",
      "Train Epoch: 14 [870/1078 (81%)]\tLoss: 327042.250000\n",
      "Train Epoch: 14 [880/1078 (82%)]\tLoss: 438237.250000\n",
      "Train Epoch: 14 [890/1078 (83%)]\tLoss: 370804.937500\n",
      "Train Epoch: 14 [900/1078 (83%)]\tLoss: 513419.468750\n",
      "Train Epoch: 14 [910/1078 (84%)]\tLoss: 292036.625000\n",
      "Train Epoch: 14 [920/1078 (85%)]\tLoss: 474472.312500\n",
      "Train Epoch: 14 [930/1078 (86%)]\tLoss: 505079.250000\n",
      "Train Epoch: 14 [940/1078 (87%)]\tLoss: 477363.218750\n",
      "Train Epoch: 14 [950/1078 (88%)]\tLoss: 472494.593750\n",
      "Train Epoch: 14 [960/1078 (89%)]\tLoss: 415734.218750\n",
      "Train Epoch: 14 [970/1078 (90%)]\tLoss: 531839.812500\n",
      "Train Epoch: 14 [980/1078 (91%)]\tLoss: 367425.343750\n",
      "Train Epoch: 14 [990/1078 (92%)]\tLoss: 521041.093750\n",
      "Train Epoch: 14 [1000/1078 (93%)]\tLoss: 401176.656250\n",
      "Train Epoch: 14 [1010/1078 (94%)]\tLoss: 460250.500000\n",
      "Train Epoch: 14 [1020/1078 (95%)]\tLoss: 406667.937500\n",
      "Train Epoch: 14 [1030/1078 (96%)]\tLoss: 367387.156250\n",
      "Train Epoch: 14 [1040/1078 (96%)]\tLoss: 486564.343750\n",
      "Train Epoch: 14 [1050/1078 (97%)]\tLoss: 522233.156250\n",
      "Train Epoch: 14 [1060/1078 (98%)]\tLoss: 244983.140625\n",
      "Train Epoch: 14 [1070/1078 (99%)]\tLoss: 431215.812500\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have defined train_loader (your data loader for training data)\n",
    "\n",
    "label = torch.tensor(labels)\n",
    "music = torch.tensor(music)\n",
    "\n",
    "# data\n",
    "dataset = TensorDataset(music, label)\n",
    "dataloader = DataLoader(dataset, shuffle=True)\n",
    "\n",
    "# Set number of epochs and log interval\n",
    "num_epochs = 15\n",
    "log_interval = 10\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "        train(epoch,dataloader,log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_shape:torch.Size([1078, 4])\n",
      "musci_shape:torch.Size([1078, 500, 3])\n"
     ]
    }
   ],
   "source": [
    "print(f\"label_shape:{label.shape}\") \n",
    "print(f\"musci_shape:{music.shape}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7, 1, 3], [42, 50, 119], [29, 25, 58], [1, -2, -6], [58, 64, 152], [-11, -14, -32], [4, -5, -13], [-30, -27, -65], [-35, -33, -78], [-22, -24, -57], [5, 11, 27], [-25, -27, -63], [-5, -9, -20], [18, 22, 53], [-5, -6, -15], [60, 58, 136], [46, 46, 108], [-6, 0, 0], [4, 4, 10], [76, 74, 175], [61, 65, 153], [-36, -34, -79], [2, -6, -13], [-19, -18, -43], [-37, -33, -78], [26, 31, 72], [-26, -28, -67], [-18, -21, -49], [50, 44, 105], [-13, -13, -32], [-33, -28, -67], [-16, -11, -25], [-44, -44, -104], [-15, -12, -29], [-43, -41, -97], [65, 59, 139], [31, 40, 95], [-26, -32, -75], [24, 23, 54], [0, 4, 9], [-44, -43, -103], [76, 73, 173], [17, 5, 13], [-42, -40, -95], [21, 34, 79], [-55, -45, -106], [-7, -4, -9], [59, 58, 138], [-10, -14, -32], [-39, -30, -70], [-28, -35, -83], [16, 15, 35], [-27, -28, -67], [-14, -16, -38], [-14, -19, -45], [-32, -27, -63], [-70, -63, -149], [17, 17, 41], [-7, -12, -28], [-4, 1, 2], [30, 31, 73], [-49, -47, -112], [-22, -19, -44], [-12, -8, -20], [33, 17, 40], [11, 4, 10], [32, 30, 70], [41, 44, 103], [-36, -39, -93], [-54, -52, -123], [77, 74, 174], [-9, -13, -31], [22, 23, 54], [18, 19, 44], [-30, -24, -58], [-43, -39, -92], [63, 55, 131], [35, 23, 54], [-15, -22, -51], [46, 47, 112], [20, 16, 38], [-53, -49, -116], [35, 33, 77], [-14, -18, -43], [27, 27, 63], [17, 18, 43], [-9, -19, -44], [11, 12, 30], [4, 5, 12], [-1, 4, 8], [2, 9, 21], [-50, -53, -126], [-51, -52, -124], [8, 12, 28], [0, 1, 2], [19, 22, 53], [32, 34, 80], [-52, -50, -117], [11, 19, 45], [9, 14, 32], [-3, -6, -15], [-33, -33, -77], [67, 70, 166], [33, 32, 77], [-26, -21, -51], [20, 10, 24], [14, 14, 34], [-7, -7, -16], [-91, -94, -222], [-44, -44, -104], [-13, -11, -26], [-44, -35, -83], [-30, -23, -55], [-4, -5, -12], [-61, -60, -143], [24, 20, 48], [-45, -47, -111], [-44, -41, -97], [16, 8, 20], [-4, -2, -6], [30, 37, 88], [85, 89, 210], [41, 39, 91], [75, 69, 163], [-2, 7, 16], [42, 48, 114], [-50, -52, -122], [-14, -20, -48], [5, 3, 8], [3, 7, 17], [-12, -14, -32], [44, 42, 99], [32, 40, 94], [-56, -56, -132], [-31, -23, -55], [-13, -5, -11], [25, 26, 62], [38, 44, 105], [-4, -9, -22], [-12, -21, -50], [24, 29, 69], [1, 2, 4], [2, 1, 3], [-2, 4, 9], [-44, -42, -100], [23, 21, 49], [-42, -36, -85], [-40, -36, -86], [-37, -31, -72], [-14, -17, -41], [13, 4, 10], [-33, -36, -85], [-24, -21, -49], [-6, -5, -13], [3, 4, 8], [-25, -18, -42], [-29, -29, -68], [-41, -46, -108], [-17, -19, -45], [27, 27, 64], [-71, -68, -161], [-7, -5, -12], [71, 69, 163], [35, 31, 73], [13, 12, 28], [7, 10, 24], [26, 21, 50], [3, 6, 14], [-11, -8, -19], [-48, -48, -114], [67, 73, 173], [-8, -8, -19], [64, 60, 141], [57, 53, 125], [-41, -48, -114], [32, 36, 85], [71, 72, 170], [-34, -32, -75], [-42, -50, -117], [-14, -20, -47], [73, 71, 169], [-36, -34, -79], [23, 17, 41], [-46, -41, -98], [-19, -20, -47], [-9, -4, -10], [19, 21, 49], [-46, -53, -126], [-12, -11, -26], [10, 22, 53], [-19, -27, -65], [9, 11, 26], [17, 16, 39], [41, 46, 108], [1, -4, -8], [-44, -42, -99], [-58, -58, -138], [22, 14, 33], [-55, -48, -114], [-23, -22, -53], [23, 21, 49], [-45, -40, -94], [-3, -7, -16], [-43, -35, -83], [16, 20, 47], [4, 2, 5], [6, 6, 15], [-51, -54, -128], [-31, -35, -83], [93, 96, 227], [4, -3, -6], [-42, -37, -87], [-9, -1, -3], [26, 21, 51], [-40, -35, -83], [1, 2, 4], [3, 8, 18], [45, 53, 124], [-58, -57, -135], [13, 16, 38], [57, 57, 134], [-28, -27, -63], [-89, -81, -192], [18, 14, 34], [14, 12, 28], [-19, -18, -42], [-59, -57, -135], [22, 23, 55], [-34, -36, -85], [-12, -14, -33], [-2, 6, 13], [-60, -58, -137], [-5, -3, -7], [-5, -12, -27], [-35, -40, -94], [-21, -21, -50], [-5, -12, -28], [-23, -24, -57], [-24, -13, -31], [27, 26, 62], [26, 25, 58], [41, 41, 96], [-20, -22, -51], [28, 21, 50], [-40, -50, -118], [-44, -42, -100], [-4, -5, -11], [33, 28, 65], [68, 69, 163], [-24, -24, -57], [-60, -55, -130], [3, 8, 19], [-25, -19, -46], [42, 43, 102], [-31, -36, -86], [-10, -11, -26], [35, 43, 100], [28, 35, 84], [-37, -37, -88], [6, 4, 10], [-17, -11, -27], [-30, -26, -61], [0, 4, 10], [-72, -72, -169], [-15, -12, -28], [-22, -16, -38], [-44, -34, -79], [22, 24, 56], [24, 25, 59], [-38, -43, -102], [-25, -21, -50], [-11, -6, -14], [8, 3, 8], [70, 59, 139], [91, 89, 210], [2, 1, 2], [-66, -72, -169], [85, 86, 202], [-59, -53, -125], [-3, -8, -18], [18, 23, 54], [38, 40, 93], [29, 25, 59], [-23, -26, -61], [-40, -42, -99], [-35, -40, -95], [14, 21, 50], [20, 22, 53], [57, 55, 130], [36, 36, 85], [-53, -48, -114], [15, 11, 26], [-4, -10, -24], [-16, -3, -7], [26, 28, 66], [7, 5, 11], [4, 8, 20], [4, 8, 19], [-42, -45, -106], [-6, -4, -9], [3, 6, 14], [38, 32, 76], [34, 35, 83], [-30, -22, -53], [7, 13, 30], [-20, -7, -16], [6, 14, 34], [40, 44, 103], [-19, -21, -50], [-11, -13, -32], [-19, -20, -48], [-36, -32, -76], [76, 73, 173], [43, 46, 108], [-6, -8, -19], [-8, -8, -18], [17, 13, 30], [12, 16, 37], [-11, -14, -34], [22, 27, 64], [44, 48, 114], [-3, -10, -23], [-40, -39, -92], [-19, -18, -43], [-39, -43, -101], [-66, -71, -168], [0, -1, -3], [3, 7, 17], [30, 25, 58], [0, -1, -2], [25, 23, 54], [8, 4, 10], [-36, -37, -88], [-2, 3, 8], [27, 29, 68], [4, 6, 15], [-22, -18, -42], [-36, -30, -71], [44, 43, 101], [5, 8, 19], [-27, -20, -47], [42, 39, 92], [-77, -78, -184], [-22, -21, -49], [67, 70, 165], [38, 33, 77], [9, 11, 25], [-68, -69, -163], [-11, -10, -23], [-37, -28, -67], [-39, -41, -97], [-3, -1, -2], [-13, -14, -32], [-16, -19, -46], [-13, -12, -27], [89, 88, 207], [-9, -8, -20], [19, 16, 38], [41, 34, 80], [-49, -53, -124], [-79, -79, -188], [-39, -42, -99], [-33, -37, -87], [40, 46, 108], [12, 13, 31], [4, -2, -4], [-77, -72, -170], [6, 9, 21], [-5, -11, -26], [-23, -22, -52], [-26, -22, -51], [52, 50, 118], [-52, -56, -133], [26, 34, 80], [-27, -30, -72], [-3, -5, -11], [-47, -45, -107], [5, 7, 17], [-27, -26, -61], [28, 31, 73], [19, 11, 26], [34, 34, 79], [5, 2, 6], [27, 33, 78], [-4, 6, 15], [-43, -38, -90], [74, 80, 190], [-19, -20, -46], [46, 49, 116], [-26, -28, -66], [-33, -33, -78], [17, 17, 41], [-66, -63, -149], [-12, -7, -16], [-41, -37, -88], [-62, -63, -148], [-4, 0, 0], [58, 59, 139], [-37, -38, -89], [-4, -6, -13], [-10, -17, -40], [-20, -15, -35], [16, 11, 27], [59, 57, 135], [36, 32, 76], [-3, 2, 4], [20, 23, 53], [3, -5, -13], [27, 29, 68], [38, 36, 85], [11, 16, 39], [29, 25, 58], [-8, -3, -6], [-35, -36, -84], [-44, -40, -94], [-58, -53, -126], [-25, -18, -41], [78, 70, 166], [-3, 7, 17], [4, 2, 4], [10, 13, 31], [-5, -2, -4], [-54, -53, -124], [-24, -19, -45], [-25, -24, -57], [-14, -10, -23], [28, 28, 66], [48, 42, 100], [-55, -48, -114], [38, 41, 96], [-15, -19, -45], [24, 25, 59], [79, 78, 185], [23, 28, 65], [-16, -18, -44], [-27, -24, -56], [20, 16, 38], [-60, -65, -153], [-16, -21, -49], [-5, 0, -1], [32, 34, 82], [6, 6, 15], [46, 53, 125], [33, 38, 89], [24, 24, 57], [57, 62, 146], [35, 29, 68], [-6, 3, 7], [49, 44, 104], [43, 40, 95], [28, 26, 62], [-43, -36, -86], [41, 34, 81], [-13, -14, -33], [14, 18, 42], [27, 24, 57], [-63, -58, -138], [43, 47, 110], [-21, -11, -27], [-34, -30, -70], [4, 7, 16], [-24, -27, -63], [-31, -31, -72], [24, 30, 71], [14, 10, 23], [-12, -11, -25], [-37, -41, -96], [24, 32, 75], [-27, -23, -54], [62, 64, 151], [-34, -31, -73], [14, 23, 54], [-26, -28, -67], [38, 39, 92], [-52, -53, -124], [58, 57, 134], [-18, -22, -53], [-64, -66, -155], [-46, -44, -105], [-12, -17, -39], [-62, -62, -147], [-30, -33, -77], [19, 11, 27], [89, 90, 213], [7, 2, 6], [-15, -14, -34], [-29, -24, -57], [6, 12, 27], [-25, -31, -72], [4, 6, 14], [-30, -38, -91], [7, 12, 28], [13, 12, 29], [10, 11, 27], [-51, -57, -135], [-51, -50, -118], [50, 47, 111], [101, 104, 245], [-3, -3, -7], [-18, -25, -59]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a trained decoder model\n",
    "# TODO change outputshape\n",
    "decoder = Decoder(latent_size=4, hidden_size=252, output_size= 500 * 3, num_classes=4)\n",
    "\n",
    "# Sample from the latent space (you can use any method to sample from a distribution, such as normal distribution)\n",
    "latent_sample = torch.randn(1, 4)  # Assuming batch size of 1\n",
    "\n",
    "target_label = [0,0,0,1]\n",
    "target_label_tensor = torch.tensor(target_label, dtype=torch.float32).unsqueeze(0)\n",
    "# Pass the sampled latent vectors through the decoder\n",
    "with torch.no_grad():\n",
    "    generated_data = decoder(latent_sample,target_label_tensor)\n",
    "\n",
    "# The generated_data tensor contains the generated data points\n",
    "generated_data = generated_data.round().int()\n",
    "generated_data = generated_data.reshape(500 , 3) # TODO change outputshape \n",
    "generated_data = generated_data.tolist()\n",
    "print(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(generated_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def midi_music(events, output_file):\n",
    "    mid = mido.MidiFile()\n",
    "\n",
    "    # Create track for metadata (track 0)\n",
    "    metadata_track = mido.MidiTrack()\n",
    "    mid.tracks.append(metadata_track)\n",
    "\n",
    "    # Set the tempo to default 120 BPM in track 0\n",
    "    metadata_track.append(mido.MetaMessage('set_tempo', tempo=500000))\n",
    "\n",
    "    # Create track for music data (track 1)\n",
    "    music_track = mido.MidiTrack()\n",
    "    mid.tracks.append(music_track)\n",
    "\n",
    "    # Iterate through the events and convert them to MIDI messages for track 1\n",
    "    for event in events:\n",
    "        note, velocity, time = event\n",
    "        if note == 0 and velocity == 0 and time == 0:\n",
    "            break\n",
    "        if note < 0:\n",
    "            note = note * -1\n",
    "        if note > 108:\n",
    "            left = random.randint(40, 70)\n",
    "            note = random.randint(left, 108)\n",
    "        if velocity < 0:\n",
    "            velocity = 0\n",
    "        if velocity > 127:\n",
    "            velocity = 0\n",
    "        if time < 0:\n",
    "            time = random.randint(0, 30)\n",
    "        if time > 1000:\n",
    "            time = random.randint(300, 600)\n",
    "        # Create a note_on message for track 1\n",
    "        note_on = mido.Message('note_on', note=note, velocity=velocity, time=time)\n",
    "        music_track.append(note_on)\n",
    "\n",
    "    # Save the MIDI file\n",
    "    mid.save(output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MIDI events / list format\n",
    "events = generated_data\n",
    "\n",
    "# Output MIDI file name\n",
    "output_file = \"output_label2.mid\"\n",
    "\n",
    "# Reconstruct MIDI and save to file\n",
    "midi_music(events, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0: \n",
      "MetaMessage('set_tempo', tempo=500000, time=0)\n",
      "MetaMessage('end_of_track', time=0)\n",
      "Track 1: \n",
      "note_on channel=0 note=7 velocity=1 time=3\n",
      "note_on channel=0 note=42 velocity=50 time=119\n",
      "note_on channel=0 note=29 velocity=25 time=58\n",
      "note_on channel=0 note=1 velocity=0 time=6\n",
      "note_on channel=0 note=58 velocity=64 time=152\n",
      "note_on channel=0 note=11 velocity=0 time=2\n",
      "note_on channel=0 note=4 velocity=0 time=1\n",
      "note_on channel=0 note=30 velocity=0 time=1\n",
      "note_on channel=0 note=35 velocity=0 time=10\n",
      "note_on channel=0 note=22 velocity=0 time=27\n",
      "note_on channel=0 note=5 velocity=11 time=27\n",
      "note_on channel=0 note=25 velocity=0 time=22\n",
      "note_on channel=0 note=5 velocity=0 time=17\n",
      "note_on channel=0 note=18 velocity=22 time=53\n",
      "note_on channel=0 note=5 velocity=0 time=9\n",
      "note_on channel=0 note=60 velocity=58 time=136\n",
      "note_on channel=0 note=46 velocity=46 time=108\n",
      "note_on channel=0 note=6 velocity=0 time=0\n",
      "note_on channel=0 note=4 velocity=4 time=10\n",
      "note_on channel=0 note=76 velocity=74 time=175\n",
      "note_on channel=0 note=61 velocity=65 time=153\n",
      "note_on channel=0 note=36 velocity=0 time=3\n",
      "note_on channel=0 note=2 velocity=0 time=9\n",
      "note_on channel=0 note=19 velocity=0 time=29\n",
      "note_on channel=0 note=37 velocity=0 time=10\n",
      "note_on channel=0 note=26 velocity=31 time=72\n",
      "note_on channel=0 note=26 velocity=0 time=21\n",
      "note_on channel=0 note=18 velocity=0 time=17\n",
      "note_on channel=0 note=50 velocity=44 time=105\n",
      "note_on channel=0 note=13 velocity=0 time=16\n",
      "note_on channel=0 note=33 velocity=0 time=14\n",
      "note_on channel=0 note=16 velocity=0 time=26\n",
      "note_on channel=0 note=44 velocity=0 time=25\n",
      "note_on channel=0 note=15 velocity=0 time=7\n",
      "note_on channel=0 note=43 velocity=0 time=15\n",
      "note_on channel=0 note=65 velocity=59 time=139\n",
      "note_on channel=0 note=31 velocity=40 time=95\n",
      "note_on channel=0 note=26 velocity=0 time=28\n",
      "note_on channel=0 note=24 velocity=23 time=54\n",
      "note_on channel=0 note=0 velocity=4 time=9\n",
      "note_on channel=0 note=44 velocity=0 time=20\n",
      "note_on channel=0 note=76 velocity=73 time=173\n",
      "note_on channel=0 note=17 velocity=5 time=13\n",
      "note_on channel=0 note=42 velocity=0 time=13\n",
      "note_on channel=0 note=21 velocity=34 time=79\n",
      "note_on channel=0 note=55 velocity=0 time=16\n",
      "note_on channel=0 note=7 velocity=0 time=27\n",
      "note_on channel=0 note=59 velocity=58 time=138\n",
      "note_on channel=0 note=10 velocity=0 time=11\n",
      "note_on channel=0 note=39 velocity=0 time=6\n",
      "note_on channel=0 note=28 velocity=0 time=8\n",
      "note_on channel=0 note=16 velocity=15 time=35\n",
      "note_on channel=0 note=27 velocity=0 time=20\n",
      "note_on channel=0 note=14 velocity=0 time=11\n",
      "note_on channel=0 note=14 velocity=0 time=1\n",
      "note_on channel=0 note=32 velocity=0 time=16\n",
      "note_on channel=0 note=70 velocity=0 time=20\n",
      "note_on channel=0 note=17 velocity=17 time=41\n",
      "note_on channel=0 note=7 velocity=0 time=30\n",
      "note_on channel=0 note=4 velocity=1 time=2\n",
      "note_on channel=0 note=30 velocity=31 time=73\n",
      "note_on channel=0 note=49 velocity=0 time=25\n",
      "note_on channel=0 note=22 velocity=0 time=14\n",
      "note_on channel=0 note=12 velocity=0 time=5\n",
      "note_on channel=0 note=33 velocity=17 time=40\n",
      "note_on channel=0 note=11 velocity=4 time=10\n",
      "note_on channel=0 note=32 velocity=30 time=70\n",
      "note_on channel=0 note=41 velocity=44 time=103\n",
      "note_on channel=0 note=36 velocity=0 time=19\n",
      "note_on channel=0 note=54 velocity=0 time=8\n",
      "note_on channel=0 note=77 velocity=74 time=174\n",
      "note_on channel=0 note=9 velocity=0 time=12\n",
      "note_on channel=0 note=22 velocity=23 time=54\n",
      "note_on channel=0 note=18 velocity=19 time=44\n",
      "note_on channel=0 note=30 velocity=0 time=14\n",
      "note_on channel=0 note=43 velocity=0 time=10\n",
      "note_on channel=0 note=63 velocity=55 time=131\n",
      "note_on channel=0 note=35 velocity=23 time=54\n",
      "note_on channel=0 note=15 velocity=0 time=5\n",
      "note_on channel=0 note=46 velocity=47 time=112\n",
      "note_on channel=0 note=20 velocity=16 time=38\n",
      "note_on channel=0 note=53 velocity=0 time=8\n",
      "note_on channel=0 note=35 velocity=33 time=77\n",
      "note_on channel=0 note=14 velocity=0 time=25\n",
      "note_on channel=0 note=27 velocity=27 time=63\n",
      "note_on channel=0 note=17 velocity=18 time=43\n",
      "note_on channel=0 note=9 velocity=0 time=17\n",
      "note_on channel=0 note=11 velocity=12 time=30\n",
      "note_on channel=0 note=4 velocity=5 time=12\n",
      "note_on channel=0 note=1 velocity=4 time=8\n",
      "note_on channel=0 note=2 velocity=9 time=21\n",
      "note_on channel=0 note=50 velocity=0 time=15\n",
      "note_on channel=0 note=51 velocity=0 time=4\n",
      "note_on channel=0 note=8 velocity=12 time=28\n",
      "note_on channel=0 note=0 velocity=1 time=2\n",
      "note_on channel=0 note=19 velocity=22 time=53\n",
      "note_on channel=0 note=32 velocity=34 time=80\n",
      "note_on channel=0 note=52 velocity=0 time=7\n",
      "note_on channel=0 note=11 velocity=19 time=45\n",
      "note_on channel=0 note=9 velocity=14 time=32\n",
      "note_on channel=0 note=3 velocity=0 time=15\n",
      "note_on channel=0 note=33 velocity=0 time=27\n",
      "note_on channel=0 note=67 velocity=70 time=166\n",
      "note_on channel=0 note=33 velocity=32 time=77\n",
      "note_on channel=0 note=26 velocity=0 time=25\n",
      "note_on channel=0 note=20 velocity=10 time=24\n",
      "note_on channel=0 note=14 velocity=14 time=34\n",
      "note_on channel=0 note=7 velocity=0 time=23\n",
      "note_on channel=0 note=91 velocity=0 time=13\n",
      "note_on channel=0 note=44 velocity=0 time=15\n",
      "note_on channel=0 note=13 velocity=0 time=30\n",
      "note_on channel=0 note=44 velocity=0 time=30\n",
      "note_on channel=0 note=30 velocity=0 time=24\n",
      "note_on channel=0 note=4 velocity=0 time=23\n",
      "note_on channel=0 note=61 velocity=0 time=2\n",
      "note_on channel=0 note=24 velocity=20 time=48\n",
      "note_on channel=0 note=45 velocity=0 time=30\n",
      "note_on channel=0 note=44 velocity=0 time=5\n",
      "note_on channel=0 note=16 velocity=8 time=20\n",
      "note_on channel=0 note=4 velocity=0 time=19\n",
      "note_on channel=0 note=30 velocity=37 time=88\n",
      "note_on channel=0 note=85 velocity=89 time=210\n",
      "note_on channel=0 note=41 velocity=39 time=91\n",
      "note_on channel=0 note=75 velocity=69 time=163\n",
      "note_on channel=0 note=2 velocity=7 time=16\n",
      "note_on channel=0 note=42 velocity=48 time=114\n",
      "note_on channel=0 note=50 velocity=0 time=27\n",
      "note_on channel=0 note=14 velocity=0 time=19\n",
      "note_on channel=0 note=5 velocity=3 time=8\n",
      "note_on channel=0 note=3 velocity=7 time=17\n",
      "note_on channel=0 note=12 velocity=0 time=11\n",
      "note_on channel=0 note=44 velocity=42 time=99\n",
      "note_on channel=0 note=32 velocity=40 time=94\n",
      "note_on channel=0 note=56 velocity=0 time=1\n",
      "note_on channel=0 note=31 velocity=0 time=3\n",
      "note_on channel=0 note=13 velocity=0 time=25\n",
      "note_on channel=0 note=25 velocity=26 time=62\n",
      "note_on channel=0 note=38 velocity=44 time=105\n",
      "note_on channel=0 note=4 velocity=0 time=9\n",
      "note_on channel=0 note=12 velocity=0 time=0\n",
      "note_on channel=0 note=24 velocity=29 time=69\n",
      "note_on channel=0 note=1 velocity=2 time=4\n",
      "note_on channel=0 note=2 velocity=1 time=3\n",
      "note_on channel=0 note=2 velocity=4 time=9\n",
      "note_on channel=0 note=44 velocity=0 time=15\n",
      "note_on channel=0 note=23 velocity=21 time=49\n",
      "note_on channel=0 note=42 velocity=0 time=20\n",
      "note_on channel=0 note=40 velocity=0 time=12\n",
      "note_on channel=0 note=37 velocity=0 time=13\n",
      "note_on channel=0 note=14 velocity=0 time=17\n",
      "note_on channel=0 note=13 velocity=4 time=10\n",
      "note_on channel=0 note=33 velocity=0 time=12\n",
      "note_on channel=0 note=24 velocity=0 time=19\n",
      "note_on channel=0 note=6 velocity=0 time=13\n",
      "note_on channel=0 note=3 velocity=4 time=8\n",
      "note_on channel=0 note=25 velocity=0 time=7\n",
      "note_on channel=0 note=29 velocity=0 time=10\n",
      "note_on channel=0 note=41 velocity=0 time=17\n",
      "note_on channel=0 note=17 velocity=0 time=10\n",
      "note_on channel=0 note=27 velocity=27 time=64\n",
      "note_on channel=0 note=71 velocity=0 time=3\n",
      "note_on channel=0 note=7 velocity=0 time=13\n",
      "note_on channel=0 note=71 velocity=69 time=163\n",
      "note_on channel=0 note=35 velocity=31 time=73\n",
      "note_on channel=0 note=13 velocity=12 time=28\n",
      "note_on channel=0 note=7 velocity=10 time=24\n",
      "note_on channel=0 note=26 velocity=21 time=50\n",
      "note_on channel=0 note=3 velocity=6 time=14\n",
      "note_on channel=0 note=11 velocity=0 time=0\n",
      "note_on channel=0 note=48 velocity=0 time=17\n",
      "note_on channel=0 note=67 velocity=73 time=173\n",
      "note_on channel=0 note=8 velocity=0 time=19\n",
      "note_on channel=0 note=64 velocity=60 time=141\n",
      "note_on channel=0 note=57 velocity=53 time=125\n",
      "note_on channel=0 note=41 velocity=0 time=5\n",
      "note_on channel=0 note=32 velocity=36 time=85\n",
      "note_on channel=0 note=71 velocity=72 time=170\n",
      "note_on channel=0 note=34 velocity=0 time=5\n",
      "note_on channel=0 note=42 velocity=0 time=24\n",
      "note_on channel=0 note=14 velocity=0 time=15\n",
      "note_on channel=0 note=73 velocity=71 time=169\n",
      "note_on channel=0 note=36 velocity=0 time=5\n",
      "note_on channel=0 note=23 velocity=17 time=41\n",
      "note_on channel=0 note=46 velocity=0 time=2\n",
      "note_on channel=0 note=19 velocity=0 time=16\n",
      "note_on channel=0 note=9 velocity=0 time=21\n",
      "note_on channel=0 note=19 velocity=21 time=49\n",
      "note_on channel=0 note=46 velocity=0 time=14\n",
      "note_on channel=0 note=12 velocity=0 time=25\n",
      "note_on channel=0 note=10 velocity=22 time=53\n",
      "note_on channel=0 note=19 velocity=0 time=2\n",
      "note_on channel=0 note=9 velocity=11 time=26\n",
      "note_on channel=0 note=17 velocity=16 time=39\n",
      "note_on channel=0 note=41 velocity=46 time=108\n",
      "note_on channel=0 note=1 velocity=0 time=11\n",
      "note_on channel=0 note=44 velocity=0 time=2\n",
      "note_on channel=0 note=58 velocity=0 time=5\n",
      "note_on channel=0 note=22 velocity=14 time=33\n",
      "note_on channel=0 note=55 velocity=0 time=12\n",
      "note_on channel=0 note=23 velocity=0 time=3\n",
      "note_on channel=0 note=23 velocity=21 time=49\n",
      "note_on channel=0 note=45 velocity=0 time=21\n",
      "note_on channel=0 note=3 velocity=0 time=18\n",
      "note_on channel=0 note=43 velocity=0 time=7\n",
      "note_on channel=0 note=16 velocity=20 time=47\n",
      "note_on channel=0 note=4 velocity=2 time=5\n",
      "note_on channel=0 note=6 velocity=6 time=15\n",
      "note_on channel=0 note=51 velocity=0 time=0\n",
      "note_on channel=0 note=31 velocity=0 time=11\n",
      "note_on channel=0 note=93 velocity=96 time=227\n",
      "note_on channel=0 note=4 velocity=0 time=1\n",
      "note_on channel=0 note=42 velocity=0 time=24\n",
      "note_on channel=0 note=9 velocity=0 time=9\n",
      "note_on channel=0 note=26 velocity=21 time=51\n",
      "note_on channel=0 note=40 velocity=0 time=20\n",
      "note_on channel=0 note=1 velocity=2 time=4\n",
      "note_on channel=0 note=3 velocity=8 time=18\n",
      "note_on channel=0 note=45 velocity=53 time=124\n",
      "note_on channel=0 note=58 velocity=0 time=6\n",
      "note_on channel=0 note=13 velocity=16 time=38\n",
      "note_on channel=0 note=57 velocity=57 time=134\n",
      "note_on channel=0 note=28 velocity=0 time=29\n",
      "note_on channel=0 note=89 velocity=0 time=30\n",
      "note_on channel=0 note=18 velocity=14 time=34\n",
      "note_on channel=0 note=14 velocity=12 time=28\n",
      "note_on channel=0 note=19 velocity=0 time=25\n",
      "note_on channel=0 note=59 velocity=0 time=9\n",
      "note_on channel=0 note=22 velocity=23 time=55\n",
      "note_on channel=0 note=34 velocity=0 time=17\n",
      "note_on channel=0 note=12 velocity=0 time=5\n",
      "note_on channel=0 note=2 velocity=6 time=13\n",
      "note_on channel=0 note=60 velocity=0 time=23\n",
      "note_on channel=0 note=5 velocity=0 time=15\n",
      "note_on channel=0 note=5 velocity=0 time=11\n",
      "note_on channel=0 note=35 velocity=0 time=5\n",
      "note_on channel=0 note=21 velocity=0 time=20\n",
      "note_on channel=0 note=5 velocity=0 time=26\n",
      "note_on channel=0 note=23 velocity=0 time=7\n",
      "note_on channel=0 note=24 velocity=0 time=8\n",
      "note_on channel=0 note=27 velocity=26 time=62\n",
      "note_on channel=0 note=26 velocity=25 time=58\n",
      "note_on channel=0 note=41 velocity=41 time=96\n",
      "note_on channel=0 note=20 velocity=0 time=18\n",
      "note_on channel=0 note=28 velocity=21 time=50\n",
      "note_on channel=0 note=40 velocity=0 time=3\n",
      "note_on channel=0 note=44 velocity=0 time=13\n",
      "note_on channel=0 note=4 velocity=0 time=22\n",
      "note_on channel=0 note=33 velocity=28 time=65\n",
      "note_on channel=0 note=68 velocity=69 time=163\n",
      "note_on channel=0 note=24 velocity=0 time=14\n",
      "note_on channel=0 note=60 velocity=0 time=9\n",
      "note_on channel=0 note=3 velocity=8 time=19\n",
      "note_on channel=0 note=25 velocity=0 time=17\n",
      "note_on channel=0 note=42 velocity=43 time=102\n",
      "note_on channel=0 note=31 velocity=0 time=26\n",
      "note_on channel=0 note=10 velocity=0 time=11\n",
      "note_on channel=0 note=35 velocity=43 time=100\n",
      "note_on channel=0 note=28 velocity=35 time=84\n",
      "note_on channel=0 note=37 velocity=0 time=17\n",
      "note_on channel=0 note=6 velocity=4 time=10\n",
      "note_on channel=0 note=17 velocity=0 time=4\n",
      "note_on channel=0 note=30 velocity=0 time=21\n",
      "note_on channel=0 note=0 velocity=4 time=10\n",
      "note_on channel=0 note=72 velocity=0 time=24\n",
      "note_on channel=0 note=15 velocity=0 time=12\n",
      "note_on channel=0 note=22 velocity=0 time=3\n",
      "note_on channel=0 note=44 velocity=0 time=23\n",
      "note_on channel=0 note=22 velocity=24 time=56\n",
      "note_on channel=0 note=24 velocity=25 time=59\n",
      "note_on channel=0 note=38 velocity=0 time=29\n",
      "note_on channel=0 note=25 velocity=0 time=12\n",
      "note_on channel=0 note=11 velocity=0 time=30\n",
      "note_on channel=0 note=8 velocity=3 time=8\n",
      "note_on channel=0 note=70 velocity=59 time=139\n",
      "note_on channel=0 note=91 velocity=89 time=210\n",
      "note_on channel=0 note=2 velocity=1 time=2\n",
      "note_on channel=0 note=66 velocity=0 time=26\n",
      "note_on channel=0 note=85 velocity=86 time=202\n",
      "note_on channel=0 note=59 velocity=0 time=1\n",
      "note_on channel=0 note=3 velocity=0 time=2\n",
      "note_on channel=0 note=18 velocity=23 time=54\n",
      "note_on channel=0 note=38 velocity=40 time=93\n",
      "note_on channel=0 note=29 velocity=25 time=59\n",
      "note_on channel=0 note=23 velocity=0 time=1\n",
      "note_on channel=0 note=40 velocity=0 time=25\n",
      "note_on channel=0 note=35 velocity=0 time=22\n",
      "note_on channel=0 note=14 velocity=21 time=50\n",
      "note_on channel=0 note=20 velocity=22 time=53\n",
      "note_on channel=0 note=57 velocity=55 time=130\n",
      "note_on channel=0 note=36 velocity=36 time=85\n",
      "note_on channel=0 note=53 velocity=0 time=21\n",
      "note_on channel=0 note=15 velocity=11 time=26\n",
      "note_on channel=0 note=4 velocity=0 time=15\n",
      "note_on channel=0 note=16 velocity=0 time=4\n",
      "note_on channel=0 note=26 velocity=28 time=66\n",
      "note_on channel=0 note=7 velocity=5 time=11\n",
      "note_on channel=0 note=4 velocity=8 time=20\n",
      "note_on channel=0 note=4 velocity=8 time=19\n",
      "note_on channel=0 note=42 velocity=0 time=22\n",
      "note_on channel=0 note=6 velocity=0 time=14\n",
      "note_on channel=0 note=3 velocity=6 time=14\n",
      "note_on channel=0 note=38 velocity=32 time=76\n",
      "note_on channel=0 note=34 velocity=35 time=83\n",
      "note_on channel=0 note=30 velocity=0 time=4\n",
      "note_on channel=0 note=7 velocity=13 time=30\n",
      "note_on channel=0 note=20 velocity=0 time=13\n",
      "note_on channel=0 note=6 velocity=14 time=34\n",
      "note_on channel=0 note=40 velocity=44 time=103\n",
      "note_on channel=0 note=19 velocity=0 time=1\n",
      "note_on channel=0 note=11 velocity=0 time=12\n",
      "note_on channel=0 note=19 velocity=0 time=28\n",
      "note_on channel=0 note=36 velocity=0 time=17\n",
      "note_on channel=0 note=76 velocity=73 time=173\n",
      "note_on channel=0 note=43 velocity=46 time=108\n",
      "note_on channel=0 note=6 velocity=0 time=9\n",
      "note_on channel=0 note=8 velocity=0 time=26\n",
      "note_on channel=0 note=17 velocity=13 time=30\n",
      "note_on channel=0 note=12 velocity=16 time=37\n",
      "note_on channel=0 note=11 velocity=0 time=22\n",
      "note_on channel=0 note=22 velocity=27 time=64\n",
      "note_on channel=0 note=44 velocity=48 time=114\n",
      "note_on channel=0 note=3 velocity=0 time=7\n",
      "note_on channel=0 note=40 velocity=0 time=8\n",
      "note_on channel=0 note=19 velocity=0 time=3\n",
      "note_on channel=0 note=39 velocity=0 time=12\n",
      "note_on channel=0 note=66 velocity=0 time=10\n",
      "note_on channel=0 note=0 velocity=0 time=17\n",
      "note_on channel=0 note=3 velocity=7 time=17\n",
      "note_on channel=0 note=30 velocity=25 time=58\n",
      "note_on channel=0 note=0 velocity=0 time=10\n",
      "note_on channel=0 note=25 velocity=23 time=54\n",
      "note_on channel=0 note=8 velocity=4 time=10\n",
      "note_on channel=0 note=36 velocity=0 time=25\n",
      "note_on channel=0 note=2 velocity=3 time=8\n",
      "note_on channel=0 note=27 velocity=29 time=68\n",
      "note_on channel=0 note=4 velocity=6 time=15\n",
      "note_on channel=0 note=22 velocity=0 time=6\n",
      "note_on channel=0 note=36 velocity=0 time=9\n",
      "note_on channel=0 note=44 velocity=43 time=101\n",
      "note_on channel=0 note=5 velocity=8 time=19\n",
      "note_on channel=0 note=27 velocity=0 time=14\n",
      "note_on channel=0 note=42 velocity=39 time=92\n",
      "note_on channel=0 note=77 velocity=0 time=23\n",
      "note_on channel=0 note=22 velocity=0 time=2\n",
      "note_on channel=0 note=67 velocity=70 time=165\n",
      "note_on channel=0 note=38 velocity=33 time=77\n",
      "note_on channel=0 note=9 velocity=11 time=25\n",
      "note_on channel=0 note=68 velocity=0 time=10\n",
      "note_on channel=0 note=11 velocity=0 time=6\n",
      "note_on channel=0 note=37 velocity=0 time=21\n",
      "note_on channel=0 note=39 velocity=0 time=1\n",
      "note_on channel=0 note=3 velocity=0 time=7\n",
      "note_on channel=0 note=13 velocity=0 time=6\n",
      "note_on channel=0 note=16 velocity=0 time=21\n",
      "note_on channel=0 note=13 velocity=0 time=14\n",
      "note_on channel=0 note=89 velocity=88 time=207\n",
      "note_on channel=0 note=9 velocity=0 time=29\n",
      "note_on channel=0 note=19 velocity=16 time=38\n",
      "note_on channel=0 note=41 velocity=34 time=80\n",
      "note_on channel=0 note=49 velocity=0 time=3\n",
      "note_on channel=0 note=79 velocity=0 time=0\n",
      "note_on channel=0 note=39 velocity=0 time=13\n",
      "note_on channel=0 note=33 velocity=0 time=11\n",
      "note_on channel=0 note=40 velocity=46 time=108\n",
      "note_on channel=0 note=12 velocity=13 time=31\n",
      "note_on channel=0 note=4 velocity=0 time=29\n",
      "note_on channel=0 note=77 velocity=0 time=12\n",
      "note_on channel=0 note=6 velocity=9 time=21\n",
      "note_on channel=0 note=5 velocity=0 time=27\n",
      "note_on channel=0 note=23 velocity=0 time=27\n",
      "note_on channel=0 note=26 velocity=0 time=7\n",
      "note_on channel=0 note=52 velocity=50 time=118\n",
      "note_on channel=0 note=52 velocity=0 time=1\n",
      "note_on channel=0 note=26 velocity=34 time=80\n",
      "note_on channel=0 note=27 velocity=0 time=0\n",
      "note_on channel=0 note=3 velocity=0 time=24\n",
      "note_on channel=0 note=47 velocity=0 time=12\n",
      "note_on channel=0 note=5 velocity=7 time=17\n",
      "note_on channel=0 note=27 velocity=0 time=15\n",
      "note_on channel=0 note=28 velocity=31 time=73\n",
      "note_on channel=0 note=19 velocity=11 time=26\n",
      "note_on channel=0 note=34 velocity=34 time=79\n",
      "note_on channel=0 note=5 velocity=2 time=6\n",
      "note_on channel=0 note=27 velocity=33 time=78\n",
      "note_on channel=0 note=4 velocity=6 time=15\n",
      "note_on channel=0 note=43 velocity=0 time=26\n",
      "note_on channel=0 note=74 velocity=80 time=190\n",
      "note_on channel=0 note=19 velocity=0 time=4\n",
      "note_on channel=0 note=46 velocity=49 time=116\n",
      "note_on channel=0 note=26 velocity=0 time=27\n",
      "note_on channel=0 note=33 velocity=0 time=11\n",
      "note_on channel=0 note=17 velocity=17 time=41\n",
      "note_on channel=0 note=66 velocity=0 time=11\n",
      "note_on channel=0 note=12 velocity=0 time=25\n",
      "note_on channel=0 note=41 velocity=0 time=8\n",
      "note_on channel=0 note=62 velocity=0 time=30\n",
      "note_on channel=0 note=4 velocity=0 time=0\n",
      "note_on channel=0 note=58 velocity=59 time=139\n",
      "note_on channel=0 note=37 velocity=0 time=8\n",
      "note_on channel=0 note=4 velocity=0 time=25\n",
      "note_on channel=0 note=10 velocity=0 time=8\n",
      "note_on channel=0 note=20 velocity=0 time=23\n",
      "note_on channel=0 note=16 velocity=11 time=27\n",
      "note_on channel=0 note=59 velocity=57 time=135\n",
      "note_on channel=0 note=36 velocity=32 time=76\n",
      "note_on channel=0 note=3 velocity=2 time=4\n",
      "note_on channel=0 note=20 velocity=23 time=53\n",
      "note_on channel=0 note=3 velocity=0 time=9\n",
      "note_on channel=0 note=27 velocity=29 time=68\n",
      "note_on channel=0 note=38 velocity=36 time=85\n",
      "note_on channel=0 note=11 velocity=16 time=39\n",
      "note_on channel=0 note=29 velocity=25 time=58\n",
      "note_on channel=0 note=8 velocity=0 time=7\n",
      "note_on channel=0 note=35 velocity=0 time=23\n",
      "note_on channel=0 note=44 velocity=0 time=10\n",
      "note_on channel=0 note=58 velocity=0 time=8\n",
      "note_on channel=0 note=25 velocity=0 time=22\n",
      "note_on channel=0 note=78 velocity=70 time=166\n",
      "note_on channel=0 note=3 velocity=7 time=17\n",
      "note_on channel=0 note=4 velocity=2 time=4\n",
      "note_on channel=0 note=10 velocity=13 time=31\n",
      "note_on channel=0 note=5 velocity=0 time=23\n",
      "note_on channel=0 note=54 velocity=0 time=27\n",
      "note_on channel=0 note=24 velocity=0 time=23\n",
      "note_on channel=0 note=25 velocity=0 time=10\n",
      "note_on channel=0 note=14 velocity=0 time=30\n",
      "note_on channel=0 note=28 velocity=28 time=66\n",
      "note_on channel=0 note=48 velocity=42 time=100\n",
      "note_on channel=0 note=55 velocity=0 time=12\n",
      "note_on channel=0 note=38 velocity=41 time=96\n",
      "note_on channel=0 note=15 velocity=0 time=24\n",
      "note_on channel=0 note=24 velocity=25 time=59\n",
      "note_on channel=0 note=79 velocity=78 time=185\n",
      "note_on channel=0 note=23 velocity=28 time=65\n",
      "note_on channel=0 note=16 velocity=0 time=28\n",
      "note_on channel=0 note=27 velocity=0 time=19\n",
      "note_on channel=0 note=20 velocity=16 time=38\n",
      "note_on channel=0 note=60 velocity=0 time=19\n",
      "note_on channel=0 note=16 velocity=0 time=6\n",
      "note_on channel=0 note=5 velocity=0 time=24\n",
      "note_on channel=0 note=32 velocity=34 time=82\n",
      "note_on channel=0 note=6 velocity=6 time=15\n",
      "note_on channel=0 note=46 velocity=53 time=125\n",
      "note_on channel=0 note=33 velocity=38 time=89\n",
      "note_on channel=0 note=24 velocity=24 time=57\n",
      "note_on channel=0 note=57 velocity=62 time=146\n",
      "note_on channel=0 note=35 velocity=29 time=68\n",
      "note_on channel=0 note=6 velocity=3 time=7\n",
      "note_on channel=0 note=49 velocity=44 time=104\n",
      "note_on channel=0 note=43 velocity=40 time=95\n",
      "note_on channel=0 note=28 velocity=26 time=62\n",
      "note_on channel=0 note=43 velocity=0 time=5\n",
      "note_on channel=0 note=41 velocity=34 time=81\n",
      "note_on channel=0 note=13 velocity=0 time=15\n",
      "note_on channel=0 note=14 velocity=18 time=42\n",
      "note_on channel=0 note=27 velocity=24 time=57\n",
      "note_on channel=0 note=63 velocity=0 time=20\n",
      "note_on channel=0 note=43 velocity=47 time=110\n",
      "note_on channel=0 note=21 velocity=0 time=19\n",
      "note_on channel=0 note=34 velocity=0 time=25\n",
      "note_on channel=0 note=4 velocity=7 time=16\n",
      "note_on channel=0 note=24 velocity=0 time=13\n",
      "note_on channel=0 note=31 velocity=0 time=6\n",
      "note_on channel=0 note=24 velocity=30 time=71\n",
      "note_on channel=0 note=14 velocity=10 time=23\n",
      "note_on channel=0 note=12 velocity=0 time=24\n",
      "note_on channel=0 note=37 velocity=0 time=16\n",
      "note_on channel=0 note=24 velocity=32 time=75\n",
      "note_on channel=0 note=27 velocity=0 time=19\n",
      "note_on channel=0 note=62 velocity=64 time=151\n",
      "note_on channel=0 note=34 velocity=0 time=22\n",
      "note_on channel=0 note=14 velocity=23 time=54\n",
      "note_on channel=0 note=26 velocity=0 time=29\n",
      "note_on channel=0 note=38 velocity=39 time=92\n",
      "note_on channel=0 note=52 velocity=0 time=30\n",
      "note_on channel=0 note=58 velocity=57 time=134\n",
      "note_on channel=0 note=18 velocity=0 time=3\n",
      "note_on channel=0 note=64 velocity=0 time=25\n",
      "note_on channel=0 note=46 velocity=0 time=30\n",
      "note_on channel=0 note=12 velocity=0 time=7\n",
      "note_on channel=0 note=62 velocity=0 time=27\n",
      "note_on channel=0 note=30 velocity=0 time=27\n",
      "note_on channel=0 note=19 velocity=11 time=27\n",
      "note_on channel=0 note=89 velocity=90 time=213\n",
      "note_on channel=0 note=7 velocity=2 time=6\n",
      "note_on channel=0 note=15 velocity=0 time=15\n",
      "note_on channel=0 note=29 velocity=0 time=22\n",
      "note_on channel=0 note=6 velocity=12 time=27\n",
      "note_on channel=0 note=25 velocity=0 time=27\n",
      "note_on channel=0 note=4 velocity=6 time=14\n",
      "note_on channel=0 note=30 velocity=0 time=19\n",
      "note_on channel=0 note=7 velocity=12 time=28\n",
      "note_on channel=0 note=13 velocity=12 time=29\n",
      "note_on channel=0 note=10 velocity=11 time=27\n",
      "note_on channel=0 note=51 velocity=0 time=11\n",
      "note_on channel=0 note=51 velocity=0 time=9\n",
      "note_on channel=0 note=50 velocity=47 time=111\n",
      "note_on channel=0 note=101 velocity=104 time=245\n",
      "note_on channel=0 note=3 velocity=0 time=29\n",
      "note_on channel=0 note=18 velocity=0 time=3\n",
      "MetaMessage('end_of_track', time=0)\n"
     ]
    }
   ],
   "source": [
    "# Load the MIDI file\n",
    "path = r\"D:\\BrownUniversity\\CS2470\\final_proj\\CS2470_final_project\\data\\EMOPIA\\midis\\Q1__8v0MFBZoco_0.mid\"\n",
    "mid = mido.MidiFile(\"output_label2.mid\")\n",
    "\n",
    "# Iterate over all messages in all tracks\n",
    "for i, track in enumerate(mid.tracks):\n",
    "    print(f'Track {i}: {track.name}')\n",
    "    for msg in track:\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_msg = get_song_msg(mid)\n",
    "msg_ls = []\n",
    "for i,note in enumerate(mid_msg):\n",
    "    if note[0] < 40:\n",
    "        note[0] = note[0]+30\n",
    "        msg_ls.append(note)\n",
    "# print(msg_ls)\n",
    "output_file = \"output_test.mid\"\n",
    "midi_music(msg_ls,output_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mmid = mido.MidiFile('output_test.mid')\n",
    "result_array = mid2arry(mmid)\n",
    "\n",
    "plt.plot(range(result_array.shape[0]), np.multiply(np.where(result_array>0, 1, 0), range(1, 89)), marker='.', markersize=1, linestyle='')\n",
    "plt.title(\"generate music.mid\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data2060",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
